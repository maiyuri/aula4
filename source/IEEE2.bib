@ARTICLE{9164974,
author={Adesina, Damilola and Bassey, Joshua and Qian, Lijun},
journal={IEEE Access},
title={Robust Deep Radio Frequency Spectrum Learning for Future Wireless Communications Systems},
year={2020},
volume={8},
number={},
pages={148528-148540},
abstract={Intelligent capabilities are of utmost importance in future wireless communication systems. For optimum resource utilization, wireless communication systems require knowledge of the prevalent situation in a frequency band through learning. To learn appropriately, it is imperative for practitioners to select the right parameters for building robust data-driven learning models as well as use the appropriate algorithms and performance evaluation methods. In this paper, we evaluate the performance of deep learning models against the performance of other machine learning methods for wireless communication systems. We explore the different wireless communication scenarios in which deep learning can be used given Radio Frequency (RF) data, and evaluate its performance in various scenarios. Furthermore, we express it as a distribution alignment problem in which deep learning models do not perform well when learning from RF data of a particular distribution and evaluating on RF data from a different distribution. We also discuss our results in the light of how signal quality affects deep learning model leveraging on the knowledge from computer vision domain. The effect of Signal-to-Noise Ratio (SNR) selection for training on the model performance as it relates to practical implementation of deep learning in communications systems is also discussed. From our analysis, we conclude that the design and use of RF spectrum learning must be tailored to each specific scenario being considered in practice.},
keywords={Radio frequency;Machine learning;Wireless communication;Signal to noise ratio;Robustness;Data models;Training;Radio frequency learning;signal-to-noise ratio;training and testing strategy;spectrum data;convolutional neural network},
doi={10.1109/ACCESS.2020.3015939},
ISSN={2169-3536},
month={},}
@ARTICLE{9248996,
author={Moosavi, Seyed Mohammad Hossein and Yuen, Choon Wah and Yap, Soon Poh and Onn, Chiu Chuen},
journal={IEEE Access},
title={Simulation-Based Sensitivity Analysis for Evaluating Factors Affecting Bus Service Reliability: A Big and Smart Data Implementation},
year={2020},
volume={8},
number={},
pages={201937-201955},
abstract={Service quality is a significant concern for both providers and users of public transportation. It is crucial for transit agencies to clearly recognize the causes of unreliability before adapting any improvement strategy. However, evaluation of main causes of bus service unreliability has not been investigated well. Existing studies have three main limitations in context of recognizing causes of service unreliability. First, public transport networks and traffic condition are highly complex systems and most of the existing models are not capable to accurately determine the relationship between service irregularity and impact factors. Second, definition of “Big data” has been neglected and most of the studies only focused on one source of large scale data set to determine the causes of unreliability. Third, bus service unreliability can impact the users' perception toward the public transport, significantly. It has been recommended by number of studies that bus service reliability should be evaluated from both service providers' and users' perspective. However, the impact of service unreliability from passengers' perception is not well investigated, yet. Consequently, we proposed a novel simulation-based sensitivity analysis to evaluating main causes of bus service unreliability using a combination of three different sources of big data. Moreover, for the first time we developed a simulation model in R studio which is an open source and powerful coding environment. According to the results, the level of reliability in Route U32 showed the highest sensitivity to headway variations. Waiting time can be decreased by 61% if only bus operators can reduce the headway variation by 25% of the actual observed data. Big gap and bus bunching could be almost disappeared by decreasing headway variations. Moreover, the terminal departure policy could significantly improve the passenger waiting time. Waiting time can be decreased by 36% when almost all the buses depart the terminal on-time.},
keywords={Analytical models;Sensitivity analysis;Encoding;Reliability;Task analysis;Public transportation;Open source software;Big data;complex systems;passengers’ perspective;simulation model;sensitivity analysis},
doi={10.1109/ACCESS.2020.3036285},
ISSN={2169-3536},
month={},}
@ARTICLE{9503402,
author={Math, Sa and Tam, Prohim and Kim, Seokhoon},
journal={IEEE Access},
title={Reliable Federated Learning Systems Based on Intelligent Resource Sharing Scheme for Big Data Internet of Things},
year={2021},
volume={9},
number={},
pages={108091-108100},
abstract={Federated learning (FL) is the up-to-date approach for privacy constraints Internet of Things (IoT) applications in next-generation mobile network (NGMN), 5th generation (5G), and 6th generation (6G), respectively. Due to 5G/6G is based on new radio (NR) technology, the multiple-input and multiple-output (MIMO) of radio services for heterogeneous IoT devices have been performed. The autonomous resource allocation and the intelligent quality of service class identity (IQCI) in mobile networks based on FL systems are obligated to meet the requirements of privacy constraints of IoT applications. In massive FL communications, the heterogeneous local devices propagate their local models and parameters over 5G/6G networks to the aggregation servers in edge cloud areas. Therefore, the assurance of network reliability is compulsory to facilitate end-to-end (E2E) reliability of FL communications and provide the satisfaction of model decisions. This paper proposed an intelligent lightweight scheme based on the reference software-defined networking (SDN) architecture to handle the massive FL communications between clients and aggregators to meet the mentioned perspectives. The handling method adjusts the model parameters and batches size of the individual client to reflect the apparent network conditions classified by the k-nearest neighbor (KNN) algorithm. The proposed system showed notable experimented metrics, including the E2E FL communication latency, throughput, system reliability, and model accuracy.},
keywords={Servers;Internet of Things;Reliability;Computational modeling;Cloud computing;Quality of service;Collaborative work;Big data;federated learning;massive Internet of Things;machine learning;software-defined network},
doi={10.1109/ACCESS.2021.3101871},
ISSN={2169-3536},
month={},}
@ARTICLE{9052728,
author={Cao, Yuan and Wang, Xinhe and Lin, Xiaoyang and Yang, Wei and Lv, Chen and Lu, Yuan and Zhang, Youguang and Zhao, Weisheng},
journal={IEEE Access},
title={Movable-Type Transfer and Stacking of van der Waals Heterostructures for Spintronics},
year={2020},
volume={8},
number={},
pages={70488-70495},
abstract={The key to achieving high-quality and practical van der Waals heterostructure devices made from various two-dimensional (2D) materials lies in the efficient control over clean and flexible interfaces. Inspired by the “movable-type printing”, one of the four great inventions of ancient China, we demonstrate the “movable-type” transfer and stacking of 2D materials, which utilizes prefabricated polyvinyl alcohol (PVA) film to engineer the interfacial adhesion to 2D materials, and provides a flexible, efficient and batchable transfer scheme for 2D materials. The experiments also verify the “movable-type” transfer can preciously control the position and orientation of 2D materials, which meets the burgeoning requirements such as the preparation of twisted graphene and other heterostructures. Importantly, water-solubility of PVA film ensures an ideal interface of the materials without introducing contamination. We illustrate the superiority of this method with a WSe2 vertical spin valve device, whose performance verifies the applicability and advantages of such a method for spintronics. Our PVA-assisted “movable-type” transfer process may promote the development of high-performance 2D-material-based devices.},
keywords={Two dimensional displays;Stacking;Graphene;Printing;Substrates;Spintronics;Adhesives;movable-type;PVA transfer;two-dimensional materials;spin valve;spintronics},
doi={10.1109/ACCESS.2020.2984942},
ISSN={2169-3536},
month={},}
@ARTICLE{8804358,
author={Liu, Xiaolong and Lin, Chia-Chen and Muhammad, Khan and Al-Turjman, Fadi and Yuan, Shyan-Ming},
journal={IEEE Access},
title={Joint Data Hiding and Compression Scheme Based on Modified BTC and Image Inpainting},
year={2019},
volume={7},
number={},
pages={116027-116037},
abstract={Seamlessly integrating image compression technique and secret data hiding technique into a single procedure for security and efficient data transmission is a novel research issue in modern, decentralized digital communication environments. The first joint data hiding and compression (JDHC) scheme on block truncation coding (BTC) compression domain is presented in this paper. In the compressing and embedding procedure, for the complex blocks, modified block truncation coding (MBTC) is utilized to embed secret data and compress blocks simultaneously, while further controlling the visual distortion that is caused during data embedding. For the smooth blocks, according to the current embedding bit, either image inpainting or block search order coding (BSOC) is used to embed secret data and compress blocks simultaneously with maintaining acceptable compression performance. According to the image compression codes that are provided as output, image decompression and secret bits extraction procedures can be conducted simultaneously. Experimental results indicate that outstanding compression bit rate can be achieved by the proposed JDHC scheme with satisfactory visual quality and hiding capacity.},
keywords={Image coding;Visualization;Transform coding;Bit rate;Agriculture;Forestry;Quantization (signal);Data hiding;image compression;MBTC;BSOC;image inpainting},
doi={10.1109/ACCESS.2019.2935907},
ISSN={2169-3536},
month={},}
@ARTICLE{7590317,
author={Yuncheng Shen and Bing Guo and Yan Shen and Xuliang Duan and Xiangqian Dong and Hong Zhang},
journal={Tsinghua Science and Technology},
title={A pricing model for Big Personal Data},
year={2016},
volume={21},
number={5},
pages={482-490},
abstract={Big Personal Data is growing explosively. Consequently, an increasing number of internet users are drowning in a sea of data. Big Personal Data has enormous commercial value; it is a new kind of data asset. An urgent problem has thus arisen in the data market: How to price Big Personal Data fairly and reasonably. This paper proposes a pricing model for Big Personal Data based on tuple granularity, with the help of comparative analysis of existing data pricing models and strategies. This model is put forward to implement positive rating and reverse pricing for Big Personal Data by investigating data attributes that affect data value, and analyzing how the value of data tuples varies with information entropy, weight value, data reference index, cost, and other factors. The model can be adjusted dynamically according to these parameters. With increases in data scale, reductions in its cost, and improvements in its quality, Big Personal Data users can thereby obtain greater benefits.},
keywords={Pricing;Data models;Cost accounting;Data privacy;Information entropy;Indexes;Computational modeling;data tuple;Big Personal Data;positive grading;reverse pricing;pricing model},
doi={10.1109/TST.2016.7590317},
ISSN={1007-0214},
month={Oct},}
@ARTICLE{9682686,
author={Sim, Sunghyun and Sutrisnowati, Riska Asriana and Won, Seokrae and Lee, Sanghwa and Bae, Hyerim},
journal={IEEE Access},
title={Automatic Conversion of Event Data to Event Logs Using CNN and Event Density Embedding},
year={2022},
volume={10},
number={},
pages={15994-16009},
abstract={In process mining, converting event data to event logs is related to the quality of analysis results. In general, to convert event data into event logs, it is necessary to identify process entities, such as the case identifier, activity label, activity originator, and activity timestamp, from the data fields in the event data, as well as other optional attributes. Up to now, the event log conversion process has been attempted by relying on an expert’s intuition or an analyst’s experience. However, the conversion is a challenging procedure without sufficient prior knowledge of process mining. To automate the conversion process, an event log–converting algorithm based on the convolutional neural network (CNN) was developed with a new embedding method called Event Density Embedding (EDE). To verify the performance of the proposed embedding method and the automatic event log conversion framework, a comparative experiment was performed using nine pieces of real-world event data. The experiments show that our method is 5–20% higher conversion accuracy than the other methods. It is expected that business experts will be able to easily apply the method to process mining technology by utilizing system-derived event data.},
keywords={Data mining;Convolutional neural networks;Feature extraction;Encoding;Xenon;Deep learning;Process mining;automatic event log conversion;event data engineering;event density embedding},
doi={10.1109/ACCESS.2022.3143609},
ISSN={2169-3536},
month={},}
@ARTICLE{8320776,
author={Lin, Huaqing and Yan, Zheng and Chen, Yu and Zhang, Lifang},
journal={IEEE Access},
title={A Survey on Network Security-Related Data Collection Technologies},
year={2018},
volume={6},
number={},
pages={18345-18365},
abstract={Security threats and economic loss caused by network attacks, intrusions, and vulnerabilities have motivated intensive studies on network security. Normally, data collected in a network system can reflect or can be used to detect security threats. We define these data as network security-related data. Studying and analyzing security-related data can help detect network attacks and intrusions, thus making it possible to further measure the security level of the whole network system. Obviously, the first step in detecting network attacks and intrusions is to collect security-related data. However, in the context of big data and 5G, there exist a number of challenges in collecting these security-related data. In this paper, we first briefly introduce network security-related data, including its definition and characteristics, and the applications of network data collection. We then provide the requirements and objectives for security-related data collection and present a taxonomy of data collection technologies. Moreover, we review existing collection nodes, collection tools, and collection mechanisms in terms of network data collection and analyze them based on the proposed requirements and objectives toward high quality security-related data collection. Finally, we discuss open research issues and conclude with suggestions for future research directions.},
keywords={Data collection;Malware;Monitoring;Intrusion detection;Communication networks;Telecommunication traffic;Network security;security-related data;data collection technologies;large-scale heterogeneous networks},
doi={10.1109/ACCESS.2018.2817921},
ISSN={2169-3536},
month={},}
@ARTICLE{9392233,
author={Chen, Jinyue and Chen, Shuisen and Fu, Rao and Wang, Chongyang and Li, Dan and Peng, Yongshi and Wang, Li and Jiang, Hao and Zheng, Qiong},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
title={Remote Sensing Estimation of Chlorophyll-A in Case-II Waters of Coastal Areas: Three-Band Model Versus Genetic Algorithm–Artificial Neural Networks Model},
year={2021},
volume={14},
number={},
pages={3640-3658},
abstract={Chlorophyll-a (Chl-a), an important indicator of phytoplankton biomass and eutrophication, is sensitive to water constitutes and optical characteristics. An integrated machine learning method of genetic algorithm and artificial neural networks (GA–ANN) was developed to retrieve the concentration of Chl-a. In situ spectra and simultaneous water quality parameters of 107 samples from two reservoirs (Res) and coastal waters (CW) were used to calibrate GA–ANN and three-band models (TBM) for comparison of Chl-a estimation. Both GA–ANN and TBM methods perform well for the joint dataset (WGD) of Res and CW with the R2 exceeding 0.90, and the root mean square error (RMSE) of corresponding validation (N = 35) are 4.40 and 5.23 μg/L, respectively. Similarly, for independent dataset of Res (N = 45), GA–ANN and TBM methods show robust performance: the R2 values are 0.87 and 0.80, respectively; and the corresponding RMSE values are 7.79 and 7.73 μg/L, respectively. For CW dataset (N = 62), the R2 values of two methods are 0.81 and 0.62, respectively; and the corresponding RMSE values are 0.79 and 1.32 μg/L, respectively. When the GA–ANN and TBM models were applied to retrieve Chl-a concentration from the calibrated Sentinel 2 MSI reflectance data in two Res on October 20, 2019, however, the validated results of MSI-derived Chl-a concentrations using quasi-synchronous in situ data (N = 36) indicated that the GA–ANN model outperforms TBM with higher R2 value (0.91 vs. 0.26) and smaller RMSE (4.41 vs. 13.85 μg/L) and mean absolute errors (3.40 vs. 11.87 μg/L) values. Although TBM has obvious overestimation of Chl-a concentration when applied to remote sensing image, we still thought that both GA–ANN and TBM are useful methods for Chl-a estimation in case-II waters, and GA–ANN performs marginally better with less deviation to measured Chl-a for multispectral remote sensing data. The ratio of TSS to Chl-a, experimental measurements, abundance of sampling points, and Chl-a concentration range are several important factors affecting the accuracy and robustness of GA–ANN and TBM methods.},
keywords={Biological system modeling;Water quality;Reservoirs;Estimation;Water pollution;Genetic algorithms;Optical sensors;Artificial neural networks (ANN);case-II waters;chlorophyll-a (Chl-a);coastal areas;genetic algorithm (GA);machine learning;Sentinel 2 MSI;three-band models (TBM)},
doi={10.1109/JSTARS.2021.3066697},
ISSN={2151-1535},
month={},}
@ARTICLE{8794542,
author={Huang, Mingfeng and Liu, Wei and Wang, Tian and Deng, Qingyong and Liu, Anfeng and Xie, Mande and Ma, Ming and Zhang, Guoping},
journal={IEEE Access},
title={A Game-Based Economic Model for Price Decision Making in Cyber-Physical-Social Systems},
year={2019},
volume={7},
number={},
pages={111559-111576},
abstract={Cyber-physical-social (CPS) systems integrate Big Data Collectors (BDCs), Service Organizers (SOs) and users to build a unified data-centric computing framework. In CPS systems, BDCs leverage a vast variety of sensing devices to collect cyber-physical-social data, and report these data to SOs to orchestrate various services provided to users, thus offering a great potential for solving complex network tasks that are far beyond the capabilities of existing networks. However, due to the lack of an economic model to describe such complex data interactions, their applications are limited. So, a game-based economic model is proposed in this paper to make smart price decisions in CPS systems. Specifically, it has the following innovations: (a) The economic model gives a dynamic game income matrix which can accurately describe the revenue changes of BDCs in the game, so as to help BDCs select appropriate game parameters and strategies, and make BDCs competitive in the game. (b) The economic model can help SOs to make optimized data purchase price and service selling price based on data collection cost and competitor price analysis, so that SOs can have a better Quality of Service (QoS) and users attraction, and maximize the profit. Experimental results demonstrate that the proposed model can help BDCs and SOs find the most suitable game strategy and price adjustment principle, which has great significance in applications.},
keywords={Economics;Games;Data models;Quality of service;Analytical models;Data collection;Task analysis;Cyber-physical-social system;price decision;game theory;economic model},
doi={10.1109/ACCESS.2019.2934515},
ISSN={2169-3536},
month={},}
@ARTICLE{9802898,
author={Wu, Jiashu and Xiong, Jingpan and Dai, Hao and Wang, Yang and Xu, Chengzhong},
journal={Tsinghua Science and Technology},
title={MIX-RS: A Multi-Indexing System Based on HDFS for Remote Sensing Data Storage},
year={2022},
volume={27},
number={6},
pages={881-893},
abstract={A large volume of Remote Sensing (RS) data has been generated with the deployment of satellite technologies. The data facilitate research in ecological monitoring, land management and desertification, etc. The characteristics of RS data (e.g., enormous volume, large single-file size, and demanding requirement of fault tolerance) make the Hadoop Distributed File System (HDFS) an ideal choice for RS data storage as it is efficient, scalable, and equipped with a data replication mechanism for failure resilience. To use RS data, one of the most important techniques is geospatial indexing. However, the large data volume makes it time-consuming to efficiently construct and leverage. Considering that most modern geospatial data centres are equipped with HDFS-based big data processing infrastructures, deploying multiple geospatial indices becomes natural to optimise the efficacy. Moreover, because of the reliability introduced by high-quality hardware and the infrequently modified property of the RS data, the use of multi-indexing will not cause large overhead. Therefore, we design a framework called Multi-IndeXing-RS (MIX-RS) that unifies the multi-indexing mechanism on top of the HDFS with data replication enabled for both fault tolerance and geospatial indexing efficiency. Given the fault tolerance provided by the HDFS, RS data are structurally stored inside for faster geospatial indexing. Additionally, multi-indexing enhances efficiency. The proposed technique naturally sits on top of the HDFS to form a holistic framework without incurring severe overhead or sophisticated system implementation efforts. The MIX-RS framework is implemented and evaluated using real remote sensing data provided by the Chinese Academy of Sciences, demonstrating excellent geospatial indexing performance.},
keywords={Fault tolerance;Satellites;File systems;Fault tolerant systems;Distributed databases;Memory;Geospatial analysis;Remote Sensing (RS) data;geospatial indexing;multi-indexing mechanism;Hadoop Distributed File System (HDFS);Multi-IndeXing-RS (MIX-RS)},
doi={10.26599/TST.2021.9010082},
ISSN={1007-0214},
month={December},}
@ARTICLE{8786119,
author={Chen, Wenbin and Shao, Yanling and Jia, Lina and Wang, Yanling and Zhang, Quan and Shang, Yu and Liu, Yi and Chen, Yan and Liu, Yanli and Gui, Zhiguo},
journal={IEEE Access},
title={Low-Dose CT Image Denoising Model Based on Sparse Representation by Stationarily Classified Sub-Dictionaries},
year={2019},
volume={7},
number={},
pages={116859-116874},
abstract={Low-dose computed tomography (LDCT) technique is an important imaging modality, but LDCT images are always severely degraded by mottle noise and streak artifacts. The recently proposed nonlocally centralized sparse representation (NCSR) algorithm has good performance in natural image denoising, but it suffers from residual streak artifacts and can't preserve edges structure information well when implemented in LDCT image denoising. In addition, it has high computational complexity. To address this problem, in this paper, we propose an improved model, i.e. SNCSR model, based on the stationary PCA sub-dictionaries, nonlocally centralized sparse representation and relative total variation. In the SNCSR model, in order to learn more accurate sub-dictionaries, the LDCT image is preprocessed by the improved total variation (ITV) model in which the weighted coefficient of the regularization term is constructed depending on a clipped and normalized local activity. In addition, the maximum eigenvalue of the gradient covariance matrix of the image patch is used to distinguish edge structure information from background region so that the restored image can be represented more sparsely. Moreover, unlike the NCSR model that needs to learn sub-dictionaries in each outer loop, the proposed model learns stationary sub-dictionaries only once before iteration starts, which shorten the computation time significantly. At last, the relative total variation (RTV) algorithm is applied to further reduce the residual artifacts in the recovered image more thoroughly. The experiments are performed on the simulated pelvis phantom, the actual thoracic phantom and the clinical abdominal data. Compared with several other competitive denoising algorithms, both subjective visual effect and objective evaluation criteria show that the proposed SNCSR model has lower computational complexity and can improve LDCT images quality more effectively.},
keywords={Computational modeling;Image denoising;Image edge detection;Computed tomography;TV;Noise reduction;X-ray imaging;Low-dose computed tomography (LDCT) image denoising;sparse representation;stationary sub-dictionaries;the maximum eigenvalue of the gradient covariance matrix;total variation (TV);the clipped and normalized local activity},
doi={10.1109/ACCESS.2019.2932754},
ISSN={2169-3536},
month={},}
@ARTICLE{9430134,
author={Xue, Zhonghao and Wang, Hongzhi},
journal={Big Data Mining and Analytics},
title={Effective density-based clustering algorithms for incomplete data},
year={2021},
volume={4},
number={3},
pages={183-194},
abstract={Density-based clustering is an important category among clustering algorithms. In real applications, manydatasets suffer from incompleteness. Traditional imputation technologies or other techniques for handling missingvalues are not suitable for density-based clustering and decrease clustering result quality. To avoid these problems, we develop a novel density-based clustering approach for incomplete data based on Bayesian theory, which conductsimputation and clustering concurrently and makes use of intermediate clustering results. To avoid the impact oflow-density areas inside non-convex clusters, we introduce a local imputation clustering algorithm, which aims toimpute points to high-density local areas. The performances of the proposed algorithms are evaluated using tensynthetic datasets and five real-world datasets with induced missing values. The experimental results show theeffectiveness of the proposed algorithms.},
keywords={Clustering algorithms;Data mining;Shape;Big Data;Bayes methods;Optimization;Clustering methods;density-based clustering;incomplete data;clustering algorihtm},
doi={10.26599/BDMA.2021.9020001},
ISSN={2096-0654},
month={Sep.},}
@ARTICLE{8924671,
author={Castro, Jorge and Yera Toledo, Raciel and Alzahrani, Ahmad A. and Sánchez, Pedro J. and Barranco, Manuel J. and Martínez, Luis},
journal={IEEE Access},
title={A Big Data Semantic Driven Context Aware Recommendation Method for Question-Answer Items},
year={2019},
volume={7},
number={},
pages={182664-182678},
abstract={Content-Based recommender systems (CB) filter relevant items to users in overloaded search spaces using information about their preferences. However, classical CB scheme is mainly based on matching between items descriptions and user profile, without considering that context may influence user preferences. Therefore, it cannot achieve high accuracy on user preference prediction. This paper aims to handle context-awareness (CA) to improve quality of recommendation taking contextual information as the trend in current trend interest, in which a stream of status updates can be analyzed to model the context. It proposes a novel CA-CB approach that recommends question/answer items by considering context awareness based on topic detection within current trend interest. A case study and related experiments were developed in the big data framework Spark to show that the context integration benefits recommendation performance.},
keywords={Market research;Recommender systems;Proposals;Big Data;Context-aware services;Context modeling;Semantics;Content-based recommender system;context-awareness;user profile contextualization;map-reduce;big data},
doi={10.1109/ACCESS.2019.2957881},
ISSN={2169-3536},
month={},}
@ARTICLE{8643345,
author={Sang, Jun and Wu, Weiqun and Luo, Hongling and Xiang, Hong and Zhang, Qian and Hu, Haibo and Xia, Xiaofeng},
journal={IEEE Access},
title={Improved Crowd Counting Method Based on Scale-Adaptive Convolutional Neural Network},
year={2019},
volume={7},
number={},
pages={24411-24419},
abstract={Crowd counting is a challenging task due to the influence of various factors, such as scene transformation, complex crowd distribution, uneven illumination, and occlusion. To overcome such problems, scale-adaptive convolutional neural network (SaCNN) used a convolutional neural network to obtain high-quality crowd density map estimation and integrate the density map to get the estimated headcount. To obtain better performance on crowd counting, an improved crowd counting method based on SaCNN was proposed in this paper. The spread parameter, i.e., the standard variance, of geometry-adaptive Gaussian kernel used in SaCNN was optimized to generate a higher quality ground truth density map for training. The absolute count loss with weight 4e-5 was used to jointly optimize with the density map loss to improve the network generalization ability for crowd scenes with few pedestrians. Also, a random cropping method was applied to improve the diversity of training samples to enhance network generalization ability. The experimental results upon ShanghaiTech public dataset showed that the proposed method can obtain more accurate and more robust results on crowd counting than those of SaCNN.},
keywords={Head;Kernel;Training;Convolutional neural networks;Estimation;Task analysis;Standards;Crowd counting;convolutional neural network;scale-adaptive convolutional neural network (SaCNN);density map;scale-adaptive;absolute count loss},
doi={10.1109/ACCESS.2019.2899939},
ISSN={2169-3536},
month={},}
@ARTICLE{8868305,
author={Xiaolong, Xu and Yun, Chen and Liuyun, Hu and Anup, Kumar},
journal={Journal of Systems Engineering and Electronics},
title={MTSS: Multi-path traffic scheduling mechanism based on SDN},
year={2019},
volume={30},
number={5},
pages={974-984},
abstract={Large-scale and diverse businesses based on the cloud computing platform bring the heavy network traffic to cloud data centers. However, the unbalanced workload of cloud data center network easily leads to the network congestion, the low resource utilization rate, the long delay, the low reliability, and the low throughput. In order to improve the utilization efficiency and the quality of services (QoS) of cloud system, especially to solve the problem of network congestion, we propose MTSS, a multi-path traffic scheduling mechanism based on software defined networking (SDN). MTSS utilizes the data flow scheduling flexibility of SDN and the multi-path feature of the fat-tree structure to improve the traffic balance of the cloud data center network. A heuristic traffic balancing algorithm is presented for MTSS, which periodically monitors the network link and dynamically adjusts the traffic on the heavy link to achieve programmable data forwarding and load balancing. The experimental results show that MTSS outperforms equal-cost multi-path protocol (ECMP), by effectively reducing the packet loss rate and delay. In addition, MTSS improves the utilization efficiency, the reliability and the throughput rate of the cloud data center network.},
keywords={Heuristic algorithms;Cloud computing;Load management;Data centers;Scheduling;Protocols;Throughput;cloud data center;software defined networking (SDN);load balancing;multi-path transmission;OpenFlow},
doi={10.21629/JSEE.2019.05.14},
ISSN={1004-4132},
month={Oct},}
@ARTICLE{8543558,
author={Chattaraj, Durbadal and Sarma, Monalisa and Das, Ashok Kumar and Kumar, Neeraj and Rodrigues, Joel J. P. C. and Park, Youngho},
journal={IEEE Access},
title={HEAP: An Efficient and Fault-Tolerant Authentication and Key Exchange Protocol for Hadoop-Assisted Big Data Platform},
year={2018},
volume={6},
number={},
pages={75342-75382},
abstract={Hadoop framework has been evolved to manage big data in cloud. Hadoop distributed file system and MapReduce, the vital components of this framework, provide scalable and fault-tolerant big data storage and processing services at a lower cost. However, Hadoop does not provide any robust authentication mechanism for principals’ authentication. In fact, the existing state-of-the-art authentication protocols are vulnerable to various security threats, such as man-in-the-middle, replay, password guessing, stolen-verifier, privileged-insider, identity compromization, impersonation, denial-of-service, online/off-line dictionary, chosen plaintext, workstation compromization, and server-side compromisation attacks. Beside these threats, the state-of-the-art mechanisms lack to address the server-side data integrity and confidentiality issues. In addition to this, most of the existing authentication protocols follow a single-server-based user authentication strategy, which, in fact, originates single point of failure and single point of vulnerability issues. To address these limitations, in this paper, we propose a fault-tolerant authentication protocol suitable for the Hadoop framework, which is called the efficient authentication protocol for Hadoop (HEAP). HEAP alleviates the major issues of the existing state-of-the-art authentication mechanisms, namely operating-system-based authentication, password-based approach, and delegated token-based schemes, respectively, which are presently deployed in Hadoop. HEAP follows two-server-based authentication mechanism. HEAP authenticates the principal based on digital signature generation and verification strategy utilizing both advanced encryption standard and elliptic curve cryptography. The security analysis using both the formal security using the broadly accepted real-or-random (ROR) model and the informal (non-mathematical) security shows that HEAP protects several well-known attacks. In addition, the formal security verification using the widely used automated validation of Internet security protocols and applications ensures that HEAP is resilient against replay and man-in-the-middle attacks. Finally, the performance study contemplates that the overheads incurred in HEAP is reasonable and is also comparable to that of other existing state-of-the-art authentication protocols. High security along with comparable overheads makes HEAP to be robust and practical for a secure access to the big data storage and processing services.},
keywords={Authentication;Servers;Big Data;Protocols;Password;Fault tolerance;Cloud computing;authentication;key agreement;big data security;hadoop;formal security;AVISPA},
doi={10.1109/ACCESS.2018.2883105},
ISSN={2169-3536},
month={},}
@ARTICLE{8466785,
author={Wu, Yue},
journal={IEEE Access},
title={Research on Depth Estimation Method of Light Field Imaging Based on Big Data in Internet of Things From Camera Array},
year={2018},
volume={6},
number={},
pages={52308-52320},
abstract={In recent years, optical field imaging technology has received extensive attention in the academic circle for its novel imaging characteristics of shooting first and focusing later, variable depth of field, variable viewpoint, and so on. However, the existing optical field acquisition equipment can only acquire a limited number of discrete angle signals, so image aliasing caused by under sampling of optical field angle signals reduces the quality of optical field images. Based on the camera array system as a platform, this paper studies the optical field imaging and depth estimation method based on the Big Data in Internet of Things obtained from camera array around the angle sampling characteristics of the optical field data set, and has achieved some innovative research results in the following aspects. On the basis of analyzing the characteristics of different depth clues in the optical field data set, a depth estimation method combining parallax method and focusing method is proposed. First, this paper analyzes the disparity clues and focus clues contained in the multi-view data set and the light field refocusing image set of the camera array, respectively, and points out the differences and relationships between the two depth clues extraction methods in the light field sampling frequency domain space, that is, the disparity method focuses on the energy concentration characteristics near the frequency domain spatial angle axis, while the focus method focuses on the high frequency proportion of energy distribution on the angle axis. Then, the weighted linear fusion method based on image gradient is used to fuse the two calculation results, which improves the accuracy and robustness of depth estimation. Finally, the results of depth estimation experiments on different sets of scenes show that compared with the method based on a single depth cue, the method in this paper has higher accuracy in depth calculation in discontinuous areas of scene depth and similar texture areas.},
keywords={Cameras;Optical imaging;Estimation;Arrays;Photography;Big data in Internet of Things(IoT);camera array;light field imaging;image aliasing;depth estimation},
doi={10.1109/ACCESS.2018.2870394},
ISSN={2169-3536},
month={},}
@ARTICLE{9186592,
author={Gao, Ya and Shi, Yongpeng and Xia, Yujie and Zhang, Hailin},
journal={IEEE Access},
title={Statistical QoS Aware for Wireless Powered Cooperative Communications in Internet of Things},
year={2020},
volume={8},
number={},
pages={165884-165893},
abstract={This article unveils the importance of statistical quality of service (QoS) for resource allocation in a two-hop network. Particularly, an access point (AP) serves multiple IoT devices for information transfer with the assistance of the energy harvesting (EH) relaying. To explore the maximum constant data arrival metric, we aim to maximize the effective capacity (EC) under specified QoS requirements. Also, the statistical QoS inspired resource allocation policies are investigated for half/full duplex (HD/FD) modes, respectively, to jointly optimize power allocation and power splitting (PS) ratio. To solve the formulated problem, we first derive the closed-form solution of the optimal power allocation at the AP and the PS ratio. To gain more insights, we further derive the boundary conditions of optimal power allocation and PS ratio. Finally, numerical results are demonstrated to validate the theoretical derivations, which highlights the proposed scheme in terms of EC performance in comparison to the benchmark scheme.},
keywords={Wireless communication;Relays;Quality of service;Resource management;Wireless sensor networks;Internet of Things;Energy harvesting;Internet of Things networks;simultaneous wireless information and power transfer;statistical QoS;relay communications;power allocation},
doi={10.1109/ACCESS.2020.3021832},
ISSN={2169-3536},
month={},}
@ARTICLE{9732429,
author={Ma, Shun and Liu, Haojie and Zhu, Xiaogang and Fan, Yufeng and Su, Caixia and Cao, Yongfeng},
journal={IEEE Access},
title={MS4PS: A Mentor-Student Architecture for Patient-Specific Seizure Detection With Combination of Transfer Learning and Active Learning},
year={2022},
volume={10},
number={},
pages={29646-29667},
abstract={Privacy protection, high labeling cost, and varying characteristics of seizures among patients and at different times are the main obstacles to building seizure detection models. Considering these issues, we propose a novel Mentor-Student architecture for Patient-Specific seizure detection (MS4PS). It contains a new method of knowledge transferring called mentor-select-for-student, which exploits the knowledge of a mentor model by using this model to select data for training a student model, making it possible to avoid transferring patient data and the negative influence of transferring parameters/structures of pre-trained models. It also contains a new method of active learning, which uses both an experienced mentor model and a quick-learning student model to select high-quality samples for doctors to label. Each of the two models is coupled with a particular sample selection strategy that combines uncertainty/certainty and the distance between the unlabeled samples and labeled seizure samples. The proposed method can quickly train a suitable detector for a patient at his/her first epilepsy diagnosis with the help of: (1) an experienced mentor model that chooses the most category-certain electroencephalography (EEG) data segments; (2) a student model (detector itself) that chooses the most category-uncertain EEG data segments; (3) doctors who label these data segments selected by both the mentor model and student model. By replacing or improving the mentor model and refining the historical models of patients when they come next time, the MS4PS system can be sustainably promoted. The proposed method is tested on the CHB-MIT and NEO datasets, and the results demonstrate its effectiveness and efficiency.},
keywords={Brain modeling;Data models;Electroencephalography;Transfer learning;Medical services;Detectors;Task analysis;Active learning;epilepsy;mentor-student architecture;patient-specific;transfer learning},
doi={10.1109/ACCESS.2022.3158348},
ISSN={2169-3536},
month={},}
@ARTICLE{8476553,
author={Salo, Fadi and Injadat, Mohammadnoor and Nassif, Ali Bou and Shami, Abdallah and Essex, Aleksander},
journal={IEEE Access},
title={Data Mining Techniques in Intrusion Detection Systems: A Systematic Literature Review},
year={2018},
volume={6},
number={},
pages={56046-56058},
abstract={The continued ability to detect malicious network intrusions has become an exercise in scalability, in which data mining techniques are playing an increasingly important role. We survey and categorize the fields of data mining and intrusion detection systems, providing a systematic treatment of methodologies and techniques. We apply a criterion-based approach to select 95 relevant articles from 2007 to 2017. We identified 19 separate data mining techniques used for intrusion detection, and our analysis encompasses rich information for future research based on the strengths and weaknesses of these techniques. Furthermore, we observed a research gap in establishing the effectiveness of classifiers to identify intrusions in modern network traffic when trained with aging data sets. Our review points to the need for more empirical experiments addressing real-time solutions for big data against contemporary attacks.},
keywords={Data mining;Intrusion detection;Systematics;Bibliographies;Quality assessment;Libraries;Search problems;Intrusion detection system;real-time detection;data mining;network security},
doi={10.1109/ACCESS.2018.2872784},
ISSN={2169-3536},
month={},}
@ARTICLE{9629345,
author={Ren, Lei and Wang, Tao and Laili, Yuanjun and Zhang, Lin},
journal={IEEE Transactions on Industrial Informatics},
title={A Data-Driven Self-Supervised LSTM-DeepFM Model for Industrial Soft Sensor},
year={2022},
volume={18},
number={9},
pages={5859-5869},
abstract={Soft sensor, as an important paradigm for industrial intelligence, is widely used in industrial production to achieve efficient monitoring and prediction of production status including product quality. Data-driven soft sensor methods have attracted attention, which still have challenges because of complex industrial data with diverse characteristics, nonlinear relationships, and massive unlabeled samples. In this article, a data-driven self-supervised long short-term memory–deep factorization machine (LSTM-DeepFM) model is proposed for industrial soft sensor, in which a framework mainly including pretraining and finetuning stages is proposed to explore diverse industrial data characteristics. In the pretraining stage, an LSTM-autoencoder is first unsupervised pretrained. Then, based on two self-supervised mask strategies, LSTM-deep can explore the interdependencies between features as well as the dynamic fluctuation in time series. In the finetuning stage, relying on pretrained representation, the temporal, high-dimensional, and low-dimensional features can be extracted from the LSTM, deep, and FM components, respectively. Finally, experiments on the real-world mining dataset demonstrate that the proposed method achieves state of the art comparing with stacked autoencoder-based models, variational autoencoder-based models, semisupervised parallel DeepFM, etc.},
keywords={Feature extraction;Soft sensors;Logic gates;Data mining;Time series analysis;Frequency modulation;Data models;Deep learning;industrial big data;industrial intelligence;product quality prediction;self-supervised learning;soft sensor},
doi={10.1109/TII.2021.3131471},
ISSN={1941-0050},
month={Sep.},}
@ARTICLE{9445109,
author={Li, Yiting and Huang, Haisong and Chen, Qipeng and Fan, Qingsong and Quan, Huafeng},
journal={IEEE Access},
title={Research on a Product Quality Monitoring Method Based on Multi Scale PP-YOLO},
year={2021},
volume={9},
number={},
pages={80373-80387},
abstract={To monitor product quality in the production process in real time, this thesis proposes a quality monitoring model based on PaddlePaddle You Only Look Once (PP-YOLO). First, in the preprocessing stage, the data enhancement method and the K-means++ method are used to improve the robustness of the algorithm, and the generated anchor box can screen more refined features earlier. Second, ResNet50-vd with the deformable convolution idea is selected as the backbone of the detection model, the feature pyramid network structure and the composition of the loss function are improved, and the feature learning ability of the model is enhanced to enable it to detect multiple scales of defects. Finally, pruning is performed on the basis of the trained model to reduce the number of model parameters so that it can be deployed in industrial scenarios with limited hardware conditions. Experimental results show that the proposed quality monitoring model can meet the requirements for detection speed and accuracy in actual production, providing a new concept for the deployment of deep learning models in the industrial field.},
keywords={Monitoring;Production;Feature extraction;Object detection;Kernel;Convolution;Quality assessment;Quality monitoring;PP-YOLO;pruning;deep learning},
doi={10.1109/ACCESS.2021.3085338},
ISSN={2169-3536},
month={},}
@ARTICLE{9894678,
author={De Capitani di sabrina Vimercati, Sabrina and Facchinetti, Dario and Foresti, Sara and Livraga, Giovanni and Oldani, Gianluca and Paraboschi, Stefano and Rossi, Matthew and Samarati, Pierangela},
journal={IEEE Transactions on Big Data},
title={Scalable Distributed Data Anonymization for Large Datasets},
year={2022},
volume={},
number={},
pages={1-14},
abstract={$\kappa $-Anonymity and $\ell $-diversity are two well-known privacy metrics that guarantee protection of the respondents of a dataset by obfuscating information that can disclose their identities and sensitive information. Existing solutions for enforcing them implicitly assume to operate in a centralized scenario, since they require complete visibility over the dataset to be anonymized, and can therefore have limited applicability in anonymizing large datasets. In this paper, we propose a solution that extends Mondrian (an efficient and effective approach designed for achieving $\kappa $-anonymity) for enforcing both $\kappa $-anonymity and $\ell $-diversity over large datasets in a distributed manner, leveraging the parallel computation of multiple workers. Our approach efficiently distributes the computation among the workers, without requiring visibility over the dataset in its entirety. Our data partitioning limits the need for workers to exchange data, so that each worker can independently anonymize a portion of the dataset. We implemented our approach providing parallel execution on a dynamically chosen number of workers. The experimental evaluation shows that our solution provides scalability, while not affecting the quality of the resulting anonymization.},
keywords={Data privacy;Information integrity;Information filtering;Europe;Soft sensors;Scalability;Big Data;Distributed data anonymization;Mondrian; $\kappa $ -Anonymity; $\ell $ -Diversity;Apache Spark},
doi={10.1109/TBDATA.2022.3207521},
ISSN={2332-7790},
month={},}
@ARTICLE{9211498,
author={Ebel, Patrick and Meraner, Andrea and Schmitt, Michael and Zhu, Xiao Xiang},
journal={IEEE Transactions on Geoscience and Remote Sensing},
title={Multisensor Data Fusion for Cloud Removal in Global and All-Season Sentinel-2 Imagery},
year={2021},
volume={59},
number={7},
pages={5866-5878},
abstract={The majority of optical observations acquired via spaceborne Earth imagery are affected by clouds. While there is numerous prior work on reconstructing cloud-covered information, previous studies are, oftentimes, confined to narrowly defined regions of interest, raising the question of whether an approach can generalize to a diverse set of observations acquired at variable cloud coverage or in different regions and seasons. We target the challenge of generalization by curating a large novel data set for training new cloud removal approaches and evaluate two recently proposed performance metrics of image quality and diversity. Our data set is the first publically available to contain a global sample of coregistered radar and optical observations, cloudy and cloud-free. Based on the observation that cloud coverage varies widely between clear skies and absolute coverage, we propose a novel model that can deal with either extreme and evaluate its performance on our proposed data set. Finally, we demonstrate the superiority of training models on real over synthetic data, underlining the need for a carefully curated data set of real observations. To facilitate future research, our data set is made available online.},
keywords={Clouds;Optical imaging;Cloud computing;Earth;Optical sensors;Data integration;Image reconstruction;Cloud removal;data fusion;deep learning;generative adversarial network (GAN);optical imagery;synthetic aperture radar (SAR)-optical},
doi={10.1109/TGRS.2020.3024744},
ISSN={1558-0644},
month={July},}
@ARTICLE{9420742,
author={Rathore, Shailendra and Park, Jong Hyuk and Chang, Hangbae},
journal={IEEE Access},
title={Deep Learning and Blockchain-Empowered Security Framework for Intelligent 5G-Enabled IoT},
year={2021},
volume={9},
number={},
pages={90075-90083},
abstract={Recently, many IoT applications, such as smart transportation, healthcare, and virtual and augmented reality experiences, have emerged with fifth-generation (5G) technology to enhance the Quality of Service (QoS) and user experience. The revolution of 5G-enabled IoT supports distinct attributes, including lower latency, higher system capacity, high data rate, and energy saving. However, such revolution also delivers considerable increment in data generation that further leads to a major requirement of intelligent and effective data analytic operation across the network. Furthermore, data growth gives rise to data security and privacy concerns, such as breach and loss of sensitive data. The conventional data analytic and security methods do not meet the requirement of 5G-enabled IoT including its unique characteristic of low latency and high throughput. In this paper, we propose a Deep Learning (DL) and blockchain-empowered security framework for intelligent 5G-enabled IoT that leverages DL competency for intelligent data analysis operation and blockchain for data security. The framework's hierarchical architecture wherein DL and blockchain operations emerge across the four layers of cloud, fog, edge, and user is presented. The framework is simulated and analyzed, employing various standard measures of latency, accuracy, and security to demonstrate its validity in practical applications.},
keywords={Security;Internet of Things;Data analysis;Blockchain;Reliability;5G mobile communication;Quality of service;Internet of Things;security attack detection;edge computing;fog computing;blockchain;software-defined networking},
doi={10.1109/ACCESS.2021.3077069},
ISSN={2169-3536},
month={},}
@ARTICLE{8845616,
author={Li, Zhi and Jin, Hai and Zou, Deqing and Yuan, Bin},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={Exploring New Opportunities to Defeat Low-Rate DDoS Attack in Container-Based Cloud Environment},
year={2020},
volume={31},
number={3},
pages={695-706},
abstract={DDoS attacks are rampant in cloud environments and continually evolve into more sophisticated and intelligent modalities, such as low-rate DDoS attacks. But meanwhile, the cloud environment is also developing in constant. Now container technology and microservice architecture are widely applied in cloud environment and compose container-based cloud environment. Comparing with traditional cloud environments, the container-based cloud environment is more lightweight in virtualization and more flexible in scaling service. Naturally, a question that arises is whether these new features of container-based cloud environment will bring new possibilities to defeat DDoS attacks. In this paper, we establish a mathematical model based on queueing theory to analyze the strengths and weaknesses of the container-based cloud environment in defeating low-rate DDoS attack. Based on this, we propose a dynamic DDoS mitigation strategy, which can dynamically regulate the number of container instances serving for different users and coordinate the resource allocation for these instances to maximize the quality of service. And extensive simulations and testbed-based experiments demonstrate our strategy can make the limited system resources be utilized sufficiently to maintain the quality of service acceptable and defeat DDoS attack effectively in the container-based cloud environment.},
keywords={Computer crime;Cloud computing;Containers;Mathematical model;Computer architecture;Resource management;Container;microservice;DDoS attack;mitigation;cloud computing},
doi={10.1109/TPDS.2019.2942591},
ISSN={1558-2183},
month={March},}
@ARTICLE{8666706,
author={Ge, Daohui and Song, Jianfeng and Qi, Yutao and Wang, Chongxiao and Miao, Qiguang},
journal={IEEE Access},
title={Self-Paced Dense Connectivity Learning for Visual Tracking},
year={2019},
volume={7},
number={},
pages={37181-37191},
abstract={When misalignment, deformation, and tracking failures occur, the appearance of the target tends to change significantly. How to effectively learn the change of target's appearance is an essential problem in visual tracking. Recently, most recent trackers based on convolutional neural networks update the tracker online to learn the change of target's appearance. These methods collect tracking results as online training samples. Thus, the reliability of training samples is very important for online updates. We propose a self-paced selection model, which integrates the self-paced learning model into the tracking framework for the goal of distinguishing the reliable samples from the tracking results. It estimates the reliability of the tracking results by the self-paced function. We design a method that adaptively calculates the value of the pace, which determines the number of samples selected. And this method is based on the number of tracking results. At the same time, the quality of the target's features plays a key role in the performance of the tracker. We employ dense connectivity learning to enhance the flow of information throughout the network, which makes the target's features represent better. The extensive experiments demonstrate that our self-paced dense connectivity learning tracker (SPDCT) performs favorably against the state-of-the-art trackers over four benchmark datasets.},
keywords={Target tracking;Training;Visualization;Reliability;Feature extraction;Semantics;Convolutional neural networks;Convolutional neural networks;densely connected learning;self-paced learning;online update},
doi={10.1109/ACCESS.2019.2904315},
ISSN={2169-3536},
month={},}
@ARTICLE{8755856,
author={Sun, Song and Zhao, Bo and Chen, Xin and Mateen, Muhammad and Wen, Junhao},
journal={IEEE Access},
title={Channel Attention Networks for Image Translation},
year={2019},
volume={7},
number={},
pages={95751-95761},
abstract={Existing image-to-image translation methods usually adopt an encoder-decoder structure to generate images. The encoder extracts the features of input images using a sequence of convolution layers until a bottleneck, and then, the intermediate features are decoded to the target image. However, the existence of bottleneck layer in such structure may lead to blurry and bad quality of the translated images, since different domain translations may be related to the global or local region in the input image or even in an abstract level. To prevent these problems, we propose the channel attention networks for image translation in this paper. It is a novel model that supports the multi-domain image-to-image translation using one single model. Conditioning on the target domain label, an auto-encoder-like network with multiple attention connections is trained to translate the input image into the target domain. The attention connections better shuttle the low-level information in the encoder to the decoder, which helps to preserve the structure. A multi-level attention mechanism is also designed in the proposed model to further improve the performance of our model. More specially, the feature maps in the encoder are first squeezed by average pooling and used to output a channel-wise attention mask. The attention mask softly determines which channels of the feature maps are translated and which channels are kept. By enforcing the model to learn a cyclic domain transformation during training, our model does not require paired training data, which greatly improves the versatility to different kinds of data. We experimentally demonstrated the effectiveness of our proposed model on the facial and clothing image translation tasks. The extensive ablations are also conducted to further validate the contribution of the proposed attention module used in our model.},
keywords={Computational modeling;Decoding;Data models;Task analysis;Adaptation models;Sun;Training data;Deep learning;computer vision;image generation;generative adversarial networks;image translation},
doi={10.1109/ACCESS.2019.2926882},
ISSN={2169-3536},
month={},}
@ARTICLE{8771231,
author={Niu, Yuzhen and Huang, Dong and Shi, Yiqing and Ke, Xiao},
journal={IEEE Access},
title={Siamese-Network-Based Learning to Rank for No-Reference 2D and 3D Image Quality Assessment},
year={2019},
volume={7},
number={},
pages={101583-101595},
abstract={2D image quality assessment (IQA) and stereoscopic 3D IQA are considered as two different tasks in the literature. In this paper, we present an index for both no-reference 2D and 3D IQA. We propose to transform the IQA task into a task of quality comparison between images. By generating image pairs, the amount of training data reaches the square of the original amount of data, effectively solving the lacking of training samples. We also propose a learning to rank model using Siamese convolutional neural networks (LRSN) for quality comparison. The presented LRSN has two branches that have the same structure, share weights with each other, and take two image patches as inputs. The goal of LRSN is learning to rank the quality scores between the two input image patches. The relative quality score of a test image is obtained by first comparing its image patches with many image patches of other images and counts the number of times that its image patches are ranked superior to other patches. The experimental results on three 2D (LIVE, CSIQ, and TID2013) and three 3D (LIVE 3D Phase-I, LIVE 3D Phase-II, and NBU) IQA databases demonstrate that the proposed LRSN model works well for both 2D and 3D IQA and outperforms the state-of-the-art no-reference 2D and 3D IQA metrics.},
keywords={Three-dimensional displays;Two dimensional displays;Measurement;Image quality;Feature extraction;Task analysis;Solid modeling;No-reference image quality assessment;stereoscopic image quality assessment;Siamese convolutional neural networks;learning to rank},
doi={10.1109/ACCESS.2019.2930707},
ISSN={2169-3536},
month={},}
@ARTICLE{9186113,
author={Wang, Xiaohua and Gong, Jianqiao and Hu, Min and Gu, Yu and Ren, Fuji},
journal={IEEE Access},
title={LAUN Improved StarGAN for Facial Emotion Recognition},
year={2020},
volume={8},
number={},
pages={161509-161518},
abstract={In the field of facial expression recognition, deep learning is extensively used. However, insufficient and unbalanced facial training data in available public databases is a major challenge for improving the expression recognition rate. Generative Adversarial Networks (GANs) can produce more one-to-one faces with different expressions, which can be used to enhance databases. StarGAN can perform one-to-many translations for multiple expressions. Compared with original GANs, StarGAN can increase the efficiency of sample generation. Nevertheless, there are some defects in essential areas of the generated face, such as the mouth and the fuzzy side face image generation. To address these limitations, we improved StarGAN to alleviate the defects of images generation by modifying the reconstruction loss and adding the Contextual loss. Meanwhile, we added the Attention U-Net to StarGAN's generator, replacing StarGAN's original generator. Therefore, we proposed the Contextual loss and Attention U-Net (LAUN) improved StarGAN. The U-shape structure and skip connection in Attention U-Net can effectively integrate the details and semantic features of images. The network's attention structure can pay attention to the essential areas of the human face. The experimental results demonstrate that the improved model can alleviate some flaws in the face generated by the original StarGAN. Therefore, it can generate person images with better quality with different poses and expressions. The experiments were conducted on the Karolinska Directed Emotional Faces database, and the accuracy of facial expression recognition is 95.97%, 2.19% higher than that by using StarGAN. Meanwhile, the experiments were carried out on the MMI Facial Expression Database, and the accuracy of expression is 98.30%, 1.21% higher than that by using StarGAN. Moreover, experiment results have better performance based on the LAUN improved StarGAN enhanced databases than those without enhancement.},
keywords={Face recognition;Gallium nitride;Generators;Feature extraction;Emotion recognition;Databases;Generative adversarial networks;Facial expression recognition;data enhancement;generative adversarial networks;self-attention},
doi={10.1109/ACCESS.2020.3021531},
ISSN={2169-3536},
month={},}
@ARTICLE{8320955,
author={Blanco, Raquel and Enríquez, José G. and Domínguez-Mayo, Francisco J. and Escalona, M. J. and Tuya, Javier},
journal={IEEE Transactions on Reliability},
title={Early Integration Testing for Entity Reconciliation in the Context of Heterogeneous Data Sources},
year={2018},
volume={67},
number={2},
pages={538-556},
abstract={Entity reconciliation (ER) aims to combine data from different sources for a unified vision. The management of large volumes of data has given rise to significant challenges to the ER problem due to facts such as data becoming more unstructured, unclean, and incomplete or the existence of many datasets that store information about the same topic. Testing the applications that implement the ER problem is crucial to ensure both the correctness of the reconciliation process and the quality of the reconciled data. This paper presents an approach based on model-driven engineering that allows the creation of test models for the early integration testing of ER applications, contributing in three main aspects: the description of the elements of the proposed framework, the definition of the testing model, and the validation of the proposal through two real-world case studies. This validation verifies that the early integration testing of the ER application is capable of detecting a series of deficiencies, which a priori are not known and that will help to improve the final result that the ER application offers.},
keywords={Testing;Erbium;Business;Big Data;Data models;Information and communication technology;Software;Early testing;entity reconciliation;heterogeneous data sources;model-driven engineering;software testing;specification-based testing},
doi={10.1109/TR.2018.2809866},
ISSN={1558-1721},
month={June},}
@ARTICLE{8869760,
author={Fan, Qilin and Li, Xiuhua and Wang, Sen and Fu, Shu and Zhang, Xu and Wang, Yueyang},
journal={IEEE Access},
title={NA-Caching: An Adaptive Content Management Approach Based on Deep Reinforcement Learning},
year={2019},
volume={7},
number={},
pages={152014-152022},
abstract={Video streaming is a dominant application over today’s Internet. The current mainstream video streaming solution is to utilize the services of a Content Delivery Network (CDN) provider. By replicating video content closer to the network edge, caching provides an effective mechanism for alleviating the demand for massive bandwidth for the Internet backbone. It reduces the network traffic and capital expense for streaming the video content, and in the meantime, enhance Internet’s Quality of Service (QoS). In this paper, we propose a neural adaptive caching approach, named NA-Caching, for helping cache learn to make caching decisions from its own experiences rather than a specific mathematical model, in a way similar to how a human being learns a new skill (e.g. cycling, swimming). NA-Caching leverages the benefits of the Recurrent Neural Network (RNN) as well as the Deep Reinforcement Learning (DRL) to maximize the cache efficiency by jointly learning request features, caching space dynamics and making decisions. Specifically, we utilize Gated Recurrent Unit (GRU) to characterize the evolving features of the dynamic requests and caching space. Moreover, the above GRU-based representation network is integrated into a Deep Q-Network (DQN) framework for making adaptive caching decisions online. To evaluate the performance of the proposed approach, we conduct extensive experiments on anonymized real-world traces from a video provider. The results demonstrate that our algorithm significantly outperform several candidate methods.},
keywords={Servers;Streaming media;Internet;Adaptive systems;Quality of service;Reinforcement learning;Recurrent neural networks;Content management;deep reinforcement learning;quality of service;content delivery network},
doi={10.1109/ACCESS.2019.2947460},
ISSN={2169-3536},
month={},}
@ARTICLE{9082679,
author={Xiao, Wei and Xu, Chuan and Liu, Hongling and Yang, Hong and Liu, Xiaobo},
journal={IEEE Access},
title={Short-Term Truckload Spot Rates’ Prediction in Consideration of Temporal and Between-Route Correlations},
year={2020},
volume={8},
number={},
pages={81173-81189},
abstract={Truckload spot rate (TSR), defined as a price offered on the spot to transport a certain cargo by using an entire truck on a target transportation line, usually price per kilometer-ton, is a key factor in shaping the freight market. In particular, the prediction of short-term TSR is of great importance to the daily operations of the trucking industry. However, existing predictive practices have been limited largely by the availability of multilateral information, such as detailed intraday TSR information. Fortunately, the emerging online freight exchange (OFEX) platforms provide unique opportunities to access and fuse more data for probing the trucking industry. As such, this paper aims to leverage the high-resolution trucking data from an OFEX platform to forecast short-term TSR. Specifically, a lagged coefficient weighted matrix-based multiple linear regression modeling (Lag-WMR) is proposed, and exogenous variables are selected by the light gradient boosting (LGB) method. This model simultaneously incorporates the dependency between historical and current TSR (temporal correlation) and correlations between the rates on alternative routes (between-route correlation). In addition, the effects of incorporating temporal and between-route correlations, time-lagged correlation and exogenous variable selection in modeling are emphasized and assessed through a case study on short-term TSR in Southwest China. The comparative results show that the proposed Lag-WMR model outperforms autoregressive integrated moving average (ARIMA) model and LGB in terms of model fitting and the quality and stability of predictions. Further research could focus on rates' standardization, to define a practical freight index for the trucking industry. Although our results are specific to the Chinese trucking market, the method of analysis serves as a general model for similar international studies.},
keywords={Predictive models;Correlation;Transportation;Load modeling;Forecasting;Data models;Industries;Freight transportation;truckload spot rates;lagged weighted matrix;short-term prediction;weighted multiple regression;trucking economy},
doi={10.1109/ACCESS.2020.2990751},
ISSN={2169-3536},
month={},}
@ARTICLE{8288619,
author={Akbar, Adnan and Kousiouris, George and Pervaiz, Haris and Sancho, Juan and Ta-Shma, Paula and Carrez, Francois and Moessner, Klaus},
journal={IEEE Access},
title={Real-Time Probabilistic Data Fusion for Large-Scale IoT Applications},
year={2018},
volume={6},
number={},
pages={10015-10027},
abstract={Internet of Things (IoT) data analytics is underpinning numerous applications, however, the task is still challenging predominantly due to heterogeneous IoT data streams, unreliable networks, and ever increasing size of the data. In this context, we propose a two-layer architecture for analyzing IoT data. The first layer provides a generic interface using a service oriented gateway to ingest data from multiple interfaces and IoT systems, store it in a scalable manner and analyze it in real-time to extract high-level events; whereas second layer is responsible for probabilistic fusion of these high-level events. In the second layer, we extend state-of-the-art event processing using Bayesian networks in order to take uncertainty into account while detecting complex events. We implement our proposed solution using open source components optimized for large-scale applications. We demonstrate our solution on real-world use-case in the domain of intelligent transportation system where we analyzed traffic, weather, and social media data streams from Madrid city in order to predict probability of congestion in real-time. The performance of the system is evaluated qualitatively using a web-interface where traffic administrators can provide the feedback about the quality of predictions and quantitatively using F-measure with an accuracy of over 80%.},
keywords={Real-time systems;Probabilistic logic;Uncertainty;Data mining;Meteorology;Bayes methods;Data analysis;Complex event processing;data analysis;internet of things;real-time systems;intelligent transportation systems},
doi={10.1109/ACCESS.2018.2804623},
ISSN={2169-3536},
month={},}
@ARTICLE{9729149,
author={Wu, Tianwei and An, Siguang and Han, Jianqiang and Shentu, Nanying},
journal={Journal of Systems Engineering and Electronics},
title={An ε-Domination based Two-Archive 2 Algorithm for Many-Objective Optimization},
year={2022},
volume={33},
number={1},
pages={156-169},
abstract={The two-archive 2 algorithm (Two_Arch2) is a many-objective evolutionary algorithm for balancing the convergence, diversity, and complexity using diversity archive (DA) and convergence archive (CA). However, the individuals in DA are selected based on the traditional Pareto dominance which decreases the selection pressure in the high-dimensional problems. The traditional algorithm even cannot converge due to the weak selection pressure. Meanwhile, Two_Arch2 adopts DA as the output of the algorithm which is hard to maintain diversity and coverage of the final solutions synchronously and increase the complexity of the algorithm. To increase the evolutionary pressure of the algorithm and improve distribution and convergence of the final solutions, an ε-domination based Two_Arch2 algorithm (ε-Two_Arch2) for many-objective problems (MaOPs) is proposed in this paper. In ε- Two_Arch2, to decrease the computational complexity and speed up the convergence, a novel evolutionary framework with a fast update strategy is proposed; to increase the selection pressure, ε-domination is assigned to update the individuals in DA; to guarantee the uniform distribution of the solution, a boundary protection strategy based on I ε+ indicator is designated as two steps selection strategies to update individuals in CA. To evaluate the performance of the proposed algorithm, a series of benchmark functions with different numbers of objectives is solved. The results demonstrate that the proposed method is competitive with the state-of-the-art multi-objective evolutionary algorithms and the efficiency of the algorithm is significantly improved compared with Two_Arch2.},
keywords={Sociology;Evolutionary computation;Benchmark testing;Systems engineering and theory;Resource management;Statistics;Computational complexity;many-objective optimization;ε-domination;boundary protection strategy;two-archive algorithm},
doi={10.23919/JSEE.2022.000016},
ISSN={1004-4132},
month={February},}
@ARTICLE{8434286,
author={Li, Shaoyong and Luo, Lei and Liu, Yaping and Zhang, Yaoxue},
journal={IEEE Access},
title={Extend Capability of Low-End Android Devices by Scheduling Apps Between Local and Cloud},
year={2018},
volume={6},
number={},
pages={45740-45754},
abstract={In this paper, we propose a multi-layer mobile application (app) scheduling method to extend the capability of low-end Android devices. With a quantitative analysis, we find that the increase of installed apps will negatively affect quality of experience (QoE) of the user, e.g., the action response time of a mobile device, by producing more periodically or irregularly background tasks. On the other hand, the user tends to install more apps than needed in case they could play a role someday, as indicated by the consumer app usage statistics. When the storage is running out, being forced to choose an app to uninstall due to space budget is a painful experience for the user. This contradiction is intensified for low-end devices due to limited resources. We try to reduce this dilemma by a multi-layer app scheduling (MAS) schema, along with a cloud service. For the first layer, we utilize the “freeze”feature of Android to prevent non-essential background activities. For the second layer, it is a network scheduler, which automatically schedules the available apps, together with their data, between local and cloud according to user's personal policy generated by big data analysis. By dynamically scheduling the apps among three states, QoE of a low-end Android device is improved. At the same time, with the help of an app state recovery mechanism, the user can directly access a large number of apps provided by the cloud with consistent app view. Experimental results on a low-end smartphone, i.e., Samsung Galaxy ON5, and a smart watch based on Newton2_Plus wearable development board show the benefits of the proposed MAS schema.},
keywords={Quality of experience;Androids;Humanoid robots;Performance evaluation;Smart phones;Resource management;Smart devices;App scheduling;low-end device;mobile device;Android},
doi={10.1109/ACCESS.2018.2865177},
ISSN={2169-3536},
month={},}
@ARTICLE{8477007,
author={Meng, Shunmei and Wang, Huihui and Li, Qianmu and Luo, Yun and Dou, Wanchun and Wan, Shaohua},
journal={IEEE Access},
title={Spatial-Temporal Aware Intelligent Service Recommendation Method Based on Distributed Tensor factorization for Big Data Applications},
year={2018},
volume={6},
number={},
pages={59462-59474},
abstract={With the dramatic growth of public cloud offerings and heterogeneous data information, how to discover potentially valuable information from big history behavior data and design intelligent recommendation techniques has become more and more important. Due to the dynamics of cloud environment, both user behaviors and QoS (Quality of Service) performance of cloud services are sensitive to contextual information, such as time and location. However, the consideration of time and location information brings the increase in the order of rating matrix and the data sparsity problem. In view of these challenges, we propose a spatial-temporal aware intelligent service recommendation method based on distributed tensor factorization to address the above problems. First, the time and location information are introduced into the recommendation models by distinguishing time-sensitive QoS metrics and region-sensitive QoS metrics from stable QoS metrics. To deal with the sparse rating data, time slots and regions are clustered respectively. Then, a high-order tensor factorization technique is applied to mine the latent factors among users, services, time information, and location information. Moreover, to improve the scalability of our recommendation models in big data environment, a fast distributed asynchronous SGD (Stochastic Gradient Descent) mechanism is employed to get a good balance between the convergence speed and prediction accuracy. Finally, experiments based on both real-world data set and big synthetic data set are conducted to validate the effectiveness and scalability of our proposal. The experimental results show that our proposal achieves a good balance between the recommendation accuracy and scalability.},
keywords={Quality of service;Cloud computing;Tensile stress;Measurement;Recommender systems;Scalability;Big Data;Big data;FDAsy-SGD;recommendation;spatial;temporal;tensor factorization},
doi={10.1109/ACCESS.2018.2872351},
ISSN={2169-3536},
month={},}
@ARTICLE{9026896,
author={Sun, Chuan and Li, Hui and Li, Xiuhua and Wen, Junhao and Xiong, Qingyu and Zhou, Wei},
journal={IEEE Access},
title={Convergence of Recommender Systems and Edge Computing: A Comprehensive Survey},
year={2020},
volume={8},
number={},
pages={47118-47132},
abstract={Under the explosive growth of information available on the Web, recommender systems have been used as an effective technology to filter useless information and attempt to recommend the most useful items. The proliferation of smart phones, smart wearable devices and other Internet of Thing (IoT) devices has gradually driven many novel emerging services which are latency-sensitive and computation-intensive with a higher quality-of-service. Under such circumstances, the data sources contain four key characteristics (i.e., sparsity, heterogeneity, mobility, volatility). The conventional recommender systems based on cloud computing are incapable of digging the information of user demands. Mobile edge computing is a novel computing paradigm via pushing computation/storage resource from the remote cloud servers to the network edge servers to provide more intelligent and personalized service. This paper comprehensively reviews the state of the art literature on the convergence of recommender systems and edge computing, and identify the future directions along this dimension. This paper can provide an array of new perspectives on the convergence for researchers, practitioners, and tap into the richness of this interdisciplinary research area.},
keywords={Recommender systems;Servers;Edge computing;Distributed databases;Quality of service;Cloud computing;Convergence;Recommender systems;edge computing;the IoT;intelligent service},
doi={10.1109/ACCESS.2020.2978896},
ISSN={2169-3536},
month={},}
@ARTICLE{7762116,
author={Chen, Xuhong and Liu, Shanyun and Lu, Jiaxun and Fan, Pingyi and Letaief, Khaled Ben},
journal={IEEE Access},
title={Smart Channel Sounder for 5G IoT: From Wireless Big Data to Active Communication},
year={2016},
volume={4},
number={},
pages={8888-8899},
abstract={Internet-of-Things (IoT) will connect billions of smart devices and generate inundant data through prominent solutions, such as machine type communication. The Third Generation Partnership Project has launched the corresponding standards for multiple heterogeneous wireless smart devices in the long term evolution (LTE)/LTE-advanced. In the forthcoming years, the valuable information hidden in the deluge of data will be extracted and utilized in every field to improve quality and efficiency. However, the bottleneck of realizing this magnificent vista of future intelligent lives lies in how to satisfy the practical demands to transmit huge data volume through efficient wireless communication in diverse scenarios. Herein, multi-scenario wireless communication triggers critical problems in wireless channel modeling and soundings for 5G IoT, which by far, are understudied. In this paper, we introduce a general wireless channel model and its multiple up-to-date corresponding channel sounding methods for future 5G IoT green wireless communication. Through adopting the perspective of wireless big data excavation, the smart channel sounder transforms the traditional passive wireless communication scheme into an active expectation-guaranteed wireless communication scheme, which helps achieve efficient and green communication. To demonstrate the validity and efficiency of this smart sounder scheme, we make a compatible prototype testified in multiple scenarios. The multiple real-scenario experiments demonstrate that the smart sounder can function effectively, especially in those scenarios where traditional channel state information is not available or imperfect.},
keywords={5G mobile comunication;Big data;Green communication;Internet of Things;Wireless communication;Smart devices;Channel state estimation;5G IoT;channel sounding;wireless big data;active estimation;green communication},
doi={10.1109/ACCESS.2016.2628820},
ISSN={2169-3536},
month={},}
@ARTICLE{8691437,
author={Cheng, Tian and Wen, Junhao and Xiong, Qingyu and Zeng, Jun and Zhou, Wei and Cai, Xueyuan},
journal={IEEE Access},
title={Personalized Web Service Recommendation Based on QoS Prediction and Hierarchical Tensor Decomposition},
year={2019},
volume={7},
number={},
pages={62221-62230},
abstract={Web service recommendation based on the quality of service (QoS) is important for users to find the exact Web service among many functionally similar Web services. Although service recommendations have been recently studied, the performance of the existing ones is unsatisfactory because: 1) the current QoS predicting algorithms still experience data sparsity and cannot predict the QoS values accurately and 2) the previous approaches fail to consider the QoS variance according to the users and services' locations carefully. A Web service recommendation method based on the QoS prediction and hierarchical tensor decomposition is proposed in this paper. The method is called QoSHTD that is based on location clustering and hierarchical tensor decomposition. First, the users and services of the QoSHTD cluster into several local groups based on their location and models local and global triadic tensors for the user-service-time relationship. The hierarchical tensor decomposition is then performed on the local and global triadic tensors. Finally, the predicted QoS value through local and global tensor decomposition is combined as the missing QoS values. The comprehensive experiment shows that the proposed method achieves a high prediction accuracy and recommending quality of Web service, and can partially address data sparsity.},
keywords={Quality of service;Web services;Prediction algorithms;Clustering algorithms;Collaboration;Predictive models;QoS;service computing;tensor decomposition},
doi={10.1109/ACCESS.2019.2909548},
ISSN={2169-3536},
month={},}
@ARTICLE{8392677,
author={Soh, Ping-Wei and Chang, Jia-Wei and Huang, Jen-Wei},
journal={IEEE Access},
title={Adaptive Deep Learning-Based Air Quality Prediction Model Using the Most Relevant Spatial-Temporal Relations},
year={2018},
volume={6},
number={},
pages={38186-38199},
abstract={Air pollution has become an extremely serious problem, with particulate matter having a significantly greater impact on human health than other contaminants. The small diameter of fine particulate matter (PM2.5) allows it to penetrate deep into the alveoli as far as the bronchioles, interfering with a gas exchange within the lungs. Long-term exposure to particulate matter has been shown to cause the cardiovascular disease, respiratory disease, and increase the risk of lung cancers. Therefore, forecasting air quality has also become important to help guide individual actions. This paper aims to forecast air quality for up to 48 h using a combination of multiple neural networks, including an artificial neural network, a convolutional neural network, and a long-short-term memory to extract spatial-temporal relations. The proposed predictive model considers various meteorology data from the previous few hours as well as information related to the elevation space to extract terrain impact on air quality. The model includes trends from multiple locations, extracted from correlations between adjacent locations, and among similar locations in the temporal domain. Experiments employing Taiwan and Beijing data sets show that the proposed model achieves excellent performance and outperforms current state-of-the-art methods.},
keywords={Air quality;Atmospheric modeling;Predictive models;Neural networks;Wind forecasting;Lung;Data mining;Dynamic time warping(DTW);convolutional neural network(CNN);long-short-term memory(LSTM);spatio-temporal analysis;big data;air quality forecast},
doi={10.1109/ACCESS.2018.2849820},
ISSN={2169-3536},
month={},}
@ARTICLE{8515201,
author={Jia, Huizhen and Zhang, Lu and Wang, Tonghan},
journal={IEEE Access},
title={Contrast and Visual Saliency Similarity-Induced Index for Assessing Image Quality},
year={2018},
volume={6},
number={},
pages={65885-65893},
abstract={Image quality that is consistent with human opinion is assessed by a perceptual image quality assessment (IQA) that defines/utilizes a computational model. A good model should take effectiveness and efficiency into consideration, but most of the previously proposed IQA models do not simultaneously consider these factors. Therefore, this paper attempts to develop an effective and efficient IQA metric. Contrast is an inherent visual attribute that indicates image quality, and visual saliency (VS) is a quality that attracts the attention of human beings. The proposed model utilized these two features to characterize the image quality. After obtaining the local contrast quality map and the global VS quality map, we added the weighted standard deviation of the previous two quality maps together to yield the final quality score. The experimental results for three benchmark databases (LIVE, TID2008, and CSIQ) demonstrated that our model performs the best in terms of a correlation with the human judgment of visual quality. Furthermore, compared with competing IQA models, this proposed model is more efficient. The MATLAB source code of the proposed method is public available online at http://www.scholat.com/vpost.html?pid=98172..},
keywords={Measurement;Visualization;Image quality;Computational modeling;Mathematical model;Indexes;Adaptation models;Full reference;image quality assessment;local contrast;summation of deviation-based pooling strategy;visual saliency},
doi={10.1109/ACCESS.2018.2878739},
ISSN={2169-3536},
month={},}
@ARTICLE{8835021,
author={Sun, Na and Lu, Yong and Cao, Yongcun},
journal={IEEE Access},
title={Career Age-Aware Scientific Collaborator Recommendation in Scholarly Big Data},
year={2019},
volume={7},
number={},
pages={136036-136045},
abstract={Seeking a collaborator is one of the important academic activities of scholars because the right collaborators will help improve the quality of scholars’ research and accelerate their research process. Therefore, it is becoming more and more important to recommend scientific collaborators based on big scholarly data. However, previous works mainly consider the research topic as the key academic factor, whereas many scholars’ demographic characteristics such as career age, gender, etc are overlooked. It has been studied that scientific collaboration patterns may vary with scholars’ career ages. It is not surprising that scholars at different career ages may have different collaboration strategies. To this end, we aim to design a scientific collaboration recommendation model that is sensitive to scholars’ career age. For this purpose, we design a career age-aware scientific collaboration model. The model is mainly consisted of three parts, including authorship extraction from the digital libraries, topic extraction based on publication titles/abstract, and career age-aware random walk for measuring scholar similarity. Experimental results on two real-world datasets demonstrate that our proposed model can achieve the best performance by comparison with six baseline methods in terms of precision and recall.},
keywords={Collaboration;Engineering profession;Social networking (online);XML;Libraries;Big Data;Scientific collaboration;career age;collaborator recommendation},
doi={10.1109/ACCESS.2019.2941022},
ISSN={2169-3536},
month={},}
@ARTICLE{8421568,
author={Xu, Jia and Bao, Weiwei and Gu, Huayue and Xu, Lijie and Jiang, Guoping},
journal={IEEE Access},
title={Improving Both Quantity and Quality: Incentive Mechanism for Social Mobile Crowdsensing Architecture},
year={2018},
volume={6},
number={},
pages={44992-45003},
abstract={Mobile crowdsensing has emerged as an efficient paradigm for performing large-scale sensing tasks. Improving both the quantity and quality of users is still the pivotal problem for mobile crowdsensing system. This paper gives a comprehensive solution to improve the quantity and quality of users simultaneously through the social mobile crowdsensing architecture. To incentive the users based on the novel architecture, we first propose a universal initial diffuser selection algorithm to accommodate two widely studied diffusion models and, then a lightweight, multi-metric comprehensive, and parameter-free user quality evaluation method is presented. Finally, we propose a reverse auction to optimize the new criterion, which takes both social cost and user quality into consideration. Through both rigorous theoretical analysis and extensive simulations, we demonstrate that the proposed incentive mechanisms achieve computational efficiency, individual rationality, truthfulness, and guaranteed approximation. Meanwhile, the proposed incentive mechanisms show prominent advantage in total unit quality cost and running time.},
keywords={Task analysis;Sensors;Social network services;Computer architecture;Monitoring;Computational modeling;Crowdsourcing;Influence diffusion;crowdsensing;incentive mechanism;social network},
doi={10.1109/ACCESS.2018.2860900},
ISSN={2169-3536},
month={},}
@ARTICLE{8259243,
author={Chen, Min and Herrera, Francisco and Hwang, Kai},
journal={IEEE Access},
title={Cognitive Computing: Architecture, Technologies and Intelligent Applications},
year={2018},
volume={6},
number={},
pages={19774-19783},
abstract={With the development of network-enabled sensors and artificial intelligence algorithms, various human-centered smart systems are proposed to provide services with higher quality, such as smart healthcare, affective interaction, and autonomous driving. Considering cognitive computing is an indispensable technology to develop these smart systems, this paper proposes human-centered computing assisted by cognitive computing and cloud computing. First, we provide a comprehensive investigation of cognitive computing, including its evolution from knowledge discovery, cognitive science, and big data. Then, the system architecture of cognitive computing is proposed, which consists of three critical technologies, i.e., networking (e.g., Internet of Things), analytics (e.g., reinforcement learning and deep learning), and cloud computing. Finally, it describes the representative applications of human-centered cognitive computing, including robot technology, emotional communication system, and medical cognitive system.},
keywords={Cognitive systems;Big Data;Cognition;Cloud computing;Cognitive science;Cyberspace;Human computer interaction;Cognitive computing;big data analysis;Internet of Things;cloud computing},
doi={10.1109/ACCESS.2018.2791469},
ISSN={2169-3536},
month={},}
@ARTICLE{8778714,
author={Song, Xiaotao and Sun, Hailong and Wang, Xu and Yan, Jiafei},
journal={IEEE Access},
title={A Survey of Automatic Generation of Source Code Comments: Algorithms and Techniques},
year={2019},
volume={7},
number={},
pages={111411-111428},
abstract={As an integral part of source code files, code comments help improve program readability and comprehension. However, developers sometimes do not comment their program code adequately due to the incurred extra efforts, lack of relevant knowledge, unawareness of the importance of code commenting or some other factors. As a result, code comments can be inadequate, absent or even mismatched with source code, which affects the understanding, reusing and the maintenance of software. To solve these problems of code comments, researchers have been concerned with generating code comments automatically. In this work, we aim at conducting a survey of automatic code commenting researches. First, we generally analyze the challenges and research framework of automatic generation of program comments. Second, we present the classification of representative algorithms, the design principles, strengths and weaknesses of each category of algorithms. Meanwhile, we also provide an overview of the quality assessment of the generated comments. Finally, we summarize some future directions for advancing the techniques of automatic generation of code comments and the quality assessment of comments.},
keywords={Quality assessment;Natural languages;Data models;Software algorithms;Software;Task analysis;Information retrieval;Code comment;deep learning;information retrieval;machine learning;program annotation},
doi={10.1109/ACCESS.2019.2931579},
ISSN={2169-3536},
month={},}
@ARTICLE{9056512,
author={Li, Gongli and Hou, Yingying and Zhu, Junzhe},
journal={IEEE Access},
title={An Efficient and Fast VLIW Compression Scheme for Stream Processor},
year={2020},
volume={8},
number={},
pages={224817-224824},
abstract={Stream processor has been widely used in multimedia processing because of the high performance gained by parallelism. In order to achieve higher parallelism, the stream processor employs large width structure of VLIW (very long instruction word, VLIW) and multiple parallelizable instructions are organized into one VLIW. Because the width of VLIW is fixed, there are a large number of empty operations (non-operation, NOP) filled in VLIW, which results in serious code size expansion problem. Aiming at this issue, the horizontal code compression and vertical code compression methods are applied on the VLIW of stream processor respectively. First the VLIW is divided into several subfields according to the logic characteristics of VLIW instruction, then the horizontal code compression scheme which based on Huffman coding is applied on each subfield and this method can achieve approximately 78% code size reduction on average. However, the extra-long time required to decode the compressed VLIW before instruction execution may cause system performance penalty. In order to reduce the decompression time consumption, the vertical compression scheme is proposed. The vertical compression can reduce the code size nearly 70% by deleting the NOPs of VLIW in vertical direction. Furthermore the VLIW after vertical compression can be executed directly without decompression operation by using banked instruction memory. Specifically, the vertical compression can compress stream processor VLIW code size significantly and without any negative influence on performance.},
keywords={VLIW;Huffman coding;Image coding;Streaming media;Parallel processing;Decoding;Stream processor;Huffman coding;horizontal compression;vertical compression;compression ratio},
doi={10.1109/ACCESS.2020.2985501},
ISSN={2169-3536},
month={},}
@ARTICLE{9295320,
author={Zhang, Xin and Cheng, Zhi},
journal={IEEE Access},
title={Improving Query Quality for Transductive Learning in Learning to Rank},
year={2020},
volume={8},
number={},
pages={226188-226198},
abstract={In traditional transductive learning, all queries are used in learning to rank in order to generate pseudo-labels when sufficient training data are not available. However, low quality queries may affect retrieval performance in transductive learning. We thus think that it is important to improve the quality of queries in transductive learning to train an effective ranking model. By using a small number of reliable samples and data close to the boundaries of classification, we propose building a query quality estimator by establishing a relationship between the benefits of good retrieval performance and features of the normalized query commitment that influence query quality. In our proposed transduction model, all queries available are filtered by the proposed query quality estimator and only high quality queries that enhance the effectiveness of retrieval such that they yield performance-related benefits, are used to generate pseudo-labels for learning to rank. Queries that can degrade performance benefits are discarded while creating the pseudo-labels. Pseudo-labels aggregated by high quality queries in transductive learning are then leveraged in learning to rank scenarios without sufficient training data. The results of extensive experiments on the standard LETOR 4.0 dataset showed that our proposed method can outperform strong baselines and the average normalized discounted cumulative gain is enhanced up to 7.77% in some case.},
keywords={Training data;Reliability;Semisupervised learning;Feature extraction;Information retrieval;Training;Supervised learning;Transductive learning;query quality;retrieval performance;learning to rank},
doi={10.1109/ACCESS.2020.3043459},
ISSN={2169-3536},
month={},}
@ARTICLE{8552406,
author={Xu, Xin and Wang, Yunsheng and Yu, Shujiang},
journal={IEEE Access},
title={Teaching Performance Evaluation in Smart Campus},
year={2018},
volume={6},
number={},
pages={77754-77766},
abstract={With the rapid development of modern teaching technology, the construction of smart campus has become the focus of modern college education reform. The application of technologies, such as the Internet of Things and big data, plays an important role in improving the teaching environment of colleges and universities, improving the utilization of teaching resources, and the flexibility of education. As an important part of campus activities, teaching performance evaluation scientifically and effectively utilizes teaching information and teacher and student interaction information to evaluate teachers' teaching performance, which helps to motivate teachers' work enthusiasm, improve teaching quality, and enhance school core competitiveness. This paper analyzes the salient features of smart campus from the perspectives of technology, business, and construction mode, and proposes a smart campus architecture model. According to the research content of teaching performance evaluation, the framework model of smart campus education data collection and storage platform is established, which provides a reference model for the construction of smart campus in colleges and universities. The evaluation of teaching performance in smart campus first analyzes the shortcomings of traditional evaluation methods and proposes the necessity of combining teaching performance evaluation with modern technology. Second, six principal components were determined using the PCA algorithm. Then, use the AHP to calculate the weights of each layer of the indicator set, avoiding the decision errors caused by subjective factors. Finally, the gray correlation degree is used to improve the TOPSIS algorithm for multi-objective decision analysis. The evaluation results of the AHP-TOPSIS teaching performance model are consistent with the actual situation. The application of the smart campus education data platform combined with the AHP and the gray correlation improvement TOPSIS algorithm is more targeted to the teacher's teaching performance evaluation and provides a new evaluation method for scientific performance evaluation, and avoid the problem of strong subjectivity of traditional teaching performance evaluation.},
keywords={Education;Performance evaluation;Big Data;Data models;Computer architecture;Sensors;Internet of Things;Smart campus;teaching performance evaluation;educational big Data;analytic hierarchy process;grey correlation degree;TOPSIS algorithm},
doi={10.1109/ACCESS.2018.2884022},
ISSN={2169-3536},
month={},}
@ARTICLE{9229062,
author={Frias, Zoraida and Mendo, Luis and Oughton, Edward J.},
journal={IEEE Access},
title={How Does Spectrum Affect Mobile Network Deployments? Empirical Analysis Using Crowdsourced Big Data},
year={2020},
volume={8},
number={},
pages={190812-190821},
abstract={Despite the growing trend towards the use of big data methodologies, there is still limited application of such techniques to understand how spectrum is used in mobile networks. In this paper we analyse how low (<; 1 GHz) and high (>1 GHz) frequency spectrum is used in 4G networks in urban areas, in relation to eNodeB density, available bandwidth, Reference Signal Received Power (RSRP) and Reference Signal Received Quality (RSRQ). We present a method to analyse the strategies used by Mobile Network Operators (MNOs) to deal with traffic congestion, and the degree to which they must densify their networks depending on their spectrum portfolio. Using crowdsourced data from 2017 from a popular mobile app, we apply this method to Greater London. We find that the fraction of sites that fully use all available bands to the MNO range from 2% to 20%. Additionally, MNOs with large bandwidth use 42% fewer sites on average in dense urban environments. This difference decreases in suburban areas to 23% fewer sites. The lowest frequencies in each eNodeB tend to exhibit lower RSRP values, as they are often used to serve cell-edge users. These frequencies also show lower RSRQ values because of higher interference caused by neighbouring cells. Similarly, large (high frequency) bandwidth improves RSRQ as it allows for fewer users per MHz, which reduces interference and enables larger cell sizes. We conclude that in dense urban environments, the available bandwidth, rather than propagation properties, determines the preferred band for network deployment by MNOs.},
keywords={Bandwidth;Long Term Evolution;Urban areas;Area measurement;Sociology;Statistics;Resource management;4G mobile communication;radio spectrum management;crowdsourcing},
doi={10.1109/ACCESS.2020.3031963},
ISSN={2169-3536},
month={},}
@ARTICLE{7974743,
author={El Fazziki, Abdelaziz and Benslimane, Djamal and Sadiq, Abderrahmane and Ouarzazi, Jamal and Sadgal, Mohamed},
journal={IEEE Access},
title={An Agent Based Traffic Regulation System for the Roadside Air Quality Control},
year={2017},
volume={5},
number={},
pages={13192-13201},
abstract={This paper describes an on-road air quality monitoring and control approach by proposing an agent-based system for modeling the urban road network infrastructure, establishing the real-time and predicted air pollution indexes in different road segments and generating recommendations and regulation proposals for road users. This can help by reducing vehicle emissions in the most polluted road sections, optimizing the pollution levels while maximizing the vehicle flow. For this, we use data sets gathered from a set of air quality monitoring stations, embedded low-cost e-participatory pollution sensors, contextual data, and the road network available data. These data are used in the air quality indexes calculation and then the generation of a dynamic traffic network. This network is represented by a weighted graph in which the edges weights evolve according to the pollution indexes. In this paper, we propose to combine the benefits of agent technology with both machine learning and big data tools. An artificial neural networks model and the Dijkstra algorithm are used for air quality prediction and the least polluted path finding in the road network. All data processing tasks are performed over a Hadoop-based framework: HBase and MapReduce.},
keywords={Air quality;Roads;Pollution;Monitoring;Tools;Sensors;Urban areas;Air quality management;crowd-sourcing;Dijkstra algorithm;mobile sensors;pollution prediction;traffic regulation},
doi={10.1109/ACCESS.2017.2725984},
ISSN={2169-3536},
month={},}
@ARTICLE{9502731,
author={Yao, Dunhong and Deng, Xiaowu},
journal={IEEE Access},
title={A Course Teacher Recommendation Algorithm Based on Improved Latent Factor Model and PersonalRank},
year={2021},
volume={9},
number={},
pages={108614-108627},
abstract={To scientifically and accurately recommend suitable teachers for university courses and improve teaching quality, designing an effective recommendation algorithm is necessary. Therefore, we construct quantitative models of teacher characteristics, course characteristics, and teaching evaluations under the theories and methods of education and build a sparse experimental data matrix based on the quantified data. On this basis, we propose a teacher recommendation algorithm (PRLFM) based on the improved latent factor model (LFM) and the improved PersonalRank algorithm. Firstly, the improved LFM is used to predict the evaluation scores of those courses that teachers have not taught. The scores which are higher than the specified threshold are used to fill the corresponding missing items in the sparse matrix to reduce the matrix's sparsity. Then, the bipartite graph model based on the teacher set and course set is constructed according to the filled experimental data matrix. The weight of edges in the bipartite graph is replaced by the teacher and course's evaluation score multiplied by the course difficulty, which reflects the correlation between course and evaluation score. Next, an improved probability transition matrix based on the bipartite graph is constructed. The access probability in the matrix is replaced by the node's out degree's reciprocal multiplied by the edge's weight. The correlation degree between the course and all teachers is quickly calculated using the matrix algorithm of PersonalRank. Finally, a teacher recommendation model is constructed to realize teachers' top-N recommendation by combining the correlation degree with teachers' characteristics. Experiments show that the PRLFM algorithm can effectively improve the accuracy of prediction and top-N recommendation. It solves the problem of lack of scientific basis in recommending suitable teachers for university courses and improving the teaching quality.},
keywords={Education;Prediction algorithms;Matrix decomposition;Correlation;Sparse matrices;Bipartite graph;Data models;LFM;PersonalRank;PRLFM;teacher recommendation;teaching quality},
doi={10.1109/ACCESS.2021.3101469},
ISSN={2169-3536},
month={},}
@ARTICLE{8979341,
author={Liu, Juntao and Yu, Chuang and Hu, Zhuhua and Zhao, Yaochi and Bai, Yong and Xie, Mingshan and Luo, Jian},
journal={IEEE Access},
title={Accurate Prediction Scheme of Water Quality in Smart Mariculture With Deep Bi-S-SRU Learning Network},
year={2020},
volume={8},
number={},
pages={24784-24798},
abstract={In the smart mariculture, the timely and accurate predictions of water quality can help farmers take countermeasures before the ecological environment deteriorates seriously. However, the openness of the mariculture environment makes the variation of water quality nonlinear, dynamic and complex. Traditional methods face challenges in prediction accuracy and generalization performance. To address these problems, an accurate water quality prediction scheme is proposed for pH, water temperature and dissolved oxygen. First, we construct a new huge raw data set collected in time series consisting of 23,204 groups of data. Then, the water quality parameters are preprocessed for data cleaning successively through threshold processing, mean proximity method, wavelet filter, and improved smoothing method. Next, the correlation between the water quality to be predicted and other dynamics parameters is revealed by the Pearson correlation coefficient method. Meanwhile, the data for training is weighted by the discovered correlation coefficients. Finally, by adding a backward SRU node to the training sequence, which can be integrated into the future context information, the deep Bi-S-SRU (Bi-directional Stacked Simple Recurrent Unit) learning network is proposed. After training, the prediction model can be obtained. The experimental results demonstrate that our proposed prediction method achieve higher prediction accuracy than the method based on RNN (Recurrent Neural Network) or LSTM (Long Short-Term Memory) with similar or less time computing complexity. In our experiments, the proposed method takes 12.5ms to predict data on average, and the prediction accuracy can reach 94.42% in the next 3~8 days.},
keywords={Water quality;Correlation;Predictive models;Interpolation;Smoothing methods;Time series analysis;Data models;Smart mariculture;precision agriculture;water quality prediction;SRU;deep learning},
doi={10.1109/ACCESS.2020.2971253},
ISSN={2169-3536},
month={},}
@ARTICLE{8660441,
author={Guo, Wenzhong and Zhu, Weiping and Yu, Zhiyong and Wang, Jiangtao and Guo, Bin},
journal={IEEE Access},
title={A Survey of Task Allocation: Contrastive Perspectives From Wireless Sensor Networks and Mobile Crowdsensing},
year={2019},
volume={7},
number={},
pages={78406-78420},
abstract={Wireless sensor networks (WSNs) and mobile crowdsensing (MCS) are two important paradigms in urban dynamic sensing. In both sensing paradigms, task allocation is a significant problem, which may affect the completion quality of sensing tasks. In this paper, we give a survey of task allocation in WSNs and MCS from the contrastive perspectives in terms of data quality and sensing cost, which help to better understand related objectives and strategies. We first analyze the different characteristics of two sensing paradigms, which may lead to difference in task allocation issues or strategies. Then, we present some common issues in task allocation with objectives in data quality and sensing cost. Furthermore, we provide reviews of unique task allocation issues in MCS according to its new characteristics. Finally, we identify some potential opportunities for the future research.},
keywords={Sensors;Task analysis;Wireless sensor networks;Resource management;Data integrity;Wireless communication;Mobile handsets;Mobile crowdsensing (MCS);task allocation;wireless sensor networks (WSNs)},
doi={10.1109/ACCESS.2019.2896226},
ISSN={2169-3536},
month={},}
@ARTICLE{8778793,
author={Zhang, Siyang and Xinhua, E. and Pan, Tian},
journal={IEEE Access},
title={A Multi-Level Author Name Disambiguation Algorithm},
year={2019},
volume={7},
number={},
pages={104250-104257},
abstract={With the rapid development of information technology, the name ambiguity problem has become one of the primary issues in the fields of information retrieval, data mining, and scientific measurement. Name disambiguation is used to promote computer technology and big data information, which maps virtual relational networks to real social networks to solve the problem that the same name points to multiple entities. At present many literature search platforms launched their respective scholar system, name ambiguity problem will inevitably affect the precision of other information calculations, reduce the credibility of the system, and affect the information quality and content quality. Most work deals with this issue by using graph theory and clustering. However, the name disambiguation problem is still not well resolved. In this paper, we propose a multi-level name disambiguation algorithm. This algorithm is mainly based on the unsupervised algorithm, which combines hierarchical agglomerative clustering (HAC) and graph theory for disambiguating. The experimental results show that the proposed solution achieves clearly better performance (+17 ~ 25% in terms of F1-Measure) than several methods, including HAC and Graph.},
keywords={Organizations;Clustering algorithms;Corporate acquisitions;Feature extraction;Graph theory;Libraries;Data mining;Associative processing;clustering algorithms;data handling;informatics},
doi={10.1109/ACCESS.2019.2931592},
ISSN={2169-3536},
month={},}
@ARTICLE{9715073,
author={Rudnitckaia, Julia and Venkatachalam, Hari Santhosh and Essmann, Roland and Hruška, Tomáš and Colombo, Armando Walter},
journal={IEEE Access},
title={Screening Process Mining and Value Stream Techniques on Industrial Manufacturing Processes: Process Modelling and Bottleneck Analysis},
year={2022},
volume={10},
number={},
pages={24203-24214},
abstract={One major result of the Industrial Digitalization is the access to a large set of digitalized data and information, i.e. Big Data. The market of analytic tools offers a huge variety of algorithms and software to exploit big datasets. Implementing their advantages into one approach brings better results and empower possibilities for process analysis. Its application in the manufacturing industry requires a high level of effort and remains to be challenging due to product complexity, human-centric processes, and data quality. In this manuscript, the authors combine process mining and value streams methods for analyzing the data from the information management system, applying the approach to the data delivered by one specific manufacturing system. The manufacturing process to be examined is the process of assembling gas meters in the manufacture. This specific and important part of the whole supply-chain process was taken as suitable for the study due to almost full-automated line with data about each process activity of the value-stream in the information system. The paper applies process mining algorithms in discovering a descriptive process model that plays the main role as a basis for further analysis. At the same time, modern techniques of the bottleneck analysis are described, and two new comprehensible methods of bottlenecks detection (TimeLag and Confidence intervals methods), as well as their advantages, will be discussed. Achieved results can be subsequently used for other sources of big data and industrial-compliant Information Management Systems.},
keywords={Data mining;Manufacturing;Information management;Production;Manufacturing processes;Companies;Analytical models;Bottleneck analysis;manufacturing process;process mining;process modelling;information management system;value stream},
doi={10.1109/ACCESS.2022.3152211},
ISSN={2169-3536},
month={},}
@ARTICLE{8918337,
author={Chao, Kuan-Hao and Hsiao, Yi-Wen and Lee, Yi-Fang and Lee, Chien-Yueh and Lai, Liang-Chuan and Tsai, Mong-Hsun and Lu, Tzu-Pin and Chuang, Eric Y.},
journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics},
title={RNASeqR: An R Package for Automated Two-Group RNA-Seq Analysis Workflow},
year={2021},
volume={18},
number={5},
pages={2023-2031},
abstract={RNA-Seq analysis has revolutionized researchers’ understanding of the transcriptome in biological research. Assessing the differences in transcriptomic profiles between tissue samples or patient groups enables researchers to explore the underlying biological impact of transcription. RNA-Seq analysis requires multiple processing steps and huge computational capabilities. There are many well-developed R packages for individual steps; however, there are few R/Bioconductor packages that integrate existing software tools into a comprehensive RNA-Seq analysis and provide fundamental end-to-end results in pure R environment so that researchers can quickly and easily get fundamental information in big sequencing data. To address this need, we have developed the open source R/Bioconductor package, RNASeqR. It allows users to run an automated RNA-Seq analysis with only six steps, producing essential tabular and graphical results for further biological interpretation. The features of RNASeqR include: six-step analysis, comprehensive visualization, background execution version, and the integration of both R and command-line software. RNASeqR provides fast, light-weight, and easy-to-run RNA-Seq analysis pipeline in pure R environment. It allows users to efficiently utilize popular software tools, including both R/Bioconductor and command-line tools, without predefining the resources or environments. RNASeqR is freely available for Linux and macOS operating systems from Bioconductor (https://bioconductor.org/packages/release/bioc/html/RNASeqR.html).},
keywords={Bioinformatics;Genomics;Quality assessment;Pipelines;Electronic mail;RNA;RNA-Seq;analysis workflow;pipeline;R;bioconductor;transcriptome assembly;differential expression analysis;gene expression;statistical analysis;visualization},
doi={10.1109/TCBB.2019.2956708},
ISSN={1557-9964},
month={Sep.},}
@ARTICLE{8952697,
author={Li, Jing and Jia, Ruiqi and Zhang, Ke and Yang, Zifan and Liu, Haixiao and Zhu, Xin and Li, Xueyan},
journal={IEEE Access},
title={Research on Construction of Crude Set Model of Critical Fault Information for Bus Based on CAN-BUS Data},
year={2020},
volume={8},
number={},
pages={14875-14892},
abstract={Under the high load, high frequency and high strength operating environment, the frequent occurrence of vehicle fault gradually attracts the attention of the society. The real-time monitoring and data recording function of vehicle-mounted equipment provides data support for vehicle status assessment and fault warning. In this paper, the real-time data collected by CAN-BUS system of Beijing Bus Group are preprocessed and discretized. On the basis of the traditional rough set theory, a new coding method is set up, and the dependency between conditional attributes and decision attributes is set as an adaptive function, which is reduced by genetic algorithm and cellular genetic algorithm respectively. The calculation results show that the key fault information of public transport vehicles is instrumental speed, oil pressure, percentage of torque, timing engine speed, and coolant temperature. By comparing the results of reduction, it is found that the cellular genetic algorithm has higher applicability than the genetic algorithm in terms of algorithm efficiency, stability, and convergence quality. Although the genetic algorithm attribute reduction is slightly better than the cellular genetic algorithm attribute reduction in the rule matching, the cellular genetic algorithm has a better ability to excavate information within the acceptable compatibility range. Finally, the selected key factors will be deployed on the Beijing Bus Group's big data platform and displayed in real time. The conclusion of this paper enriches the theory of bus engine fault warning and establishes an engine failure warning system, which can effectively reduce the failure rate of bus vehicles and reduce the maintenance cost expenditure. It has certain guiding significance for the bus operation work of Beijing Bus Group.},
keywords={Fault diagnosis;Rough sets;Genetic algorithms;Maintenance engineering;Real-time systems;Engines;Data models;Rough set;genetic algorithms;cellular genetic algorithm;bus;fault diagnosis},
doi={10.1109/ACCESS.2020.2964791},
ISSN={2169-3536},
month={},}
@ARTICLE{8488459,
author={Rahman, Md. Abdur and Hassanain, Elham and Rashid, Md. Mamunur and Barnes, Stuart J. and Hossain, M. Shamim},
journal={IEEE Access},
title={Spatial Blockchain-Based Secure Mass Screening Framework for Children With Dyslexia},
year={2018},
volume={6},
number={},
pages={61876-61885},
abstract={In this paper, we present a novel method, process, and system for calculating dyslexic symptoms, generating metric data for an individual user, community, or group in general. We present a mobile multimedia Internet of Things (IoT)-based environment that can capture multimodal smartphone or tab-based user interaction data during dyslexia testing and share it via a mobile edge network, which employs auto-grading algorithms to find dyslexia symptoms. In addition to algorithm-based auto-grading, the captured mobile multimedia payload is stored in a decentralized repository that can be shared with a medical practitioner for replay and further manual analysis purposes. Since the framework is language-independent and based on Blockchain and a decentralized big data repository, dyslexic patterns and a massive amount of captured multimedia IoT test data can be shared for further clinical research, statistical analysis, and quality assurance. Notwithstanding, our proposed Blockchain and off-chain-based decentralized and secure dyslexia data storage, management, and sharing framework will allow security, anonymity, and multimodal visualization of the captured test data for mobile users. This paper presents the detailed design, implementation, and test results, which demonstrate the strong potential for wider adoption of the dyslexia mobile health management globally.},
keywords={Big Data;Writing;Stakeholders;Testing;Multimedia systems;Blockchain;dyslexia;auto-grading;mass screening;mobile multimedia health},
doi={10.1109/ACCESS.2018.2875242},
ISSN={2169-3536},
month={},}
@ARTICLE{9005249,
author={Zhang, Xin and Sun, Pengcheng and Xu, Jiping and Wang, Xiaoyi and Yu, Jiabin and Zhao, Zhiyao and Dong, Yunfeng},
journal={IEEE Access},
title={Blockchain-Based Safety Management System for the Grain Supply Chain},
year={2020},
volume={8},
number={},
pages={36398-36410},
abstract={In recent years, various food-safety issues have aroused public concern regarding safety in the food supply chain. Since grains are closely linked to human life and health, it is necessary to effectively manage information in the grain supply chain. The grain supply chain is characterized by a long life cycle, complex links, various hazards, and heterogeneous information sources. Problems with traditional traceability systems include easy data tampering, difficult hazardous-material information management, the “information isolated island” problem, and low traceability efficiency in the whole supply chain. Blockchain is a distributed computing paradigm characterized by decentralization, network-wide recording, security, and reliability. As such, it can reduce administrative costs and improve the efficiency of information management. Based on literature research and a field investigation of wheat-processing enterprises in Shandong Province, We analyze the operation process of grain supply chain. This study, therefore, proposed a new system architecture in the entire grain supply chain based on blockchain technology and designed a multimode storage mechanism that combines chain storage. This prototype system was tested and verified using actual cases and application scenarios. Compared to traditional systems, the proposed system is characterized by data security and reliability, information interconnection and intercommunication, real-time sharing of hazardous-material information, and dynamic and credible whole-process tracing. As such, this system is highly significant and has reference value for guaranteeing food quality and safety-process traceability.},
keywords={Supply chains;Blockchain;Information management;Hazards;Reliability;Blockchain;food safety;grain supply chain;hyperledger;smart contract},
doi={10.1109/ACCESS.2020.2975415},
ISSN={2169-3536},
month={},}
@ARTICLE{8567886,
author={Chen, Wenbin and Shao, Yanling and Wang, Yanling and Zhang, Quan and Liu, Yi and Yao, Linhong and Chen, Yan and Yang, Guanru and Gui, Zhiguo},
journal={IEEE Access},
title={A Novel Total Variation Model for Low-Dose CT Image Denoising},
year={2018},
volume={6},
number={},
pages={78892-78903},
abstract={Low-dose computed tomography (LDCT) images are polluted by mottle noise and streak artifacts. To improve LDCT images quality, this paper proposes a novel total variation (NTV) model. A weighted coefficient of the regularization term of NTV model is constructed by standard deviation, gray-level probability and gradient magnitude to smooth LDCT images adaptively, since the standard deviation and the gray-level probability of detail region are higher than that of the noisy background, and the gradient magnitude of edges is higher than that of the noisy background. Besides, to preserve details and edges effectively, the fidelity term of the proposed NTV model is constructed by the block-matching 3d filter because it performs well in details and edges preservation. The experiments are performed on the computer simulated phantom and the actual phantom. Compared with several other competitive methods, both subjective visual effect and objective evaluation criteria show that the proposed NTV model can improve LDCT images quality more effectively such as noise and artifacts suppression, details, and edges preservation.},
keywords={Adaptation models;Filtering algorithms;TV;Image edge detection;Mathematical model;Computational modeling;Standards;Low-dose CT;image denoising;total variation;weighted coefficient;edges and details preservation},
doi={10.1109/ACCESS.2018.2885514},
ISSN={2169-3536},
month={},}
@ARTICLE{8936407,
author={Ortiz, Guadalupe and Caravaca, José Antonio and García-de-Prado, Alfonso and Chavez de la O, Fràncisco and Boubeta-Puig, Juan},
journal={IEEE Access},
title={Real-Time Context-Aware Microservice Architecture for Predictive Analytics and Smart Decision-Making},
year={2019},
volume={7},
number={},
pages={183177-183194},
abstract={The impressive evolution of the Internet of Things and the great amount of data flowing through the systems provide us with an inspiring scenario for Big Data analytics and advantageous real-time context-aware predictions and smart decision-making. However, this requires a scalable system for constant streaming processing, also provided with the ability of decision-making and action taking based on the performed predictions. This paper aims at proposing a scalable architecture to provide real-time context-aware actions based on predictive streaming processing of data as an evolution of a previously provided event-driven service-oriented architecture which already permitted the context-aware detection and notification of relevant data. For this purpose, we have defined and implemented a microservice-based architecture which provides real-time context-aware actions based on predictive streaming processing of data. As a result, our architecture has been enhanced twofold: on the one hand, the architecture has been supplied with reliable predictions through the use of predictive analytics and complex event processing techniques, which permit the notification of relevant context-aware information ahead of time. On the other, it has been refactored towards a microservice architecture pattern, highly improving its maintenance and evolution. The architecture performance has been evaluated with an air quality case study.},
keywords={Computer architecture;Decision making;Real-time systems;Big Data;Context-aware services;Predictive analytics;Service-oriented architecture;Context awareness;context-aware services;service-oriented architecture;decision making;microservice architecture},
doi={10.1109/ACCESS.2019.2960516},
ISSN={2169-3536},
month={},}
@ARTICLE{8787230,
author={Ye, Zhonglin and Zhao, Haixing and Zhang, Ke and Wang, Zhaoyang and Zhu, Yu},
journal={Big Data Mining and Analytics},
title={Network representation based on the joint learning of three feature views},
year={2019},
volume={2},
number={4},
pages={248-260},
abstract={Network representation learning plays an important role in the field of network data mining. By embedding network structures and other features into the representation vector space of low dimensions, network representation learning algorithms can provide high-quality feature input for subsequent tasks, such as network link prediction, network vertex classification, and network visualization. The existing network representation learning algorithms can be trained based on the structural features, vertex texts, vertex tags, community information, etc. However, there exists a lack of algorithm of using the future evolution results of the networks to guide the network representation learning. Therefore, this paper aims at modeling the future network evolution results of the networks based on the link prediction algorithm, introducing the future link probabilities between vertices without edges into the network representation learning tasks. In order to make the network representation vectors contain more feature factors, the text features of the vertices are also embedded into the network representation vectors. Based on the above two optimization approaches, we propose a novel network representation learning algorithm, Network Representation learning algorithm based on the joint optimization of Three Features (TFNR). Based on Inductive Matrix Completion (IMC), TFNR algorithm introduces the future probabilities between vertices without edges and text features into the procedure of modeling network structures, which can avoid the problem of the network structure sparse. Experimental results show that the proposed TFNR algorithm performs well in network vertex classification and visualization tasks on three real citation network datasets.},
keywords={Prediction algorithms;Task analysis;Optimization;Probability;Neural networks;Matrix decomposition;Sparse matrices;network representation learning;network feature mining;embedding learning;link prediction;matrix factorization},
doi={10.26599/BDMA.2019.9020009},
ISSN={2096-0654},
month={Dec},}
@ARTICLE{8336850,
author={Shi, Meihui and Shen, Derong and Nie, Tiezheng and Kou, Yue and Yu, Ge},
journal={Big Data Mining and Analytics},
title={HPPQ: A parallel package queries processing approach for large-scale data},
year={2018},
volume={1},
number={2},
pages={146-159},
abstract={A lot of scholars have focused on developing effective techniques for package queries, and a lot of excellent approaches have been proposed. Unfortunately, most of the existing methods focus on a small volume of data. The rapid increase in data volume means that traditional methods of package queries find it difficult to meet the increasing requirements. To solve this problem, a novel optimization method of package queries (HPPQ) is proposed in this paper. First, the data is preprocessed into regions. Data preprocessing segments the dataset into multiple subsets and the centroid of the subsets is used for package queries, this effectively reduces the volume of candidate results. Furthermore, an efficient heuristic algorithm is proposed (namely IPOL-HS) based on the preprocessing results. This improves the quality of the candidate results in the iterative stage and improves the convergence rate of the heuristic algorithm. Finally, a strategy called HPR is proposed, which relies on a greedy algorithm and parallel processing to accelerate the rate of query. The experimental results show that our method can significantly reduce time consumption compared with existing methods.},
keywords={Heuristic algorithms;Query processing;Dispersion;Parallel processing;Data preprocessing;Convergence;Acceleration;package queries;heuristic algorithms;parallel processing;opposition-based learning},
doi={10.26599/BDMA.2018.9020014},
ISSN={2096-0654},
month={June},}
@ARTICLE{9770057,
author={Wang, Lei and Liu, Yi and Wu, Rui and Liu, Yuhang and Yan, Rongbiao and Ren, Shilei and Gui, Zhiguo},
journal={IEEE Access},
title={Image Processing for Low-Dose CT via Novel Anisotropic Fourth-Order Diffusion Model},
year={2022},
volume={10},
number={},
pages={50114-50124},
abstract={Low-dose CT images contain severe mottle noise and streak artifacts, which seriously affect the physician’s diagnosis of the disease. Hence, in this paper, we propose a novel anisotropic fourth-order diffusion model for low-dose CT image processing. The proposed diffusion model uses both image gradient magnitude and weighted residual local energy to determine the diffusion coefficient. Gradient magnitude is used to detect the image edges, while the weighted residual local energy preserves textures and details in the image. In addition, the fidelity term is introduced into the diffusion model to avoid excessive smoothing and weaken the blocky effects. Experimental results show that when compared with the anisotropic fourth-order diffusion model, the proposed algorithm protects the texture details and suppresses the blocky effects. In comparison with other state-of-the-art algorithms, the proposed model effectively suppresses mottle noise and streak artifacts while simultaneously improving the low-dose CT image quality.},
keywords={Computed tomography;Image edge detection;Noise reduction;Mathematical models;Laplace equations;Image reconstruction;Detectors;Low-dose computed tomography;anisotropic diffusion;fourth-order PDEs;residual local energy},
doi={10.1109/ACCESS.2022.3172975},
ISSN={2169-3536},
month={},}
@ARTICLE{7809136,
author={Huda, Shamsul and Yearwood, John and Jelinek, Herbert F. and Hassan, Mohammad Mehedi and Fortino, Giancarlo and Buckland, Michael},
journal={IEEE Access},
title={A Hybrid Feature Selection With Ensemble Classification for Imbalanced Healthcare Data: A Case Study for Brain Tumor Diagnosis},
year={2016},
volume={4},
number={},
pages={9145-9154},
abstract={Electronic health records (EHRs) are providing increased access to healthcare data that can be made available for advanced data analysis. This can be used by the healthcare professionals to make a more informed decision providing improved quality of care. However, due to the inherent heterogeneous and imbalanced characteristics of medical data from EHRs, data analysis task faces a big challenge. In this paper, we address the challenges of imbalanced medical data about a brain tumor diagnosis problem. Morphometric analysis of histopathological images is rapidly emerging as a valuable diagnostic tool for neuropathology. Oligodendroglioma is one type of brain tumor that has a good response to treatment provided the tumor subtype is recognized accurately. The genetic variant, 1p-/19q-, has recently been found to have high chemosensitivity, and has morphological attributes that may lend it to automated image analysis and histological processing and diagnosis. This paper aims to achieve a fast, affordable, and objective diagnosis of this genetic variant of oligodendroglioma with a novel data mining approach combining a feature selection and ensemble-based classification. In this paper, 63 instances of brain tumor with oligodendroglioma are obtained due to prevalence and incidence of the tumor variant. In order to minimize the effect of an imbalanced healthcare data set, a global optimization-based hybrid wrapper-filter feature selection with ensemble classification is applied. The experiment results show that the proposed approach outperforms the standard techniques used in brain tumor classification problem to overcome the imbalanced characteristics of medical data.},
keywords={Tumors;Feature extraction;Data mining;Medical diagnostic imaging;Artificial neural networks;Brain tumor;morphological features;ANNIGMA;MRMR;feature selection;classification},
doi={10.1109/ACCESS.2016.2647238},
ISSN={2169-3536},
month={},}
@ARTICLE{8768306,
author={Zhang, Hui and Cui, Houdun and Shi, Baiying},
journal={IEEE Access},
title={A Data-Driven Analysis for Operational Vehicle Performance of Public Transport Network},
year={2019},
volume={7},
number={},
pages={96404-96413},
abstract={The operational stability of public transport is significant for both passengers and operators. Affected by many stochastic factors, such as traffic congestion, traffic signals and passenger demand at stops, the headway always become uneven, which greatly reduces the service quality. This paper used the big global positioning systems (GPS) trajectory data to analyze the headway stability of bus system from the perspective of network. A statistical method is proposed to analyze the operational vehicle performance of bus network. The GPS trajectory data of Jinan is used to test the model. The results show that the average dwell time, actual headway, and headway stability index of stations follow lognormal distributions with obvious right tails. Moreover, the seriously unstable situations do not appear in the peak hours, but in the time periods before peak hours. In addition, the stations with most unstable headway are located in the suburbs and the fringe area of downtown. The outcomes suggest that operators should pay more attention to the suburbs and the fringe area of downtown, and the time periods before peak hours to efficiently improve the service quality.},
keywords={Global Positioning System;Stability criteria;Trajectory;Synchronization;Network topology;Public transport network;stability of headway;GPS trajectory data;data-driven analysis},
doi={10.1109/ACCESS.2019.2930279},
ISSN={2169-3536},
month={},}
@ARTICLE{9154564,
author={Chkirbene, Zina and Hadjidj, Rachid and Foufou, Sebti and Hamila, Ridha},
journal={IEEE/ACM Transactions on Networking},
title={LaScaDa: A Novel Scalable Topology for Data Center Network},
year={2020},
volume={28},
number={5},
pages={2051-2064},
abstract={The growth of cloud-based services is mainly supported by the core networking infrastructures of large-scale data centers, while the scalability of these services is influenced by the performance and dependability characteristics of data centers. Hence, the data center network must be agile and reconfigurable in order to respond quickly to the ever-changing application demands and service requirements. The network must also be able to interconnect the big number of nodes, and provide an efficient and fault-tolerant routing service to upper-layer applications. In response to these challenges, the research community began exploring novel interconnect topologies, namely: Flecube, DCell, Ficonn, HyperFlaNet and BCube. However, these topologies either scale too fast (grows exponentially in size), or too slow, and therefore suffer from performance bottlenecks. In this paper, we propose a novel data center topology called LaScaDa (Layered Scalable Data Center) as a new solution for building scalable and cost-effective data center networking infrastructures. The proposed topology organizes nodes in clusters of similar structure, then interconnect these clusters in a well-crafted pattern and system of coordinates for nodes to reduce the number of redundant connections between clusters, while maximizing connectivity. LaScaDa forwards packets between nodes using a new hierarchical row-based routing algorithm. The algorithm constructs the route to the source based on the modular difference between the source and destination coordinates. Furthermore, the proposed topology interconnects a large number of nodes using a small node degree. This strategy increases the number of directly connected clusters and avoids redundant connections. As a result, we get a good quality of nodes in terms of average path length (APL), bisection bandwidth, and aggregated bottleneck throughput. Experimental results show that LaScaDa has better performance than DCell, BCube, and HyperBcube in terms of scalability, while providing a good quality of service.},
keywords={Topology;Network topology;Data centers;Routing;Scalability;Fault tolerance;Fault tolerant systems;Data center network;network topology;average path length;bisection bandwidth},
doi={10.1109/TNET.2020.3008512},
ISSN={1558-2566},
month={Oct},}
@ARTICLE{9200319,
author={López-Cuadrado, José Luis and González-Carrasco, Israel and Leonardo López-Hernández, Jesús and Martínez-Fernández, Paloma and Martínez-Fernández, José Luis},
journal={IEEE Access},
title={Automatic Learning Framework for Pharmaceutical Record Matching},
year={2020},
volume={8},
number={},
pages={171754-171770},
abstract={Pharmaceutical manufacturers need to analyse a vast number of products in their daily activities. Many times, the same product can be registered several times by different systems using different attributes, and these companies require accurate and quality information regarding their products since these products are drugs. The central hypothesis of this research work is that machine learning can be applied to this domain to efficiently merge different data sources and match the records related to the same product. No human is able to do this in a reasonable way because the number of records to be matched is extremely high. This article presents a framework for pharmaceutical record matching based on machine learning techniques in a big data environment. The proposed framework aims to explode the well-known rules for the matching of records from different databases for training machine learning models. Then the trained models are evaluated by predicting matches with records that do not follow these known rules. Finally, the production environment is simulated by generating a huge amount of combinations of records and predicting the matches. The obtained results show that, despite the good results obtained with the training datasets, in the production environment, the average accuracy of the best model is around 85%. That shows that matches which do not follow the known rules can be predicted and, considering that there is not a human way to process this amount of data, the results are promising.},
keywords={Pharmaceuticals;Machine learning;Support vector machines;Companies;Training;Semantics;Data integration;Big data;data integration;machine learning;pattern detection;medicine},
doi={10.1109/ACCESS.2020.3024558},
ISSN={2169-3536},
month={},}
@ARTICLE{9371683,
author={Liang, Wuchao and Li, Wenning and Feng, Lili},
journal={IEEE Access},
title={Information Security Monitoring and Management Method Based on Big Data in the Internet of Things Environment},
year={2021},
volume={9},
number={},
pages={39798-39812},
abstract={As an important part of the new generation of information technology, the Internet of Things (IoT), with its ubiquitous connection and service characteristics, has penetrated into various fields of application and played an important role. In this paper, based on the study of the basic technology of the environmental Internet of Things, combined with the service-oriented technology architecture SOA, J2EE, multi-level system architecture MVC, real-time database and other technologies and project practice experience, summarized and proposed a kind of environmental quality monitoring integrated management platform design and implementation feasibility scheme. Firstly, the background of the era of big data is described in detail, the urgency and necessity of information security monitoring under the background of big data is clarified, and the three elements of information security monitoring mechanism, namely network monitoring personnel, environment and technology, are proposed, and the three elements as the starting point to establish the information security monitoring mechanism; Starting from the relevant monitoring strategies and safety monitoring technologies, this paper explains the basic principles of constructing the evaluation index system, and establishes the evaluation index system according to the key influencing factors of enterprise information security level in the environment of big data. AHP fuzzy comprehensive evaluation method is chosen on the basis of analyzing various comprehensive evaluation methods, and the weight of each evaluation index is determined and the comprehensive evaluation model is constructed. The establishment of information security monitoring and evaluation system, the use of information security monitoring and evaluation system, for information security monitoring work to provide reference standards. Finally, on the basis of the foregoing, relevant strategies for information security monitoring are proposed, and necessary suggestions are provided for information security work.},
keywords={Monitoring;Information security;Business;Pollution;Internet of Things;Big Data;Information security;big data;evaluation model;monitoring mechanism;Internet of Things},
doi={10.1109/ACCESS.2021.3064350},
ISSN={2169-3536},
month={},}
@ARTICLE{9309228,
author={He, Mu and Shu, Jian},
journal={IEEE Access},
title={A Link Quality Estimation Method for Wireless Sensor Networks Based on Deep Forest},
year={2021},
volume={9},
number={},
pages={2564-2575},
abstract={In wireless sensor networks, sensor nodes, the miniature embedded devices, have limitation of energy, storage, computing, and etc. One of the tasks of the nodes is to use their limited resources to complete work efficiently. Choosing high quality link communication can effectively save energy. In this paper, we propose a link quality estimation model that is based on deep forest. To avoid a noise sample becoming a center point in the clustering, we use an improved K-medoids algorithm based on step increasing and optimizing medoids (INCK) when dividing the link quality grades. During the sample preprocessing stage, the Pauta criterion is used to delete the noise link samples, and we fill the mean value of each grade into the missing values. The feature extraction performance of deep forest is improved by combining the stratified sampling to change the unbalance distribution of link quality samples. And then the Stratified Sampling Cascade Forest link quality estimation (SCForest-LQE) is constructed by combining stratified sampling with cascade forest. The experiments are conducted in three real application scenarios. Compared with the existing six link quality estimation models, SCForest-LQE has better estimation performance and stability.},
keywords={Estimation;Signal to noise ratio;Forestry;Heuristic algorithms;Wireless sensor networks;Clustering algorithms;Wireless sensor networks;link quality estimation;deep forest;stratified sampling},
doi={10.1109/ACCESS.2020.3047648},
ISSN={2169-3536},
month={},}
@ARTICLE{9099795,
author={Sun, Lanfang and Jiang, Xin and Ren, Huixia and Guo, Yi},
journal={IEEE Access},
title={Edge-Cloud Computing and Artificial Intelligence in Internet of Medical Things: Architecture, Technology and Application},
year={2020},
volume={8},
number={},
pages={101079-101092},
abstract={With the booming development of medical informatization and the ubiquitous connections in the fifth generation mobile communication technology (5G) era, the heterogeneity and explosive growth of medical data have brought huge challenges to data access, security and privacy, as well as information processing in Internet of Medical Things (IoMT). This article provides a comprehensive review of how to realize the timely processing and analysis of medical big data and the sinking of high-quality medical resources under the constraints of the existing medical environment and medical-related equipment. We mainly focus on the advantages brought by the cloud computing, edge computing and artificial intelligence technologies to the IoMT. We also explore how to rationalize the use of medical resources and the security and privacy of medical data, so that high-quality medical services can be provided to patients. Finally, we discuss the current challenges and possible future research directions in the edge-cloud computing and artificial intelligence related IoMT.},
keywords={Cloud computing;Computer architecture;Medical diagnostic imaging;Edge computing;Medical services;Radiofrequency identification;Internet of medical things (IoMT);deep learning;edge of computing;computation offloading},
doi={10.1109/ACCESS.2020.2997831},
ISSN={2169-3536},
month={},}
@ARTICLE{8360420,
author={Cristóbal, Teresa and Padrón, Gabino and Quesada-Arencibia, Alexis and Alayón, Francisco and García, Carmelo R.},
journal={IEEE Access},
title={Systematic Approach to Analyze Travel Time in Road-Based Mass Transit Systems Based on Data Mining},
year={2018},
volume={6},
number={},
pages={32861-32873},
abstract={Road-based mass transit systems are an effective means to combat the negative impact of transport that is based on private vehicles. Providing quality of service in this type of transit system is a priority for transport authorities. In these systems, travel time (TT) is a basic factor in quality of service. This paper presents a methodology, based on data mining, for analyzing TT in a mass transit system that is planned by timetable. The objective of the methodology is to understand the behavior patterns of TTs on the different routes of the transport network, as well as the factors that influence these patterns. To achieve this objective, the methodology uses clustering techniques to process the GPS data provided by the vehicles of the public transport fleet. The results that were obtained when implementing this methodology in a public transport company are presented as a use case, demonstrating its validity.},
keywords={Quality of service;Global Positioning System;Roads;Data mining;Neural networks;Companies;Reliability;Road-based mass transit systems;travel time;intelligent transportation systems;data mining;pattern clustering;global positioning system},
doi={10.1109/ACCESS.2018.2837498},
ISSN={2169-3536},
month={},}
@ARTICLE{9416689,
author={Wang, Lifang and Zhang, Jin and Liu, Yang and Mi, Jia and Zhang, Jiong},
journal={IEEE Access},
title={Multimodal Medical Image Fusion Based on Gabor Representation Combination of Multi-CNN and Fuzzy Neural Network},
year={2021},
volume={9},
number={},
pages={67634-67647},
abstract={Aiming at the current multimodal medical image fusion methods that cannot fully characterize the complex textures and edge information of the lesion in the fused image, a method based on Gabor representation of multi-CNN combination and fuzzy neural network is proposed. This method first filters the CT and MR image sets through a set of Gabor filter banks with different proportions and directions to obtain different Gabor representations pairs of CT and MR, each pair of different Gabor representations is used to train the corresponding CNN to generate a G- CNN and multiple G- CNN form a G- CNN group, namely G- CNNs; then when fusing CT and MR images, CT and MR are represented by Gabors to get Gabor representation pairs firstly, each Gabor representation pair is put into the corresponding trained G- CNN for preliminary fusion, then use the fuzzy neural network to fuse multiple outputs of the G- CNNs to obtain the final fused image. Compared with the nine recent state-of-the-art multimodal fusion methods, the average mutual information of the three groups of experiments has increased by 13%, 10.3%, and 10% respectively; the average spatial frequency has increased by 10.3%, 20%, and 10.7%; the average standard deviation has increased respectively 12.4%, 10.8%, 14.4%; the average edge retention information increased by 33.5%, 22%, and 43%. The experimental results show that the proposed fusion method is significantly better than the other comparative fusion methods in objective evaluation and visual quality. It has the best performance on the four indicators and can better integrate the rich texture features and the clear edge information of the source images into the final fused image, which improves the quality of multimodal medical image fusion, and effectively assists doctors in disease diagnosis.},
keywords={Medical diagnostic imaging;Computed tomography;Gabor filters;Image edge detection;Feature extraction;Filter banks;Medical image fusion;G-CNNs;Gabor representation;convolutional neural network;fuzzy neural network},
doi={10.1109/ACCESS.2021.3075953},
ISSN={2169-3536},
month={},}
@ARTICLE{8787738,
author={Huang, Yanrong and Chen, Min},
journal={IEEE Access},
title={Improve Reputation Evaluation of Crowdsourcing Participants Using Multidimensional Index and Machine Learning Techniques},
year={2019},
volume={7},
number={},
pages={118055-118067},
abstract={Building a scientific and reasonable reputation evaluation mechanism for crowdsourcing participants is an effective way to solve the problem of transaction fraud, to establish the trust of traders and ensure the quality of task completion. Under the big data environment, machine learning methods have been applied in the domain of e-commerce of physical goods to improve the traditional reputation evaluation methods, and achieved good results. However, few studies have applied machine learning methods to crowdsourcing, a form of service e-commerce, to evaluate the reputation of participants. This paper proposes a reputation evaluation model (i.e. LDA-RF) for crowdsourcing participants of Random Forest based on Linear Discriminant Analysis. The model consists of five steps: firstly, building a multidimensional reputation evaluation index system for crowdsourcing participants, collecting real data sets, and preprocessing data; secondly, data dimensionality reduction methods, including Linear Discriminant Analysis, Principal Component Analysis, Mean Impact Value method and ReliefF feature selection method, are used to eliminate redundant variables; thirdly, data normalization; fourthly, with selected feature subset, five machine learning techniques, Random Forest, Decision Tree, Back propagation Neural Network, Radial Basis Function Neural Network and Support Vector Machine are used to train the model; Fifthly, the validity of the model is tested by four evaluation measures: 10 fold cross validation, confusion matrix, Kruskal-wallis test and dispersion degree. The results show that the LDA-RF model on accuracy, F1-measure, generalization ability and robustness are better than those of other models, and it has better performance and effectiveness. This study represents a new contribution to establish reputation evaluation of crowdsourcing participants under big data environment.},
keywords={Crowdsourcing;Task analysis;Indexes;Machine learning;Data models;Analytical models;Game theory;Crowdsourcing participants;reputation evaluation;machine learning;random forest;data dimension reduction},
doi={10.1109/ACCESS.2019.2933147},
ISSN={2169-3536},
month={},}
@ARTICLE{9143114,
author={Liu, Yangxiaoyue and Yang, Yaping and Jing, Wenlong},
journal={IEEE Access},
title={Potential Applicability of SMAP in ECV Soil Moisture Gap-Filling: A Case Study in Europe},
year={2020},
volume={8},
number={},
pages={133114-133127},
abstract={The Essential Climate Variable (ECV) soil moisture (SM) datasets, originated from the European Space Agency, have revealed great potential for application in hydrology and agriculture. Hence, it is essential to continuously enhance the data quality and spatial completeness to satisfy the increasing scientific research requirements. In this study, we explore the potential possibility of Soil Moisture Active Passive (SMAP) datasets in filling the gaps of ECV SM. The comprehensive assessment results show that: (1) The data missing percent of gap-filled ECV decreases 20% on average, which can be one step closer to generate a seamlessly covered global land surface SM product with favorable quality. (2) Compared to the original ECV, the gap-filled ECV products express similar good response to the in-situ measurements, suggesting that the SMAP SM products could be taken to efficiently fill the gaps and consistently maintain favorable accuracy at the same time. (3) Compared to the in-situ measurements, the original ECV SM products demonstrate extremely high probability density peak percentages. Fortunately, this eminent high value could be effectively rectified through gap-filling progress using SMAP. Overall, this study conducts objective and detailed evaluation on the performance of applying SMAP to fill the gaps of ECV, and is expected to act as a valuable reference in ECV SM gap-filling method.},
keywords={Microwave radiometry;Meteorology;Satellite broadcasting;Sensors;Soil moisture;Synthetic aperture radar;Soil measurements;Gap-filling;satellite retrieved soil moisture;the essential climate variable soil moisture;the soil moisture active passive soil moisture},
doi={10.1109/ACCESS.2020.3009977},
ISSN={2169-3536},
month={},}
@ARTICLE{8901214,
author={Li, Congcong and Li, Jing and Dai, Yanran and Yang, Tao and Xie, Yuguang and Lu, Zhaoyang},
journal={IEEE Access},
title={Data-Driven Variable Synthetic Aperture Imaging Based on Semantic Feedback},
year={2019},
volume={7},
number={},
pages={166021-166042},
abstract={Synthetic aperture imaging, which has been proved to be an effective approach for occluded object imaging, is one of the challenging problems in the field of computational imaging. Currently most of the related researches focus on fixed synthetic aperture which usually accompanies with mixed observation angle and foreground de-focus blur. But the existence of them is frequently a source of perspective effect decrease and occluded object imaging quality degradation. In order to solve this problem, we propose a novel data-driven variable synthetic aperture imaging based on semantic feedback. The semantic content we concerned for better de-occluded imaging is the foreground occlusions rather than the whole scene. Therefore, unlike other methods worked on pixel-level, we start from semantic layer and present a semantic labeling method based on feedback. Semantic labeling map deeply mines visual data in synthetic image and preserves the semantic information of foreground occluder. On the basis of semantic feedback strategy, semantic labeling map will conversely pass to synthetic imaging process. The proposed data-driven variable synthetic aperture imaging contains two levels: one is adaptive changeable imaging aperture driven by synthetic depth and perspective angle, the other is light ray screening driven by visual information in semantic labeling map. On this basis, the hybrid camera view and superimposition of foreground occlusion can be removed. Evaluations on several complex indoor scenes and real outdoor environments demonstrate the superiority and robustness performance of our proposed approach.},
keywords={Apertures;Semantics;Labeling;Cameras;Visualization;Image reconstruction;Synthetic aperture imaging;data-driven variable synthetic aperture;semantic feedback imaging;multi-camera array},
doi={10.1109/ACCESS.2019.2953560},
ISSN={2169-3536},
month={},}
@ARTICLE{9745947,
author={Qian, Kun and Wang, Yuanyuan and Shi, Yilei and Zhu, Xiao Xiang},
journal={IEEE Transactions on Geoscience and Remote Sensing},
title={γ-Net: Superresolving SAR Tomographic Inversion via Deep Learning},
year={2022},
volume={60},
number={},
pages={1-16},
abstract={Synthetic aperture radar tomography (TomoSAR) has been extensively employed in 3-D reconstruction in dense urban areas using high-resolution SAR acquisitions. Compressive sensing (CS)-based algorithms are generally considered as the state-of-the art in super-resolving TomoSAR, in particular in the single look case. This superior performance comes at the cost of extra computational burdens, because of the sparse reconstruction, which cannot be solved analytically, and we need to employ computationally expensive iterative solvers. In this article, we propose a novel deep learning-based super-resolving TomoSAR inversion approach, $\boldsymbol {\gamma }$ -Net, to tackle this challenge. $\boldsymbol {\gamma }$ -Net adopts advanced complex-valued learned iterative shrinkage thresholding algorithm (CV-LISTA) to mimic the iterative optimization step in sparse reconstruction. Simulations show the height estimate from a well-trained $\boldsymbol {\gamma }$ -Net approaches the Cramér-Rao lower bound (CRLB) while improving the computational efficiency by one to two orders of magnitude comparing to the first-order CS-based methods. It also shows no degradation in the super-resolution power comparing to the state-of-the-art second-order TomoSAR solvers, which are much more computationally expensive than the first-order methods. Specifically, $\boldsymbol {\gamma }$ -Net reaches more than 90% detection rate in moderate super-resolving cases at 25 measurements at 6 dB SNR. Moreover, simulation at limited baselines demonstrates that the proposed algorithm outperforms the second-order CS-based method by a fair margin. Test on real TanDEM-X data with just six interferograms also shows high-quality 3-D reconstruction with high-density detected double scatterers.},
keywords={Synthetic aperture radar;Superresolution;Deep learning;Neural networks;Reflectivity;Imaging;Image reconstruction;Complex-valued learned iterative shrinkage thresholding algorithm (LISTA);compressive sensing (CS);synthetic aperture radar~(SAR) tomography (TomoSAR);super-resolution},
doi={10.1109/TGRS.2022.3164193},
ISSN={1558-0644},
month={},}
@ARTICLE{8827494,
author={Tang, Zetian and Ding, Zhao and Zeng, Ruimin and Wang, Yang and Wen, Jun and Bian, Lifeng and Yang, Chen},
journal={IEEE Access},
title={Multi-Threshold Corner Detection and Region Matching Algorithm Based on Texture Classification},
year={2019},
volume={7},
number={},
pages={128372-128383},
abstract={In order to address the unreasonable distributed corners in single threshold Harris detection and expensive computation cost incurred from image region matching performed by normalized cross correlation (NCC) algorithm, multi-threshold corner detection and region matching algorithm based on texture classification are proposed. Firstly, the input image is split into sub-blocks which are classified into four different categories based on the specific texture: flat, weak, middle texture and strong regions. Subsequently, an algorithm is suggested to decide threshold values for different texture type, and interval calculation for the sub-blocks is performed to improve operation efficiency in the algorithm implementation. Finally, based on different texture characteristics, Census, interval-sampled NCC, and complete NCC are employed to perform image matching. As demonstrated by the experimental results, corner detection based on texture classification is capable to obtain a reasonable corner number as well as a more uniform spatial distribution, when compared to the traditional Harris algorithm. If combined with the interval classification, speedup for texture classification is approximately 30%. In addition, the matching algorithm based on texture classification is capable to improve the speed of 26.9%~29.9% while maintaining the comparable accuracy of NCC. In general, for better splicing quality, the overall stitching speed is increased by 14.1%~18.4%. Alternatively, for faster speed consideration, the weak texture region which accounts for a large proportion of an image and provides less effective information can be ignored, for which 23.9%~28.4% speedup can be achieved at the cost of a 1.9%~3.9% reduction in corner points. Therefore, the proposed algorithm is made potentially suited to uniformly distributed corner point calculation and high computation efficiency requirement scenarios.},
keywords={Classification algorithms;Corner detection;Complexity theory;Nanoscale devices;Clustering algorithms;Feature extraction;Microsoft Windows;Harris;texture classification;interval categorization;classification matching},
doi={10.1109/ACCESS.2019.2940137},
ISSN={2169-3536},
month={},}
@ARTICLE{9516007,
author={Zhang, Chen and Wang, Xiaofeng and Chen, Shengbing and Li, Hong and Wu, Xiaoxuan and Zhang, Xin},
journal={IEEE Access},
title={A Modified Random Forest Based on Kappa Measure and Binary Artificial Bee Colony Algorithm},
year={2021},
volume={9},
number={},
pages={117679-117690},
abstract={Random forest (RF) is an ensemble classifier method, all decision trees participate in voting, some low-quality decision trees will reduce the accuracy of random forest. To improve the accuracy of random forest, decision trees with larger degree of diversity and higher classification accuracy are selected for voting. In this paper, the RF based on Kappa measure and the improved binary artificial bee colony algorithm (IBABC) are proposed. Firstly, Kappa measure is used for pre-pruning, and the decision trees with larger degree of diversity are selected from the forest. Then, the crossover operator and leaping operator are applied in ABC, and the improved binary ABC is used for secondary pruning, and the decision trees with better performance are selected for voting. The proposed method (Kappa+IBABC) are tested on a quantity of UCI datasets. Computational results demonstrate that Kappa+IBABC improves the performance on most datasets with fewer decision trees. The Wilcoxon signed-rank test is used to verify the significant difference between the Kappa+IBABC method and other pruning methods. In addition, Chinese haze pollution is becoming more and more serious. This proposed method is used to predict haze weather and has achieved good results.},
keywords={Random forests;Vegetation;Decision trees;Artificial bee colony algorithm;Forestry;Training;Radio frequency;Random forest;Kappa measure;artificial bee colony algorithm;haze prediction},
doi={10.1109/ACCESS.2021.3105796},
ISSN={2169-3536},
month={},}
@ARTICLE{9270014,
author={Pham, Tung Thanh and Hoang, Xiem Van and Nguyen, Nghia Trung and Dinh, Duong Trieu and Ha, Le Thanh},
journal={IEEE Access},
title={End-to-End Image Patch Quality Assessment for Image/Video With Compression Artifacts},
year={2020},
volume={8},
number={},
pages={215157-215172},
abstract={In this paper, we present an experimental image quality assessment (IQA) method for image/video patches with compression artifacts. Using the High Efficiency Video Coding (HEVC) standard, we create a new database of image patches with compression artifacts. Then, we conduct a completed subjective testing process to obtain the `ground truth' quality scores for the mentioned database. Finally, we employ an end-to-end learning method to estimate the IQA model for the patches with HEVC compression artifacts. In such proposed method, a modified convolutional neural network (CNN) architecture is exploited for feature extraction while an adaptive moment estimation optimizer solution is used to perform the training process. Experimental results show that the proposed end-to-end IQA method significantly outperforms the relevant IQA benchmarks, especially when the compression artifacts are strongly realized in image/video patches. The proposed IQA method is expected to drive a new set of image/video compression solutions in future image/video coding and transmissions.},
keywords={Databases;Image coding;Distortion;Image quality;Measurement;Feature extraction;Training;Image quality assessment;coding distortion;image-patch quality assessment;compression artifacts},
doi={10.1109/ACCESS.2020.3040416},
ISSN={2169-3536},
month={},}
@ARTICLE{8938802,
author={Zhou, Renjie and Xia, Dongchen and Wan, Jian and Zhang, Sanyuan},
journal={IEEE Access},
title={An Intelligent Video Tag Recommendation Method for Improving Video Popularity in Mobile Computing Environment},
year={2020},
volume={8},
number={},
pages={6954-6967},
abstract={Big data generated from social media and smart mobile devices has been regarded as a key to obtain insights into human behavior and been extensively utilized for launching marketing activities. A successful marketing activity requires attracting high social popularity to their contents, since higher popularity usually indicates stronger influence, more fame and higher revenue. In this paper, we focus on the question of how to improve popularity of videos sharing on websites like YouTube in mobile computing environment. Obviously, composing high quality titles and tags is beneficial for viewers to discover videos of their interests and increase their tendency to watch more videos. However, it is not an easy task for uploaders, which is especially true since the screen is tight for most mobile devices. To this end, this paper proposes a novel hybrid method based on multi-modal content analysis that recommends keywords for video uploaders to compose titles and tags of their videos and then to gain higher popularity. The method generates candidate keywords by integrating techniques of textual semantic analysis of original tags and recognition of video content. On one hand, taking the original keywords of a video as input, the method obtains most relevant words from WordNet and related video titles gathered from the three top video sharing sites (YouTube, Yahoo Video, Bing Video). On the other hand, through recognizing video content with deep learning technology, the method extracts the entity name of video content as candidate keywords. Finally, a TF-SIM algorithm is proposed to rank the candidate keywords and the most relevant keywords are recommended to uploaders for optimizing the titles and tags of their videos. The experimental results show that the proposed method can effectively improve the social popularity of the videos as well as extend the length of video viewing time per playback.},
keywords={Mobile computing;YouTube;Deep learning;Search engines;Big Data;Mobile handsets;Mobile computing;social media;big data;video tagging;video popularity;artificial intelligence;deep learning},
doi={10.1109/ACCESS.2019.2961392},
ISSN={2169-3536},
month={},}
@ARTICLE{8943962,
author={Ma, Tian and Tian, Feng and Dong, Bo},
journal={IEEE Access},
title={Ordinal Optimization-Based Performance Model Estimation Method for HDFS},
year={2020},
volume={8},
number={},
pages={889-899},
abstract={Modeling and analyzing the performance of distributed file systems (DFSs) benefit the reliability and quality of data processing in data-intensive applications. Hadoop Distributed File System (HDFS) is a typical representative of DFSs. Its internal heterogeneity and complexity as well as external disturbance contribute to HDFS's built-in features of nonlinearity as well as randomness in system level, which raises a great challenge in modeling these features. Particularly, the randomness results in the uncertainty of HDFS performance model. Due to the complex mathematical structure and parameters hardly estimated of analytical models, it is highly complicated and computationally impossible to build an explicit and precise analytical model of the randomness. The measurement-based methodology is a promising way to model HDFS performance in terms of randomness since it requires no knowledge of system's internal behaviors. In this paper, the estimation of HDFS performance models on account of the randomness is transformed to an optimization problem of finding out the real best design of performance model structure with large design space. Core ideas of ordinal optimization (OO) are introduced to solve this problem with a limited computing budget. Piecewise linear (PL) model is applied to approximate the nonlinear characteristics and randomness of HDFS performance. The experimental results show that the proposed method is effective and practical to estimate the optimal design of the PL-based performance model structure for HDFS. It not only provides a globally consistent evaluation of the design space but also guarantees the goodness of the solution with high probability. Moreover, it improves the accuracy of system model-based HDFS performance models.},
keywords={Computational modeling;Mathematical model;Analytical models;Optimization;Estimation;Uncertainty;Throughput;Distributed file system;HDFS;performance modeling;randomness;ordinal optimization},
doi={10.1109/ACCESS.2019.2962724},
ISSN={2169-3536},
month={},}
@ARTICLE{8382164,
author={Muhammed, Thaha and Mehmood, Rashid and Albeshri, Aiiad and Katib, Iyad},
journal={IEEE Access},
title={UbeHealth: A Personalized Ubiquitous Cloud and Edge-Enabled Networked Healthcare System for Smart Cities},
year={2018},
volume={6},
number={},
pages={32258-32285},
abstract={Smart city advancements are driving massive transformations of healthcare, the largest global industry. The drivers include increasing demands for ubiquitous, preventive, and personalized healthcare, to be provided to the public at reduced risks and costs. Mobile cloud computing could potentially meet the future healthcare demands by enabling anytime, anywhere capture and analyses of patients' data. However, network latency, bandwidth, and reliability are among the many challenges hindering the realization of next-generation healthcare. This paper proposes a ubiquitous healthcare framework, UbeHealth, that leverages edge computing, deep learning, big data, high-performance computing (HPC), and the Internet of Things (IoT) to address the aforementioned challenges. The framework enables an enhanced network quality of service using its three main components and four layers. Deep learning, big data, and HPC are used to predict network traffic, which in turn are used by the Cloudlet and network layers to optimize data rates, data caching, and routing decisions. Application protocols of the traffic flows are classified, enabling the network layer to meet applications' communication requirements better and to detect malicious traffic and anomalous data. Clustering is used to identify the different kinds of data originating from the same application protocols. A proof of concept UbeHealth system has been developed based on the framework. A detailed literature review is used to capture the design requirements for the proposed system. The system is described in detail including the algorithmic implementation of the three components and four layers. Three widely used data sets are used to evaluate the UbeHealth system.},
keywords={Medical services;Cloud computing;Edge computing;Quality of service;Machine learning;Smart cities;Internet of Things;Cloudlets;deep learning;Internet of Things (IoT);mobile edge computing;mobile healthcare;preventive healthcare;traffic classification;traffic prediction;survey;fog computing;cloud computing;multimedia applications;smart cities},
doi={10.1109/ACCESS.2018.2846609},
ISSN={2169-3536},
month={},}
@ARTICLE{9519539,
author={Li, Zhihui and Peng, Lu and Wu, Feng},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
title={The Impacts of Impervious Surface on Water Quality in the Urban Agglomerations of Middle and Lower Reaches of the Yangtze River Economic Belt From Remotely Sensed Data},
year={2021},
volume={14},
number={},
pages={8398-8406},
abstract={The Urban Agglomerations of Middle and Lower Reaches of the Yangtze River Economic Belt (UAMLYREB) have experienced rapid and intense urbanization over the past decades with natural ecosystems being converted to impervious surfaces. Thus, impervious surfaces are recognized as critical parameters when considering the effect of urbanization on water quality. While understanding how the threshold of impervious surfaces affects water quality has been a hot topic, there has been little quantitative analysis on how such thresholds change during rapid urbanization periods across large urban areas. To remedy this deficiency, this article made use of remotely-sensed impervious surface area data and in situ water quality monitoring observations for the period 2000 to 2018 to quantitively derive the temporal variation in the thresholds of the percentage of the impervious surface area (PISA) when inferring the relationship between PISA and a set of water quality indicators for a selection of watersheds within the UAMLYREB. We employed segmented regression model to derive the nonlinear relationship between PISA, the water quality indicators, and the PISA-related thresholds. Our results indicate that PISA may be considered a useful water quality indicator over watershed spatial scales. We also found that the threshold effects differed between water quality indicators (DO, CODMn, NH3-N), where, except for NH3-N, the indicators showed a PISA threshold of 30.08 to 42.34%, with slight variations over the study period. These results imply that maintaining PISA to be around 30% in watershed areas may be sufficient to mitigate against water quality degradation during the urbanization process.},
keywords={Water quality;Rivers;Land surface;Remote sensing;Belts;Monitoring;Manganese;Impervious surface;rapid urbanization;remote sensing;segmented regression;threshold;water quality;Yangtze River economic belt},
doi={10.1109/JSTARS.2021.3106038},
ISSN={2151-1535},
month={},}
@ARTICLE{9027867,
author={Dong, Bingbing and Zhu, Yi and Li, Lei and Wu, Xindong},
journal={IEEE Access},
title={Hybrid Collaborative Recommendation via Dual-Autoencoder},
year={2020},
volume={8},
number={},
pages={46030-46040},
abstract={With the rapid increase of internet information, personalized recommendation systems are an effective way to alleviate the information overload problem, which has attracted extensive attention in recent years. The traditional collaborative filtering utilizes matrix factorization methods to learn hidden feature representations of users and/or items. With deep learning achieved good performance in representation learning, the autoencoder model is widely applied in recommendation systems for the advantages of fast convergence and no label requirement. However, the previous recommendation systems may take the reconstruction output of an autoencoder as the prediction of missing values directly, which may deteriorate their performance and cause unsatisfactory results of recommendation. In addition, the parameters of an autoencoder need to be pre-trained ahead, which greatly increases the time complexity. To address these problems, in this paper, we propose a Hybrid Collaborative Recommendation method via Dual-Autoencoder (HCRDa). More specifically, firstly, a novel dual-autoencoder is utilized to simultaneously learn the feature representations of users and items in our HCRDa, which obviously reduces time complexity. Secondly, embedding matrix factorization into the training process of the autoencoder further improves the quality of hidden features for users and items. Finally, additional attributes of users and items are utilized to alleviate the cold start problem and to make hybrid recommendations. Comprehensive experiments on several real-world data sets demonstrate the effectiveness of our proposed method in comparison with several state-of-the-art methods.},
keywords={Collaboration;Sparse matrices;Time complexity;Matrix decomposition;Machine learning;Neurons;Training;Recommendation system;matrix factorization;semi-autoencoder},
doi={10.1109/ACCESS.2020.2979255},
ISSN={2169-3536},
month={},}
@ARTICLE{8491315,
author={Asif-Ur-Rahman, Md. and Afsana, Fariha and Mahmud, Mufti and Kaiser, M. Shamim and Ahmed, Muhammad R. and Kaiwartya, Omprakash and James-Taylor, Anne},
journal={IEEE Internet of Things Journal},
title={Toward a Heterogeneous Mist, Fog, and Cloud-Based Framework for the Internet of Healthcare Things},
year={2019},
volume={6},
number={3},
pages={4049-4062},
abstract={Rapid developments in the fields of information and communication technology and microelectronics allowed seamless interconnection among various devices letting them to communicate with each other. This technological integration opened up new possibilities in many disciplines including healthcare and well-being. With the aim of reducing healthcare costs and providing improved and reliable services, several healthcare frameworks based on Internet of Healthcare Things (IoHT) have been developed. However, due to the critical and heterogeneous nature of healthcare data, maintaining high quality of service (QoS)-in terms of faster responsiveness and data-specific complex analytics-has always been the main challenge in designing such systems. Addressing these issues, this paper proposes a five-layered heterogeneous mist, fog, and cloud-based IoHT framework capable of efficiently handling and routing (near-)real-time as well as offline/batch mode data. Also, by employing software defined networking and link adaptation-based load balancing, the framework ensures optimal resource allocation and efficient resource utilization. The results, obtained by simulating the framework, indicate that the designed network via its various components can achieve high QoS, with reduced end-to-end latency and packet drop rate, which is essential for developing next generatione-healthcare systems.},
keywords={Medical services;Cloud computing;Internet of Things;Edge computing;Quality of service;Monitoring;Data fusion;healthcare application;healthcare big data;load balancing;quality of service (QoS);real-time computing;resource allocation},
doi={10.1109/JIOT.2018.2876088},
ISSN={2327-4662},
month={June},}
@ARTICLE{9292991,
author={Liu, Dong and Li, Qinpeng and Ru, Yan and Zhang, Jun},
journal={IEEE Access},
title={The Network Representation Learning Algorithm Based on Semi-Supervised Random Walk},
year={2020},
volume={8},
number={},
pages={222956-222965},
abstract={As an important tool of social network analysis, network representation learning also called network embedding maps the network to a latent space and learns low-dimensional and dense real vectors of nodes, while preserving the structure and internal attributes of network. The learned representations or embedding vectors can be used for node clustering, link prediction, network visualization and other tasks for network analysis. Most of the existing network representation learning algorithms mainly focus on the preservation of micro or macro network structure, ignoring the mesoscopic community structure information. Although a few network embedding methods are proposed to preserve the community structure, they all ignore the prior information about communities. Inspired by the semi-supervised community detection in complex networks, in this article, a novel Semi-Supervised DeepWalk method(SSDW) is proposed for network representation learning, which successfully preserves the community structure of network in the embedding space. Specifically, a semi-supervised random walk sampling method which effectively integrates the pairwise constraints is proposed. By doing so, the SSDW model can guide the transition probability in the random walk process and obtain the node context sequence in line with the prior knowledge. The experimental results on eight real networks show that comparing with the popular network embedding methods, the node representation vectors integrating pairwise constraints into the random walk process can obtain higher accuracy on node clustering task, and the results of link prediction, network visualization tasks indicate that the semi-supervised model SSDW is more discriminative than unsupervised ones.},
keywords={Task analysis;Clustering algorithms;Matrix decomposition;Complex networks;Topology;Symmetric matrices;Network representation learning;semi-supervised;pairwise constraints;community structure;random walk},
doi={10.1109/ACCESS.2020.3044367},
ISSN={2169-3536},
month={},}
@ARTICLE{9514599,
author={Yin, Hang and Liu, Chuanyun and Gao, Yacui and Fan, Wenting and Xiao, Bin and Cao, Liang and Hassan, Shahbaz Gul and Liu, Shuangyin},
journal={IEEE Access},
title={A Novel Method to Predict Laying Rate Based on Multiple Environment Variables},
year={2021},
volume={9},
number={},
pages={115488-115496},
abstract={Realizing an accurate laying rate prediction based on environmental factors plays a vital role in livestock and poultry breeding. In this paper, multiple environmental factors were considered to improve the accuracy of egg production rate prediction. A method was proposed by combining the Random Forest (RF) and Long Short-Term Memory (LSTM) to analyze the impact of the external environmental factors on the laying rate. Firstly, using RF, feature importance selection was implemented on environmental factors affecting laying rate. Secondly, the extreme Gradient Boosting (XGBoost) was introduced as a comparison to evaluate the accuracy and reliability of the RF feature importance selection. Finally, by discarding the features with low importance one by one, the multi-variable RF-LSTM laying rate prediction was conducted. Experiment results showed that the proposed RF-LSTM method significantly improved the prediction accuracy on laying rate.},
keywords={Random forests;Production;Predictive models;Logic gates;Computer architecture;Radio frequency;Indexes;Long short-term memory (LSTM);random forests (RF);egg laying rate;feature importance selection},
doi={10.1109/ACCESS.2021.3105189},
ISSN={2169-3536},
month={},}
@ARTICLE{9042330,
author={Zhou, Zhou and Li, Fangmin and Abawajy, Jemal H. and Gao, Chaochao},
journal={IEEE Access},
title={Improved PSO Algorithm Integrated With Opposition-Based Learning and Tentative Perception in Networked Data Centres},
year={2020},
volume={8},
number={},
pages={55872-55880},
abstract={Particle swarm optimization (PSO) algorithms have low-quality initial particle swarm, which is generated by a random method when handling the problem of task scheduling in networked data centres. Such algorithms also fall easily into local optimum when searching for the optimal solution. To address these problems, this study proposes combining opposition-based learning (OBL) and tentative perception (TP) with PSO; the proposed method is called OBL-TP-PSO. This algorithm uses reverse learning to generate the initial population, such that the quality of the initial particle swarm can be improved. Before the particle speed and location are updated, the TP method is used to search for the individual optimum around each particle, thereby reducing the possibility of missing the potential optimal solution during the process of searching. In this manner, the problem in which the PSO algorithm easily falls into the local optimal is effectively solved. To evaluate the performance of the proposed algorithm, simulation experiments are performed on CloudSim toolkit. Experimental results show that in comparison with other algorithms (namely, Min-Min, Max-Min and PSO algorithm), the proposed OBL-TP-PSO algorithm has better performance in terms of the total execution time, load balancing and quality of service.},
keywords={Task analysis;Particle swarm optimization;Cloud computing;Scheduling;Quality of service;Sociology;Statistics;Big data processing;high-performance data processing;networked data centre;opposition-based learning;tentative perception},
doi={10.1109/ACCESS.2020.2981972},
ISSN={2169-3536},
month={},}
@ARTICLE{8698790,
author={Gu, Xiao-Guang and Tong, Wen-Tao and Han, Meng-Meng and Wang, Yan and Wang, Zhong-Yang},
journal={IEEE Access},
title={Parameter and Tolerance Economic Design for Multivariate Quality Characteristics Based on the Modified Process Capability Index With Individual Observations},
year={2019},
volume={7},
number={},
pages={59249-59262},
abstract={The process capability index (PCI) is widely used in an on-line quality control stage for measuring and controlling the quality level of a production process. The calculation of PCI requires a large number of samples, but in the off-line quality control stage, a certain production process in off-line quality control stage only has a few individual observations. From the perspective of quality loss and tolerance cost, this paper proposes a parameter and tolerance economic design approach for multivariate quality characteristics based on the modified PCI with individual observations. The response surface models of mean and variance are constructed using individual observations, and exponential models are fitted according to the tolerance cost data of design variables. A modified PCI is proposed with the consideration of three types of quality characteristics. The optimal design variables and tolerances are obtained by a comprehensive optimization model that is constructed based on the proposed PCI. An example of an isobutylene-isoprene rubber (IIR) inner tube is used to (i) demonstrate the implementation of our proposed approach, (ii) improve the PCI value and reflect the sensitivity of the deviation between process mean and specification, and (iii) reduce the risk of increasing cost of quality caused by replicated experimental design and some other unknown reasons.},
keywords={Quality control;Biological system modeling;Economics;Indexes;Process control;Optimization;Response surface methodology;Parameter;tolerance;economic design;multivariate quality characteristics;process capability index;individual observations},
doi={10.1109/ACCESS.2019.2913215},
ISSN={2169-3536},
month={},}
@ARTICLE{9364686,
author={Liu, Yang and Zuo, Xianyu and Tian, Junfeng and Li, Shenshen and Cai, Kun and Zhang, Wanjun},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
title={Research on Generic Optical Remote Sensing Products: A Review of Scientific Exploration, Technology Research, and Engineering Application},
year={2021},
volume={14},
number={},
pages={3937-3953},
abstract={With the initial establishment of global earth observation system in various countries, more and more high-resolution remote sensing data of multisource, multitemporal, multiscale, and different types of satellites are obtained. It is urgent to explore the advanced basic theory of remote sensing information science, design high-performance generic key technologies of remote sensing information system and global positioning system, and study complex engineering system of remote sensing applications and geographic information system. In this article, the basic theory exploration, inversion technology research, and engineering application design and development of generic optical remote sensing product (ORSP) are systematically reviewed. We classify the ORSP scientifically, review the main algorithms and application scope of 16 kinds of generic ORSP, and expound the validation and quality evaluation methods of ORSP in engineering application. Furthermore, we analyze the current core problems and solutions, and prospects for the state-of-the-art research and the future development trend of generic ORSP. This will provide valuable reference for scientific research and construction of high-resolution earth observation system.},
keywords={Remote sensing;Indexes;Vegetation mapping;Optical sensors;Satellites;Earth Observing System;Reflectivity;Generic optical remote sensing products (ORSPs);high-resolution earth observation system;inversion technology;quality evaluation;remote sensing (RS) application;RS product category;validation},
doi={10.1109/JSTARS.2021.3062411},
ISSN={2151-1535},
month={},}
@ARTICLE{9040585,
author={Shang, Xiaoting and Yang, Kai and Wang, Weiqiao and Wang, Weiping and Zhang, Haifeng and Celic, Selena},
journal={IEEE Access},
title={Stochastic Hierarchical Multimodal Hub Location Problem for Cargo Delivery Systems: Formulation and Algorithm},
year={2020},
volume={8},
number={},
pages={55076-55090},
abstract={This study aims at developing a stochastic hierarchical multimodal hub location modeling framework for cargo delivery systems to capture uncertainty in hub construction cost and travel time at the strategic level. From a ring-star-star type network design perspective, a stochastic model is established to formulate this problem formally via the expected value and chance-constrained programming techniques. In particular, three types of chance constraints are proposed to ensure that the on-time delivery with pre-specified confidence levels in their respective layer networks. For normal distributions, the original stochastic model can be reformulated as a crisp equivalent mixed-integer linear programming (MILP) model by invoking the central limit theorem. Since the number of constraints and variables increases drastically with the size of cargo delivery distribution network, a memetic algorithm (MA) is designed. This algorithm incorporates genetic search and local intensification to obtain optimal/near-optimal solutions for realistic instance size within a reasonable time limit. For general distributions, it is difficult to convert the stochastic model into its deterministic counterpart. Hence, a hybrid methodology is further designed by combining the MA and Monte Carlo (MC) simulation to solve the proposed stochastic model. To demonstrate the properties of the proposed model and the performance of the designed algorithm, a series of numerical experiments are set up based on the Civil Aeronautics Board (CAB) and Turkish network data sets. Computational results indicate as the confidence level increases, the airport hubs are located further apart in the cargo delivery distribution network for gaining a greater time advantage. In addition, comparative results demonstrate that the MA algorithm proposed herein performs better than the genetic algorithm (GA) in terms of computing speed and quality of the solution.},
keywords={Stochastic processes;Airports;Uncertainty;Atmospheric modeling;Distribution networks;Numerical models;Hierarchical multimodal hub location;cargo delivery systems;stochastic programming;mixed-integer linear programming;memetic algorithm;Monte Carlo simulation},
doi={10.1109/ACCESS.2020.2981669},
ISSN={2169-3536},
month={},}
@ARTICLE{6574675,
author={Zhou, Jin and Hu, Liang and Wang, Feng and Lu, Huimin and Zhao, Kuo},
journal={Tsinghua Science and Technology},
title={An efficient multidimensional fusion algorithm for IoT data based on partitioning},
year={2013},
volume={18},
number={4},
pages={369-378},
abstract={The Internet of Things (IoT) implies a worldwide network of interconnected objects uniquely addressable, via standard communication protocols. The prevalence of IoT is bound to generate large amounts of multisource, heterogeneous, dynamic, and sparse data. However, IoT offers inconsequential practical benefits without the ability to integrate, fuse, and glean useful information from such massive amounts of data. Accordingly, preparing us for the imminent invasion of things, a tool called data fusion can be used to manipulate and manage such data in order to improve process efficiency and provide advanced intelligence. In order to determine an acceptable quality of intelligence, diverse and voluminous data have to be combined and fused. Therefore, it is imperative to improve the computational efficiency for fusing and mining multidimensional data. In this paper, we propose an efficient multidimensional fusion algorithm for IoT data based on partitioning. The basic concept involves the partitioning of dimensions (attributes), i.e., a big data set with higher dimensions can be transformed into certain number of relatively smaller data subsets that can be easily processed. Then, based on the partitioning of dimensions, the discernible matrixes of all data subsets in rough set theory are computed to obtain their core attribute sets. Furthermore, a global core attribute set can be determined. Finally, the attribute reduction and rule extraction methods are used to obtain the fusion results. By means of proving a few theorems and simulation, the correctness and effectiveness of this algorithm is illustrated.},
keywords={Partitioning algorithms;Data integration;Internet;Set theory;Data mining;Information management;Internet of Things;data fusion;multidimensional data;partitioning;rough set theory},
doi={10.1109/TST.2013.6574675},
ISSN={1007-0214},
month={August},}
@ARTICLE{8976082,
author={Yang, Le and Jiang, Dongmei and Sahli, Hichem},
journal={IEEE Access},
title={Feature Augmenting Networks for Improving Depression Severity Estimation From Speech Signals},
year={2020},
volume={8},
number={},
pages={24033-24045},
abstract={Depression disorder has become one of the major psychological diseases endangering human health. Researcher in the affective computing community is supporting the development of reliable depression severity estimation system, from multiple modalities (speech, face, text), to assist doctors in their diagnosis. However, the limited amount of annotated data has become the main bottleneck restricting the study on depression screening, especially when deep learning models are used. To alleviate this issue, in this work we propose to use Deep Convolutional Generative Adversarial Network (DCGAN) for features augmentation to improve depression severity estimation from speech. To the best of our knowledge, this approach is the first attempt to apply the Generative Adversarial Network for depression severity estimation from speech. Besides, to measure the quality of the augmented features, we propose three different measurement criteria, characterizing the spatial, frequency and representation learning of the augmented features. Finally, the augmented features are used to train depression estimation models. Experiments are carried out on speech signals from the Audio Visual Emotion Challenge (AVEC2016) depression dataset, and the relationship between the model performance and data size is explored. Our experimental results show that: 1) The combination of the three proposed evaluation criteria can effectively and comprehensively evaluate the quality of the augmented features. 2) When increasing the size of the augmented data, the performance of depression severity estimation gradually improves and the model converges to a certain stable state. 3) The proposed DCGAN based data augmentation approach effectively improves the performance of depression severity estimation, with the root mean square error (RMSE) reduced to 5.520 and mean absolute error (MAE) reduced to 4.634, which is better than most of the state of the art results on AVEC 2016.},
keywords={Depression;Estimation;Generative adversarial networks;Gallium nitride;Data models;Visualization;Frequency measurement;Depression estimation;audio features;data augmentation;deep convolutional generative adversarial network;spatial domain;frequency domain;deep learning aspect},
doi={10.1109/ACCESS.2020.2970496},
ISSN={2169-3536},
month={},}
@ARTICLE{8314682,
author={Huang, Mingfeng and Liu, Yuxin and Zhang, Ning and Xiong, Neal N. and Liu, Anfeng and Zeng, Zhiwen and Song, Houbing},
journal={IEEE Access},
title={A Services Routing Based Caching Scheme for Cloud Assisted CRNs},
year={2018},
volume={6},
number={},
pages={15787-15805},
abstract={With the emergence of Internet of Things, the number of connected devices has been dramatically increasing, causing severe spectrum shortage problem. To fully explore the spectrum resources, big data, and cloud computing can be employed by cognitive radio networks, to make efficient use of various sensing results from different sensing sources. However, the massive growth of sensing data brings tremendous load pressure on the data center, resulting in long service response time and poor Quality of Experience. Edge computing and fog computing deal with these issues by placing computation resources at the network edge. However, compared with the data center, the capabilities at edge servers are limited. Therefore, a services routing-based caching scheme (SRCS) is proposed, which can greatly lighten the load on the data center and maintain the advantages of global intelligent computing of traditional cloud computing. Specifically, SRCS first introduces the concept of transmitting service flow. At the edge layer, data are converted to service flow by network hardware and software, thus achieving the network architecture centered on service computing. Then, SRCS proposes a service routing based on service similarity, transmits similar services through the same path, and service data are fused on the path to minimize transmission load. Moreover, SRCS caches services in content routers (CRs). When the service is requested again, CRs are used as service providers to return data, thus achieving the nearest access to the content. Both theoretical analysis and experiment results demonstrate that comparing existing schemes, SRCS improves service response time by 13.67%–51.15%, reduces transmitting data amount by 23.62%–30.3%, and makes energy consumption more balanced.},
keywords={Data centers;Sensors;Edge computing;Routing;Cloud computing;Big Data;Network architecture;Big data;edge computing;services joint data routing;in-network caching;services fusion},
doi={10.1109/ACCESS.2018.2815039},
ISSN={2169-3536},
month={},}
@ARTICLE{8883242,
author={Chu, Xiang and Liu, Jun and Gong, Daqing and Wang, Rui},
journal={IEEE Access},
title={Preserving Location Privacy in Spatial Crowdsourcing Under Quality Control},
year={2019},
volume={7},
number={},
pages={155851-155859},
abstract={Emerging spatial crowdsourcing (SC) provides an approach for collecting and analyzing spatiotemporal information from intelligent transportation systems. However, the exposure of massive location privacy to potential adversaries for the purpose of quality control makes workers more vulnerable. To protect workers’ location privacy, an obfuscation scheme is proposed to incorporate uncertainties into the SC quality control problem through obfuscating the standard location data in terms of both space and time. Two measures, location entropy and results accuracy, are used to evaluate the performance of location privacy protection. We theoretically and experimentally confirm the security and accuracy of the obfuscation approach. The results of experiments show that: a) hiding workers’ location from the requester reduces the quality of SC; and b) obfuscation arithmetic with appropriate obfuscation coefficients protects workers’ location privacy with little effect on SC quality. Under the protection of this obfuscation scheme, the new system provides better security and similar quality compared to the existing SC system.},
keywords={Task analysis;Privacy;Quality control;Crowdsourcing;Uncertainty;Entropy;Data privacy;Spatial crowdsourcing;obfuscation location privacy of workers;quality control;EM algorithm},
doi={10.1109/ACCESS.2019.2949409},
ISSN={2169-3536},
month={},}
@ARTICLE{9018381,
author={Liu, Yu and Luo, Qinyao and Shen, Hang and Zhuang, Sida and Xu, Chen and Dong, Yihe and Sun, Yukai and Wang, Shaochen and Deng, Hao},
journal={IEEE Access},
title={Social Media Big Data-Based Research on the Influencing Factors of Insomnia and Spatiotemporal Evolution},
year={2020},
volume={8},
number={},
pages={41516-41529},
abstract={Insomnia is a prevalent sleep disorder that causes serious harm to individuals and society. It is closely linked to not only personal factors but also social, economic and other factors. This study explores the influencing factors and spatial differentiation of insomnia from the perspective of social media. This paper chose China's largest social media platform, Sina Weibo, as its data source. Then, based on the collected relevant data of 288 Chinese cities from 2013 to 2017, it explored the impact of economic, social, and environmental factors and an educated population on insomnia. Additionally, the importance and interaction of each influencing factor were analyzed. According to the results, the gross domestic product (GDP), proportion of households connected to the Internet and number of students in regular institutions of higher education are the major factors that influence insomnia, and their influences show obvious spatial nonstationarity. Rapid GDP growth has increased the probability of insomnia, and the positive correlation between the proportion of households connected to the internet and insomnia has strengthened annually. Although the impact of insomnia on college students decreased in some regions, the overall impact was still increasing annually, and spatial nonstationarity was obvious. Properly controlling GDP growth and unnecessary time spent online and guiding people to develop healthy Internet surfing habits and lifestyles will help improve their sleep quality. Our research results will help relevant professionals better understand the distribution of regional insomnia and provide a reference for related departments to formulate regional insomnia prevention and treatment policies.},
keywords={Social network services;Urban areas;Analytical models;Spatiotemporal phenomena;Economic indicators;Sociology;Social media;insomnia;geographically weighted regression model;influencing factors},
doi={10.1109/ACCESS.2020.2976881},
ISSN={2169-3536},
month={},}
@ARTICLE{9378518,
author={Bekkouch, Imad Eddine Ibrahim and Nicolae, Dragoş Constantin and Khan, Adil and Kazmi, S. M. Ahsan and Khattak, Asad Masood and Ibragimov, Bulat},
journal={IEEE Access},
title={Adversarial Reconstruction Loss for Domain Generalization},
year={2021},
volume={9},
number={},
pages={42424-42437},
abstract={The biggest fear when deploying machine learning models to the real world is their ability to handle the new data. This problem is significant especially in medicine, where models trained on rich high-quality data extracted from large hospitals do not scale to small regional hospitals. One of the clinical challenges addressed in this work is magnetic resonance image generalization for improved visualization and diagnosis of hip abnormalities such as femoroacetabular impingement and dysplasia. Domain Generalization (DG) is a field in machine learning that tries to solve the model's dependency on the training data by leveraging many related but different data sources. We present a new method for DG that is both efficient and fast, unlike the most current state of art methods, which add a substantial computational burden making it hard to fine-tune. Our model trains an autoencoder setting on top of the classifier, but the encoder is trained on the adversarial reconstruction loss forcing it to forget style information while extracting features useful for classification. Our approach aims to force the encoder to generate domain-invariant representations that are still category informative by pushing it in both directions. Our method has proven universal and was validated on four different benchmarks for domain generalization, outperforming state of the art on RMNIST, VLCS and IXMAS with a 0.70% increase in accuracy and providing comparable results on PACS with a 0.02% difference. Our method was also evaluated for unsupervised domain adaptation and has shown to be quite an effective method against over-fitting.},
keywords={Data models;Deep learning;Image reconstruction;Training;Computational modeling;Feature extraction;Transfer learning;Computer vision;deep learning;domain adaptation;domain generalization;transfer learning},
doi={10.1109/ACCESS.2021.3066041},
ISSN={2169-3536},
month={},}