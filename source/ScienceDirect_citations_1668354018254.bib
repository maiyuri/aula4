@article{SECINARO2022296,
title = {Smart city reporting: A bibliometric and structured literature review analysis to identify technological opportunities and challenges for sustainable development},
journal = {Journal of Business Research},
volume = {149},
pages = {296-313},
year = {2022},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2022.05.032},
url = {https://www.sciencedirect.com/science/article/pii/S0148296322004672},
author = {Silvana Secinaro and Valerio Brescia and Federico Lanzalonga and Gabriele Santoro},
keywords = {Smart city, Sustainability, Reporting, Technology},
abstract = {While policies and academic interest in smart cities gain momentum, there remain significant gaps in practice and academic conceptualisations explaining it as a new source of innovation. Moreover, there is a need to synthesise reporting behaviours and tools thereof, supporting communication and transparency for citizens along with their involvement in innovation processes. An Organisation for Economic Co-operation and Development (OECD) country analysis highlights gaps in transparency, reporting and communication of results, and the consequent allocation of resources in smart cities. Thus, this study identifies literature streams embracing the notion of smart cities and reporting. It employs a bibliometric and structured literature review analysis. Accordingly, this study proposes a framework comprising four macro-areas, several micro-elements, and the most appropriate implementation of technologies for sustainability challenges. Notably, it contributes to strengthening the smart city as an unconventional source of innovation, providing policymakers an opportunity to account for the smart city's weaknesses and identify areas for significant improvement efforts to be channelled.}
}
@article{ATAMAN2022103462,
title = {Urban Interventions and Participation Tools in Urban Design Processes: A Systematic Review and Thematic Analysis (1995 – 2021)},
journal = {Sustainable Cities and Society},
volume = {76},
pages = {103462},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103462},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721007356},
author = {Cem Ataman and Bige Tuncer},
keywords = {Urban intervention, participation tool, urban design process, participatory design, informed decision-making},
abstract = {All cities need to change and transform to become more livable. Urban interventions are effective for observing the changes and participation tools are in use for collecting data from urban contexts. Nevertheless, the two research fields remain thematically disintegrated within themselves and between each other in the literature that spread across disciplines. This article aims to contribute to and advance the academic conceptualization of urban interventions and participation tools within urban design processes. In order to establish a solid basis and provide conceptual clarity, the research domains of two study fields are explored from 1995 through 2021. We conducted a thematic analysis covering 176 peer-reviewed publications in English. The studies on urban interventions are synthesized and categorized into five main thematic areas: urbanism, community, sustainability, building types, and participation; while the studies on participation tools are investigated within four thematic areas: participation, digital tools, representations, and responsive cities. We conclude that the two research fields are highly interrelated and need to be studied together. This systematic review would trigger new perspectives and directions in the future, and provide a well-conceptualized base that combines urban interventions and digital participatory designs for both theory-based and practical studies.}
}
@article{GARFINKLE2022782,
title = {Assessment of long-term bowel dysfunction after restorative proctectomy for neoplastic disease: A population-based cohort study},
journal = {Surgery},
volume = {172},
number = {3},
pages = {782-788},
year = {2022},
issn = {0039-6060},
doi = {https://doi.org/10.1016/j.surg.2021.10.068},
url = {https://www.sciencedirect.com/science/article/pii/S0039606021011107},
author = {Richard Garfinkle and Sophie Dell’Aniello and Sahir Bhatnagar and Nancy Morin and Gabriela Ghitulescu and Julio Faria and Carol-Ann Vasilevsky and Paul Brassard and Marylise Boutros},
abstract = {Background
The purpose of this study was to describe postoperative bowel dysfunction after restorative proctectomy, and to identify factors associated with its development.
Methods
Patients who underwent restorative proctectomy for rectal cancer between April 1998 and November 2018 were identified from the Hospital Episode Statistics database and linked to the Clinical Practice Research Datalink for postoperative follow-up. Bowel dysfunction was defined according to relevant symptom-based read codes and medication prescription–product codes. A Cox proportional hazards model was performed to identify factors associated with postoperative bowel dysfunction, adjusting for relevant covariates.
Results
In total, 2,197 patients were included. The median age was 70.0 (interquartile range: 62.0–77.0) years old, and the majority (59.2%) of patients were male. After a median follow-up of 51.6 (24.0–90.0) months, bowel dysfunction was identified in 620 (28.2%) patients. Risk factors for postoperative bowel dysfunction included extremes of age (<40 years old: adjusted hazards ratio 2.35, 95% confidence interval 1.18–4.65; 70–79 years old: adjusted hazards ratio 1.25, 95% confidence interval 1.03–1.52), radiotherapy (adjusted hazards ratio 1.94, 95% confidence interval 1.56–2.42), distal tumors (adjusted hazards ratio 1.62, 95% confidence interval 1.34–1.94), history of diverting ostomy (adjusted hazards ratio 1.58, 95% confidence interval 1.33–1.89), and anastomotic leak (adjusted hazards ratio 1.48, 95% confidence interval 1.06–2.05). A minimally invasive surgical approach was protective for postoperative bowel dysfunction (adjusted hazards ratio 0.68, 95% confidence interval 0.53–0.86).
Conclusion
Bowel dysfunction was common after restorative proctectomy, and several patient, disease, and treatment-level factors were associated with its development.}
}
@article{FADHILLAH2022463,
title = {Mapping of landslide potential in Pyeongchang-gun, South Korea, using machine learning meta-based optimization algorithms},
journal = {The Egyptian Journal of Remote Sensing and Space Science},
volume = {25},
number = {2},
pages = {463-472},
year = {2022},
issn = {1110-9823},
doi = {https://doi.org/10.1016/j.ejrs.2022.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S1110982322000382},
author = {Muhammad Fulki Fadhillah and Wahyu Luqmanul Hakim and Mahdi Panahi and Fatemeh Rezaie and Chang-Wook Lee and Saro Lee},
keywords = {Susceptibility map, Hybrid algorithm, ANFIS, Metaheuristic algorithm},
abstract = {Landslides are geological hazards that can have severe impacts, threatening both the people and the local environment of highlands or mountain slopes. Landslide susceptibility mapping is an essential tool for predicting landslides and mitigating landslide-associated damage in areas prone to these events. This study aims to investigate the combination of using an adaptive network-based fuzzy inference system (ANFIS) with metaheuristic optimization algorithms: gray wolf optimizer (GWO), particle swarm optimization algorithm (PSO), and the imperialist competitive algorithm (ICA) in mapping landslide potential. The study area was Pyeongchang-gun, South Korea, for which an accurate landslide inventory dataset is available. A landslide inventory map was organized, and the data were separated randomly into training data (70%) and validation data (30%). In addition, 16 landslide-related factors consisting of geo-environmental and topo-hydrological factors were considered as predictive variables. This landslide susceptibility model was be evaluated based on the value of the area under the receiver operating characteristic (ROC) curve (AUC) to measure its accuracy. Based on the maps, the validation results showed that the optimized models of ANFIS-ICA, ANFIS-PSO, and ANFIS-GWO had AUC accuracies of 0.927, 0.947, and 0.968, respectively. The result from the hybrid algorithms model of ANFIS with metaheuristic algorithms outperformed the standalone ANFIS model in terms of accuracy in predicting landslide potential. Therefore, the ML algorithm and optimization algorithm models proposed in this study are more suitable for landslide susceptibility mapping in the study area.}
}
@article{YU202255,
title = {Blockchain-empowered secure federated learning system: Architecture and applications},
journal = {Computer Communications},
volume = {196},
pages = {55-65},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2022.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0140366422003474},
author = {Feng Yu and Hui Lin and Xiaoding Wang and Abdussalam Yassine and M. Shamim Hossain},
keywords = {Blockchain, Federated learning, Deep learning, Internet of Things, Intelligent transportation},
abstract = {Federated learning (FL) is a promising paradigm to realize distributed machine learning on heterogeneous clients without exposing their private data. However, there is the risk of single point failure with FL because it relies on a central server to gather the model updates from clients, moreover, malicious behaviors of some clients may lead to low-quality or even poisoned global models. Blockchain as a revolutionary distributed ledger technology can alleviate the above problems to significantly enhance the security and scalability of FL systems. Therefore, this article presents a general framework of Blockchain-based Federated Learning (BFL) system with detailed description of its key technologies and operation steps. We then review and compare the most recent representative BFL applications. And we outlook some key challenges and opportunities of the future BFL system in terms of security, cost, and scalability. Finally, we propose PoS-BFL in IoT scenarios with malicious devices. The validator voting mechanism and role switching mechanism in PoS-BFL ensure the stakes of legitimate nodes, and effectively reduce the impact of malicious nodes on the accuracy of the system model. And the experiments are conducted to demonstrate that PoS-BFL can achieve 86% accuracy, which is much higher than vanilla FL and pFedMe, and PoS-BFL is robust to some extent by adjusting the ratio of workers, validators and miners.}
}
@article{GLASS20223367,
title = {Synthetic Pedestrian Routes Generation: Exploring Mobility Behavior of Citizens through Multi-Agent Reinforcement Learning},
journal = {Procedia Computer Science},
volume = {207},
pages = {3367-3375},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.395},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922012856},
author = {Ayşe Glass and Jörg Rainer Noennig},
keywords = {Synthetic generation, mobility behavior, reinforcement learning, smart city},
abstract = {The data-driven city is improving the quality of everyday life for citizens and the efficient use of resources. While data-driven cities are benefiting from artificial intelligence technologies, one of the major challenges are the security, privacy, managing issues and costs. Furthermore, the training data for machine learning methods are in many cases not sufficiently available. Simulation tools are available for the designers or administration, and synthetic data generation based on real data is a promising approach on the development of new methods. This paper reports an exploratory research, targeting data generation with agent-based simulations combined with reinforcement learning. The study is still in its starting phase, but the conceptual outline and methodology has been created. The goal of this study is to establish a model to retrieve insights into the integration from a restricted data set from Google Maps and agent-based simulations. One of the primary observations is that intelligent agents, trained/reinforced paths instead of random behavior, show vastly different behavior than randomly acting agents. Evaluate the behavior according to empirical data, mostly because of the advantage of this method for complex behavior, where it would impractical to iterate through all possible paths, resulting in methodological issues. The paper exposes the following methodical challenges. (1) Realistic data sets will be large and full of decisions that appear to be random. To verify the collected, empirical data might lead to unreliable results, as actors will, as in real life, make different decisions according to circumstance. (2) The more complex a model has to be to be equivalent to the synthetic model, the more powerful the computational resources have to be. This leads to a dilemma between the model's complexity to make results comparable, and the simplicity to make computation realistic. Outline of the papers framework: (1) The generated data set challenges explored with the goal of providing realistic synthetic data. (2) A method for integration of synthetic and real-world data based on the reinforcement learning is developed. The premise is that implementing a reinforcement learning framework on top of multi-agent systems makes it possible to understand the mobility behavior of citizens. The paper explains the feasibility of both points, showing that this approach forms a solid basis for further investigation of the synthetic data generation for recognizing the mobility behavior of the citizens and enables the researchers to investigate the usage of reinforcement learning approach on the human mobility routes.}
}
@article{ZIMMERMANN2022706,
title = {Job Profiles in the Field of Data-Driven Supply Chain Management An Analysis of the Austrian Job Market},
journal = {Procedia Computer Science},
volume = {204},
pages = {706-713},
year = {2022},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.08.085},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922008237},
author = {Robert Zimmermann and Patrick Brandtner},
keywords = {Supply Chain Management, Data, Job Advertisments, Data Science, Data Analytics},
abstract = {Supply chains are immersed in extremely complex and dynamic environments. Reducing uncertainty and improving decision making by means of data-driven supply chain management (SCM) has increasingly become an indispensable core of organizational management. To implement data-driven SCM, companies need to possess the right skilled employees. Job advertisements in the field of data-driven SCM come with multiple different titles, sets of tasks, requirements, and desired soft skills. Therefore, determining which job profile typically inherits which specific requirements, tasks and soft skills presents a challenging task. To illuminate this question, we analyzed the entire Austrian SCM job market and extracted all available job profiles, their specific tasks, requirements, and basic salaries. Analyzing these data, we give recommendations about which qualifications and skills an applicant should inherit for a specific job profile. Additionally, we highlight which tasks typically need to be performed and what minimum salaries can be expected for the specific job profiles. Thus, our results help companies to specify their job advertisements in the field of data-driven SCM and provide job applicants with an overview of tasks they can expect, requirements they need to fulfill, and skills they need to acquire. From a scientific point of view, our results contribute to the body of knowledge by providing insights into the Austrian SCM domain, by offering starting points on how to adapt training and education programs and research projects in the university sector.}
}
@article{VESKIOJA2022102720,
title = {Implications of digitalization in facilitating socio-technical energy transitions in Europe},
journal = {Energy Research & Social Science},
volume = {91},
pages = {102720},
year = {2022},
issn = {2214-6296},
doi = {https://doi.org/10.1016/j.erss.2022.102720},
url = {https://www.sciencedirect.com/science/article/pii/S2214629622002249},
author = {Kaija Veskioja and Ralf-Martin Soe and Einari Kisel},
keywords = {Smart energy services, Implications of energy data, Multi-level perspective of sustainability transitions, Adoption of smart services, Demand-side response},
abstract = {The energy sector is digitalizing - we see a lot of smart energy services providing higher value to customers through data processing, which also increases the importance of transparency and security of data access and processing. Nevertheless, the widespread use of these services is lagging behind for enabling fundamental transitions of energy systems. This interdisciplinary article operationalises the MLP of sustainability transitions and draws together previous research on the application and implications of energy data and consumer motivation for analysing the imbalance between the supply and demand of smart energy services in the current energy transition. Besides drawing together the opportunities and challenges with energy data of 85 international smart energy services, the empirical findings present some new energy data use cases aimed especially for consumers and provide an extensive overview of additional data types with reasoning needed by service providers. These findings are complemented with the more in-depth Estonian electricity sector digitalization case study. Furthermore, we propose a list of characteristics essential for Pan-European energy data access with the main aim to open up data, activate consumers and increase the demand of smart energy services for speeding up the green energy transition.}
}
@article{BELLONMAUREL2022103524,
title = {Digital revolution for the agroecological transition of food systems: A responsible research and innovation perspective},
journal = {Agricultural Systems},
volume = {203},
pages = {103524},
year = {2022},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2022.103524},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X22001603},
author = {Véronique Bellon-Maurel and Evelyne Lutton and Pierre Bisquert and Ludovic Brossard and Stéphanie Chambaron-Ginhac and Pierre Labarthe and Philippe Lagacherie and Francois Martignac and Jérome Molenat and Nicolas Parisey and Sébastien Picault and Isabelle Piot-Lepetit and Isabelle Veissier},
keywords = {Digital revolution, Agroecological transition, Food systems, Responsible research and innovation, Interdisciplinary research},
abstract = {CONTEXT
So far, digital technology development in agriculture has mainly dealt with precision agriculture, often associated with conventional large-scale systems. The emergence of digital agriculture - based on the triptych of “new data sources / new processing methods / new inter-connection capacities (internet)” - opens up prospects for mobilizing digital technologies to accelerate the deployment of other forms of agriculture, such as agroecology. A specific research agenda must therefore be built to redirect researchers specialized in digital technologies towards these new issues. This construction is significant because digital technology and agroecology are disruptive innovations that shake up the actors' practices, agricultural innovation ecosystems, and value chains.
OBJECTIVE
An interdisciplinary group of INRAE researchers (covering 10 scientific departments) was mandated to carry out this reflection, with the objective of developing a research agenda to better couple digitalization and agroecology, in order to pave the way for responsible digital farming. The group used the framework of responsible research and innovation.
METHOD
Over 18 months, the group met monthly by video-conference, to overcome the interdisciplinarity barrier, and at three face-to-face seminars, where creative design exercises were carried out (based on a world café format, and “remember the future” method). This work gave rise to three prospective lines of research aimed at putting digitalization at the service of agroecology and local food systems. These topics prioritize research that fosters innovations in digital technology, as well as organisations and policies that (1) accelerate the agroecological transition on the farm and in the territories, (2) manage the territories as commons, (3) empower farmers and consumers. Then, the group examined these three prospective lines of research from an RRI perspective as well as three current research topics on digital agriculture (digital soil mapping, precision agriculture, technologies for food wastage reduction).
RESULTS AND CONCLUSIONS
This work allowed us to highlight the gaps between current research on digital agriculture and the RRI expectations, and the tensions (between rationalization and diversity of farming systems, between complexity of agroecological systems and the need for simplification of models, and finally between data speculation and frugality). We were also able to refine the specific scientific questions of each prospective line of research and finally to draw attention to the key levers that will have to be integrated if these research efforts are to be approached from an RRI perspective.
SIGNIFICANCE
This contribution shows RRI can be used not only to reflect on research practices but also as a framework to build a research agenda paving the way for responsible digital agriculture.}
}
@article{NGUYEN2022108381,
title = {Knowledge mapping of digital twin and physical internet in Supply Chain Management: A systematic literature review},
journal = {International Journal of Production Economics},
volume = {244},
pages = {108381},
year = {2022},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2021.108381},
url = {https://www.sciencedirect.com/science/article/pii/S0925527321003571},
author = {Tiep Nguyen and Quang Huy Duong and Truong Van Nguyen and You Zhu and Li Zhou},
keywords = {, , , },
abstract = {Physical Internet (PI) is an open global logistics system of which components are hyperconnected for increased efficiency and sustainability. Digital twin (DT), referring to the virtual representation of a physical object, is well-perceived as a key driver in the development of PI-based Supply Chain Management (SCM). Due to the capabilities of real-time monitoring and evaluation of large-scale complex systems, significant research efforts have been made to exploit values of PI/DT in SCM. Despite this, the current literature remained largely unstructured and scattered due to a lack of systematic literature reviews to synergise research findings, analyse the evolution of research fronts and extract emerging trends in the field. To address this issue, the paper deploys a bibliometric knowledge mapping approach to provide a bird's eye view of the current research status in the PI/DT-SCM area. Using CiteSpace's keyword co-occurrence network, 518 journal articles are clustered into 10 key research streams on PI/DT applications in: job shop scheduling, smart manufacturing design, PI-based SCM, manufacturing virtualisation, information management, sustainability development, data analytics, manufacturing operations management, simulation and optimisation, and assembly process planning. Based on citation burst rate, keywords representing research frontiers of the PI/DT are detected and their temporal evolutions are discussed. Likewise, some identified emerging research trends are production process and system, robotics, computer architecture, and cost. Finally, seven future research directions are suggested, which emphasise on several PI/DT-related issues, including business ecosystem, sustainability development, SC downstream management, cognitive thinking in Industry 5.0, citizen twin in digital society, and SC resilience.}
}
@article{ZHAO2022107658,
title = {How can dense results be differentiated in comprehensive evaluations? A hybrid information filtering model},
journal = {Knowledge-Based Systems},
volume = {235},
pages = {107658},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107658},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121009205},
author = {Lu-Tao Zhao and Wen-Jing Wang and Da-Kuan Li},
keywords = {Multiindex comprehensive evaluation, Information filtering, Student evaluation of teaching, Differentiation, Entropy},
abstract = {Multiindex comprehensive evaluation (MICE) is the basis for scientific and democratic decision-making. One of its basic functions is to distinguish evaluation objects to the greatest extent possible. However, the behavioral bias of evaluators results in dense evaluation results, affecting the effectiveness of evaluations. Integrating feature engineering, an evaluator distance-based information filtering model (IFED) is proposed to increase the differentiation of dense evaluation results. The IFED model first quantitatively measures the validity of evaluators by calculating the feature distance. Then, it filters evaluators by dividing the whole set of evaluators into valid and invalid categories according to the threshold distance. Finally, the generated valid dataset is inputted into a traditional MICE model. An empirical analysis is conducted on the teaching evaluation dataset of universities to verify the performance of the model. The IFED model identified 22.44% of invalid evaluators, which led to a 43.44% increase in the differentiation of the evaluation results. The modified entropy weighting method based on the IFED model increased the stability of student evaluations of teaching by 27.08%. Finally, we confirmed the robustness of the IFED model by replacing the entropy weighting method with three other MICE methods.}
}
@article{ZHANG202246,
title = {Adaptive deep learning for network intrusion detection by risk analysis},
journal = {Neurocomputing},
volume = {493},
pages = {46-58},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.04.061},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222004337},
author = {Lijun Zhang and Xingyu Lu and Zhaoqiang Chen and Tianwei Liu and Qun Chen and Zhanhuai Li},
keywords = {Network intrusion detection, Risk analysis, Adaptive deep learning},
abstract = {With increasing connectedness, network intrusion has become a critical security concern for modern information systems. The state-of-the-art performance of Network Intrusion Detection (NID) has been achieved by deep learning. Unfortunately, NID remains very challenging, and deep models may still mislabel many activities in real networks. Therefore, there is a need for risk analysis, which aims to know which activities may be mislabeled and why. In this paper, we propose a novel solution of interpretable risk analysis for NID that can rank the activities by their mislabeling risk. Built upon the existing framework of LearnRisk, it first extracts interpretable risk features and then trains a risk model by a learning-to-rank objective. It constructs risk features based on domain knowledge of network intrusion as well as statistical characteristics of activities. Furthermore, we demonstrate how to leverage risk analysis to improve prediction accuracy of deep models. Specifically, we present an adaptive training approach for NID that can effectively fine-tune a deep model towards a particular workload by minimizing its misprediction risk. Finally, we empirically evaluate the performance of the proposed solutions on real benchmark data. Our extensive experiments have shown that the proposed solution of risk analysis can identify mislabeled activities with considerably higher accuracy than the existing alternatives, and the proposed solution of adaptive training can effectively improve the performance of deep models by considerable margins in both offline and online settings.}
}
@article{DONG2022105435,
title = {Recent text-based research and applications in railways: A critical review and future trends},
journal = {Engineering Applications of Artificial Intelligence},
volume = {116},
pages = {105435},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.105435},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622004250},
author = {Kaitai Dong and Igor Romanov and Colin McLellan and Ahmet F. Esen},
keywords = {Natural language processing, Machine learning, Railway, Text-based analysis, Critical review},
abstract = {In the railway industry, a significant amount of data is stored in the textual format. The advanced development of natural language processing and text mining techniques enable automatic knowledge extraction and discovery from such documents. This paper presents a systematic review with quantitative and qualitative analyses to understand the current state of text-based research in the context of railway transport. The paper collects 107 relevant publications in the past decade and identifies different channels for researchers to obtain text data in railways and the corresponding text analysis application use-cases. Moreover, a comprehensive analysis is performed on the state-of-the-art machine learning and natural language processing methods. Four key research directions, namely multilingual NLP, digital maintenance, external data integration, and railway-centred solution pipeline, are identified from Siemens Mobility’s perspective to highlight the most prominent challenges faced in the railway industry.}
}
@article{FAN2022103262,
title = {Road grade estimation based on Large-scale fuel consumption data of connected vehicles},
journal = {Transportation Research Part D: Transport and Environment},
volume = {106},
pages = {103262},
year = {2022},
issn = {1361-9209},
doi = {https://doi.org/10.1016/j.trd.2022.103262},
url = {https://www.sciencedirect.com/science/article/pii/S1361920922000918},
author = {Pengfei Fan and Guohua Song and Zijun Zhu and Yizheng Wu and Zhiqiang Zhai and Lei Yu},
keywords = {Road Grade, Fuel Consumption, Vehicle Specific Power, Connected Vehicle},
abstract = {Road grade is crucial in vehicle control and emission studies but challenging to obtain in large-scale road networks due to current methods’ expensive deployment costs or limited accuracy. This paper proposed a scale-deployable and cost-efficient road grade estimation solution based on the fuel consumption rate (FCR) difference between flat and graded roads. Real-world road grades from design drawings and 261,814 second-by-second vehicle operating data from 680 light-duty vehicles were collected to examine the proposed method’s performance. Sensitivity tests for vehicle types and sample sizes were conducted. Results show that (1) the proposed method acquired road grade with an accuracy of 0.12% mean absolute error (MAE), (2) in positive vehicle specific power (VSP) bins, a 1% road grade caused an average 16% FCR change, and (3) larger-scale fuel consumption data contributed to reducing estimation error which converged from 0.25% to 0.12% as the segment passes increased from 50 to 400.}
}
@article{ROESSLER2022105569,
title = {A machine learning approach for modelling the occurrence of Galba truncatula as the major intermediate host for Fasciola hepatica in Switzerland},
journal = {Preventive Veterinary Medicine},
volume = {200},
pages = {105569},
year = {2022},
issn = {0167-5877},
doi = {https://doi.org/10.1016/j.prevetmed.2022.105569},
url = {https://www.sciencedirect.com/science/article/pii/S0167587722000022},
author = {Anne S. Roessler and Andreas W. Oehm and Gabriela Knubben-Schweizer and Andreas Groll},
keywords = {trematodes, liver fluke, spatial risk model, intermediate host, snail habitats, cattle diseases},
abstract = {Fasciolosis caused by the trematode Fasciola hepatica is an important parasitosis in both livestock and humans across the globe. Chronic infections in cattle are associated with considerable economic losses. As a prerequisite for an effective control and prevention of fasciolosis in cattle fine-scale predictive models on farm-level are needed. Since disease transmission will only occur where the mollusc intermediate host is present, the objective of our research was to develop a regression model that allows to predict the local presence or absence of Galba truncatula as principal intermediate host for Fasciola hepatica in Switzerland. By implementing generalized linear mixed models (GLMMs) a total amount of 70 variables were analysed for their potential influence on the likelihood πi of finding Galba truncatula at a certain site. Important site-specific features could be considered by selecting suitable modelling procedures. The statistical software R was used to conduct regression analysis, performing the grplasso and the glmmLasso method. The selection of parameters was based on 10-fold cross validation and the Bayesian Information Criterion (BIC). This yielded a total number of 19 potential predictor variables for the grplasso and 13 variables for the glmmLasso model, which also included random effects. Nine variables appeared to be relevant predictors for the occurrence of Galba truncatula in both models. These included reed/humid area, spring water, water bodies within a 100 m radius, and trees/bushes as powerful positive predictors. High soil depth, temperatures frequently exceeding 30 °C in the year preceding the search for snails and temperatures below 0 °C especially in the second year before were identified to exert an adverse effect on the occurrence of Galba truncatula. Temperatures measured near ground level proved to be more powerful predictors than macroclimatic parameters. Precipitation values seemed to be of minor impact in the given setting. Both regression models may be convenient for a fine-scale prediction of the occurrence of Galba truncatula, and thus provide useful approaches for the development of future spatial transmission models, mapping the risk of fasciolosis in Switzerland on farm-level.}
}
@article{BOUHLAL2022819,
title = {The internet of things for smart ports},
journal = {Procedia Computer Science},
volume = {203},
pages = {819-824},
year = {2022},
note = {17th International Conference on Future Networks and Communications / 19th International Conference on Mobile Systems and Pervasive Computing / 12th International Conference on Sustainable Energy Information Technology (FNC/MobiSPC/SEIT 2022), August 9-11, 2022, Niagara Falls, Ontario, Canada},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.07.123},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922007281},
author = {Amine BOUHLAL and Rachida AITABDELOUAHID and Abdelaziz MARZAK},
keywords = {Internet of things, Tangier Med Port, vessels, Containers, Terminals},
abstract = {Researchers have investigated the impact of the Internet of Things on port performance in order to identify IoT applications and determine any changes that may be needed. Tangier Med Port will be able to compete better than its rivals, significantly improving its efficiency. A real-time tracking and monitoring application can be used to track vessels and containers in the first application. In addition to managing traffic or allocating priority and services to vessels moving through the port jurisdiction, information about vessels and containers can also be utilized to stack containers optimally at the port terminals. Thirdly, the Internet of Things facilitates the transition from manual to automated ports/terminals. Fourth, they can spend less time interacting with customers daily. Furthermore, the increased exchange of data will allow existing processes to be optimized. If all the likely threats can be dealt with, the aforementioned points above may have profound effects on the performance of Tangier Med Port, especially its efficiency in its principal activity, which is container activity. This development should be driven by all stakeholders of Tangier Med Port. When compared to its two main rivals, Algeciras and Valencia, Tanger Med can become the most attractive port if it encourages other parties to follow the development of the Internet of Things. Additionally, Port Tanger Med has a geographical advantage.}
}
@article{HE2022104509,
title = {Unique distribution pattern and δ13C signature of des-A-triterpenoids from Lake Wuliangsu: Source and paleoenvironmental implications},
journal = {Organic Geochemistry},
volume = {174},
pages = {104509},
year = {2022},
issn = {0146-6380},
doi = {https://doi.org/10.1016/j.orggeochem.2022.104509},
url = {https://www.sciencedirect.com/science/article/pii/S0146638022001437},
author = {Yuxin He and Qingfeng Zhao and Dayang Sun},
keywords = {A-triterpenoids, Compound specific carbon isotope, Submerged macrophytes, Microbial activities, Lake Wuliangsu},
abstract = {des-A-triterpenoids have been widely recognized as indicators of terrestrial vascular angiosperms and microbial activities. However, recent studies also suggested complex sources for des-A-triterpenoids in lakes and peatlands, thus complicating their applications in paleoenvironmental reconstructions. Here we present the occurrences of aliphatic and aromatic des-A-triterpenoids from a ∼160-year sedimentary core in Lake Wuliangsu in the upper reaches of the Yellow River, China. In these sediments, des-A-triterpane was not detected, whereas di-unsaturated des-A-triterpenes are more abundant than mono-unsaturated des-A-triterpenes. The δ13C values of di-unsaturated des-A-triterpenes range from –23.0‰ to –17.6‰, with an average value of –21.0‰. Accordingly, aliphatic des-A-triterpenoids from Lake Wuliangsu show a unique distribution pattern and more positive δ13C signatures compared with those sourced from terrestrial vascular angiosperms. By comparing the concentrations and δ13C values of des-A-triterpenoids with n-alkanes and triterpenoids, we suggest that des-A-triterpenoids from Lake Wuliangsu sediments might be degraded from oleanenone, which was produced by submerged macrophytes. In this sense, aliphatic des-A-triterpenes in Lake Wuliangsu could represent a novel proxy for submerged macrophytes, which would be more precise than those of mid-chain n-alkanes, considering that mid-chain n-alkanes are usually from multiple sources. Our results also demonstrate the importance of strong aerobic bacteria activities and photodegradation for the formation of di-unsaturated des-A-triterpenes. The aromatization process of aliphatic des-A-triterpenes show contrasting variation characteristic with the formation of aliphatic des-A-triterpenes over the past ∼160 years, probably due to different rates (production vs consumption of di-unsaturated des-A-triterpenes) and prerequisites (aerobic vs anaerobic conditions) for these two synthesis pathways.}
}
@article{YANG2022102230,
title = {A digital twin-driven hybrid approach for the prediction of performance degradation in transmission unit of CNC machine tool},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {73},
pages = {102230},
year = {2022},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2021.102230},
url = {https://www.sciencedirect.com/science/article/pii/S0736584521001125},
author = {Xin Yang and Yan Ran and Genbao Zhang and Hongwei Wang and Zongyi Mu and Shengguang Zhi},
keywords = {Digital twin, Data-driven, Wear, Simulation, Performance degradation, CNCMT},
abstract = {Precision performance prediction of transmission system is considered as a key technology to modern equipment health management. Given the importance of maintaining a transmission system's precision, this paper presents a hybrid approach framework driven by digital twin technology (DT), to predict performance degradation. Firstly, a DT model based on meta-action theory is established, and real-time monitoring and digital simulation, driven by DT data, is realized in order to analyze the precision of the transmission units in machine tools. Secondly, the wear of gear in transmission unit is studied through Achard wear theory, which considered the comprehensive influence of gear load and speed on surface wear of the gear pair tooth, based on the model driving method. The performance degradation of the transmission unit is obtained by using the RBF neural network algorithm based on the data-driven method to extrapolate the wear data to the field-measurable precision index value. In addition, the hybrid predictive approach of the performance degradation model through the particle filter algorithm is built, and the real-time data is used to update the current state estimation to improve the prediction accuracy. By combining the mechanism of the physical degradation processes with the real-time and historical data and turning them into a cooperative architecture, this prediction method uses the complementary advantages offered by the fusion of these methods to bridge the link between data-driven prediction and model-based prediction. Finally, the method has been successfully applied to the precision prediction of the transmission unit in CNCMT turntable, and it is compared with the single prediction method to verify the effectiveness and feasibility.}
}
@article{WANG2022348,
title = {Blockchain Empowered Federated Learning for Data Sharing Incentive Mechanism},
journal = {Procedia Computer Science},
volume = {202},
pages = {348-353},
year = {2022},
note = {International Conference on Identification, Information and Knowledge in the internet of Things, 2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.04.047},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922005816},
author = {Zexin Wang and Biwei Yan and Anming Dong},
keywords = {Federated learning, Blockchain, Incentive Mechanism, Shaply Value},
abstract = {In the machine learning, data sharing between different participants can increase the amount of data, improve the quality of the dataset, and thereby improve the quality of the model. Under the condition of data supervision, federated learning, as a distributed machine learning, aims to protect data while training models through collaboration among all parties to achieve data sharing and improve model quality. However, there are still some issues. For instance, the lack of trust between the participants makes it impossible to establish a secure and reliable sharing mechanism. In addition, how to fairly share the benefits generated by the model, identify honest participants and punish malicious participants is still a challenge. In this paper, we propose a new federated learning scheme based on blockchain architecture for federated learning data sharing. Moreover, an incentive mechanism based on reputation points and Shaply values is proposed to improve the sustainability of the federated learning system, which provides a credible participation mechanism for data sharing based on federated learning and fair incentives. The experimental results and analysis show that the loss of federated learning is more smooth than that of centralized machine learning.}
}
@article{CHEN2022100336,
title = {An Intelligent Government Complaint Prediction Approach},
journal = {Big Data Research},
volume = {30},
pages = {100336},
year = {2022},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2022.100336},
url = {https://www.sciencedirect.com/science/article/pii/S2214579622000302},
author = {Siqi Chen and Yanling Zhang and Bin Song and Xiaojiang Du and Mohsen Guizani},
keywords = {Machine learning, Text classification, Government complaint prediction, Automatic label correction},
abstract = {Recent advances in machine learning (ML) bring more opportunities for greater implementation of smart government construction. However, there are many challenges in terms of government data application due to the previous nonstandard records and man-made errors. In this paper, we propose a practical intelligent government complaint prediction (IGCP) framework that helps governments quickly respond to citizens' consultations and complaints via ML technologies. In addition, we put forward an automatic label correction method and demonstrate its effectiveness on the performance improvement of intelligent government complaint prediction task. Specifically, the central server collects the interaction records from users and departments and automatically integrates them by the label correction approach which is designed to evaluate the similarity between different labels in data, and merge highly similar labels and corresponding samples into their most similar category. Based on those refined data, the central server quickly generates accurate solutions to complaints through text classification algorithms. The main innovation of our approach is that we turn the task of government complaint distribution into a text classification problem which is uniformly coordinated by the central server, and employ the label correction approach to correct redundant labels for training better models based on limited complaint records. To explore the influences of our approach, we evaluate its performance on real-world government service records provided by our collaborator. The experimental results demonstrate the prediction task which uses the label correction algorithm achieves significant improvements on almost all metrics of the classifier.}
}
@article{KAUSAR202216,
title = {Automated Machine Learning based Elderly Fall Detection Classification},
journal = {Procedia Computer Science},
volume = {203},
pages = {16-23},
year = {2022},
note = {17th International Conference on Future Networks and Communications / 19th International Conference on Mobile Systems and Pervasive Computing / 12th International Conference on Sustainable Energy Information Technology (FNC/MobiSPC/SEIT 2022), August 9-11, 2022, Niagara Falls, Ontario, Canada},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S187705092200610X},
author = {Firdous Kausar and Medhat Awadalla and Mostefa Mesbah and Taif AlBadi},
keywords = {Fall Detection, Automated Machine Learning, Classification Learner, Optimized Classifier},
abstract = {As we grow older, one of the most concerning aspects of our lives becomes increasingly challenging to manage our health. Fall is a leading cause of health problems or death in the elderly population. Using a wearable sensors device, this research presents a strategy for identifying and distinguishing fall activities from activities of daily living (ADL) in older persons. The conventional Machin learning method was applied by extracting features from telemetry data after pre-processing, and feature extraction. It is then compared to non-coding Automated Machine Learning (AutoML) method, where all the selected classifiers get automatically optimized. Furthermore, machine learning algorithms such as Support Vector Machine, K-Nearest Neighbor, Random Forest tree, and Artificial Neural Network are used to categorize acceleration signals as falling or regular activity. The test results indicate that AutoML can predict exceptionally accurate results in binary classifications with 99.9% accuracy on three of the four machine learning techniques it was tested against.}
}
@article{HU2022113343,
title = {Association between outdoor artificial light at night and sleep duration among older adults in China: A cross-sectional study},
journal = {Environmental Research},
volume = {212},
pages = {113343},
year = {2022},
issn = {0013-9351},
doi = {https://doi.org/10.1016/j.envres.2022.113343},
url = {https://www.sciencedirect.com/science/article/pii/S0013935122006703},
author = {Kejia Hu and Wanlu Li and Yunquan Zhang and Huashuai Chen and Chen Bai and Zhenchun Yang and Thiess Lorenz and Keyang Liu and Kokoro Shirai and Jinglu Song and Qi Zhao and Yali Zhao and Junfeng (Jim) Zhang and Jing Wei and Jiahao Pan and Jin Qi and Tingting Ye and Yi Zeng and Yao Yao},
keywords = {Nighttime light, Outdoor light, ALAN, Sleep duration, Sleep, China},
abstract = {Background
Light after dusk disrupts the circadian rhythms and shifts the timing of sleep later; but it is unknown whether outdoor artificial light at night (ALAN) affects sleep quality. This study aimed to explore the association between residential outdoor ALAN and sleep duration in a nationally representative sample of Chinese older adults.
Methods
We examined the cross-sectional associations of outdoor ALAN with self-reported sleep duration in 13,474 older adults participating in the 2017–2018 wave of the Chinese Longitudinal Healthy Longevity Survey (CLHLS). Outdoor ALAN exposure was estimated at the residence level using satellite images. We applied generalized linear mixed models to investigate the association between ALAN exposure and sleep duration. We performed stratified analyses by age, sex, education, and household income levels. Moreover, we used multi-level logistic regression models to investigate the effects of ALAN on the short sleep duration (≤6 h) and the long sleep duration (>8 h), respectively, in reference to sleep for >6–8 h per day.
Results
We found a significant association between outdoor ALAN intensity and sleep duration. The highest quartile of ALAN was associated with 17.04 (95% CI: 9.42–24.78) fewer minutes of sleep as compared to the lowest quartile. The reductions in sleep duration per quartile change in ALAN were greater in the young old (≥65–85 years) and in those with higher levels of education, and those with higher household income, respectively. We did not detect a sex difference. In addition, those in the highest quartile of ALAN were more likely to report a 25% (95% CI: 10%–42%) increase in short sleep (<6 h), and a 21% (95% CI: 9%–31%) decrease in long sleep (>8 h).
Conclusions
Increasing outdoor nighttime light intensity surrounding residences was associated with shorter sleep duration in older residents in China. This finding implies the importance of urban outdoor artificial light management as a potential means to lower the public health burden of sleep disorders.}
}
@article{MEAD2022100168,
title = {Generalised network architectures for environmental sensing: Case studies for a digitally enabled environment},
journal = {Array},
volume = {14},
pages = {100168},
year = {2022},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2022.100168},
url = {https://www.sciencedirect.com/science/article/pii/S2590005622000303},
author = {M.I. Mead and M. Bevilacqua and C. Loiseaux and S.H. Hallett and S. Jude and C. Emmanouilidis and J. Harris and P. Leinster and S. Mutnuri and T.H. Tran and L. Williams},
keywords = {Ubiquitous sensor networks, Network analytics, Integrated sensing, Network policy considerations, Living laboratory, Digital environment, Internet of things, Urban observatory},
abstract = {A digitally enabled environment is a setting which incorporates sensors coupled with reporting and analytics tools for understanding, observing or managing that environment. Large scale data collection and analysis are a part of the emerging digitally enabled approach for the characterisation and understanding of our environment. It is recognised as offering an effective methodology for addressing a range of complex and interrelated social, economic and environmental concerns. The development and construction of the approach requires advances in analytics control linked with a clear definition of the issues pertaining to the interaction between elements of these systems. This paper presents an analysis of selected issues in the field of analytics control. It also discusses areas of progress, and areas in need of further investigation as sensing networks evolve. Three case studies are described to illustrate these points. The first is a physical analytics test kit developed as a part of the “Reinvent the Toilet Challenge” (RTTC) for process control in a range of environments. The second case study is the Cranfield Urban Observatory that builds on elements of the RTTC and is designed to allow users to develop user interfaces to monitor, characterise and compare a variety of environmental and infrastructure systems plus behaviours (e.g., water distribution, power grids). The third is the Data and Analytics Facility for National Infrastructure, a cloud-based high-performance computing cluster, developed to receive, store and present such data to advanced analytical and visualisation tools.}
}
@incollection{HOVENGA2022239,
title = {Chapter 10 - Guideline and knowledge management in a digital world},
editor = {Evelyn Hovenga and Heather Grain},
booktitle = {Roadmap to Successful Digital Health Ecosystems},
publisher = {Academic Press},
pages = {239-270},
year = {2022},
isbn = {978-0-12-823413-6},
doi = {https://doi.org/10.1016/B978-0-12-823413-6.00012-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128234136000124},
author = {Evelyn Hovenga},
keywords = {Knowledge, Learning health systems, Ontology, Artificial intelligence, Decision support, Governance, Quality, Computing, Concept representation},
abstract = {Knowledge represents primary sources of truth, a crucial, valuable asset supporting the health system. The current digital health revolution has sped up the acquisition of new knowledge. This is far too much for any one person to process. Traditionally, this has taken too long to adopt as dissemination methods are failing to streamline timely access and use. Health-related knowledge needs to support decision-making at any level within the healthcare system. No clinician has the time to discover and wade through multiple PDF documents in order to access the best available or real-time evidence. Computers need to be enabled to deliver this by facilitating querying anytime, integrating and using clinical guidelines and protocols metadata to support automation in decision support systems. Electronic knowledge processing, governance and use, at points of decision-making, and the supporting standards and legislative requirements for a well-functioning digital health ecosystem to benefit the population at large are explored in this chapter.}
}
@article{SHUAI2022100301,
title = {A Full-Sample Clustering Model Considering Whole Process Optimization of Data},
journal = {Big Data Research},
volume = {28},
pages = {100301},
year = {2022},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2021.100301},
url = {https://www.sciencedirect.com/science/article/pii/S2214579621001180},
author = {Yong Shuai},
keywords = {Optimization of whole process, Principal component analysis, Self organizing maps, K-means cluster, Collaborative filtering},
abstract = {With the continuous increase of data volume and data dimensions, it becomes more and more difficult to improve the accuracy and interpretability of the algorithm only from the clustering algorithm itself. In order to improve the accuracy of the clustering algorithm and improve the interpretability of the clustering results, we propose an Improved feature selection and combined clustering model considering whole process optimization. In this model, we processed the data from the whole process of data mining and carried out clustering analysis. Firstly, we started data preprocessing, and then used the feature selection algorithm of text weight + principal component analysis (PCA) to reduce the feature dimension and obtain important features and data sets for clustering. Secondly, we used the improved Self organizing maps (SOM) neural network and K-means clustering combination model to perform clustering analysis and established clustering algorithm evaluation indicators. Thirdly, we used collaborative filtering to cluster data sets that included missing data to ensure that all sample data can obtain results. Finally, through case analysis, it was verified that the model proposed in this paper had high clustering accuracy and interpretability.}
}
@article{PENG2022,
title = {East Asian new techno-humanities report},
journal = {New Techno Humanities},
year = {2022},
issn = {2664-3294},
doi = {https://doi.org/10.1016/j.techum.2022.100003},
url = {https://www.sciencedirect.com/science/article/pii/S2664329422000012},
author = {Qinglong Peng and Man Zhou},
keywords = {Humanities, New techno perspective, Digital humanities, East Asia},
abstract = {Overall, the development of digital humanities (DH) in Asia is slower than that in Europe and North America, while within East Asia, specifically China, Japan, and South Korea, there are differences in DH's acceptance and progress. This paper reviews the history and current situation of DH in China, Japan, and South Korea. In comparison to Japan and South Korea, the paper also analyzes the characteristics, problems, and possible causes of the problems presented by Chinese DH. Such a retrospective process demonstrates not only the integration and cooperation between humanities and technology, but also the transformation of humanities in the perspective of new technologies. The transformation, whether active or passive, has led many Chinese humanities scholars to worry and reflect, which is one of the focuses of this paper.}
}
@incollection{FOTOPOULOS2022241,
title = {Chapter 8 - The edge-cloud continuum in wearable sensing for respiratory analysis},
editor = {Rui Pedro Paiva and Paulo de Carvalho and Vassilis Kilintzis},
booktitle = {Wearable Sensing and Intelligent Data Analysis for Respiratory Management},
publisher = {Academic Press},
pages = {241-271},
year = {2022},
isbn = {978-0-12-823447-1},
doi = {https://doi.org/10.1016/B978-0-12-823447-1.00002-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128234471000026},
author = {Anaxagoras Fotopoulos and Pantelis Z. Lappas and Alexis Melitsiotis},
keywords = {Artificial intelligence, Edge computing, Internet of Medical Things, Multisource fusion, P4 health care},
abstract = {Edge computing is seen as a set of remotely available computer system resources that drive the computing power at the source of data to improve energy efficiency and security, as well as decrease latency. Although the computation capability of biomedical wearables has increased extremely during the past decade, it is still challenging to perform sophisticated artificial intelligence (AI) algorithms in a resource-constrained environment for energy-efficiency and (near) real-time processing, along the edge-cloud continuum. The aim of this chapter is twofold. The first is to outline the role of edge computing on the Internet of Medical Things, in which wearable technologies are used as the sensory equipment for respiratory analysis, at the transition of patient monitoring from hospital to home. The second is to discuss the potential of explainable AI in the P4 health-care context for respiratory analysis, by highlighting computational intelligence and multisource fusion approaches to achieve continuous monitoring of respiratory analysis.}
}
@incollection{SUI2022113,
title = {Chapter 4 - Data fusion technologies for MaaS},
editor = {Haoran Zhang and Xuan Song and Ryosuke Shibasaki},
booktitle = {Big Data and Mobility as a Service},
publisher = {Elsevier},
pages = {113-142},
year = {2022},
isbn = {978-0-323-90169-7},
doi = {https://doi.org/10.1016/B978-0-323-90169-7.00005-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323901697000051},
author = {Yi Sui and Haoran Zhang and Wenxiao Jiang and Rencheng Sun and Fengjing Shao},
keywords = {MaaS, Data fusion, Deep learning, Fusion strategies, Matrix factorization},
abstract = {Mobility as a Service (MaaS) connects passengers and drivers by providing online ride services through an internet-based platform, which has been popular around the world. In the MaaS system, a diversity of datasets from different sources are collected and processed for data mining tasks. However, data from different sources have multi-modal characteristics. How to effectively fuse them to support data mining tasks is uneasy work. This chapter provides a technical review of advanced data fusion models used in the MaaS applications. First, we summarize the data types in the MaaS system and their input formula for data fusion methods. Second, data fusion methods are classified into two categories: deep learning-based methods and decomposition-based methods. For deep learning-based methods, basic model units and widely used data fusion strategies are discussed. For decomposition-based methods, we introduce the basic mathematics tools and their applications. Finally, we discuss challenging problems and future study trends. We believe this review will facilitate future studies in the data fusion in the MaaS system.}
}
@incollection{SANNI202225,
title = {Chapter 3 - Advances in data-centric intelligent systems for air quality monitoring, assessment, and control},
editor = {Gonçalo Marques and Joshua O. Ighalo},
booktitle = {Current Trends and Advances in Computer-Aided Intelligent Environmental Data Engineering},
publisher = {Academic Press},
pages = {25-58},
year = {2022},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-323-85597-6},
doi = {https://doi.org/10.1016/B978-0-323-85597-6.00021-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323855976000215},
author = {Samuel Eshorame Sanni and Emmanuel Emeka Okoro and Emmanuel Rotimi Sadiku and Babalola Aisosa Oni},
keywords = {Air pollution, air quality prediction, artificial intelligence, computer-aided algorithms, data-centric systems, machine learning, particle dispersion},
abstract = {Air pollution is currently an issue of great concern due to the increase in anthropogenic, economic, industrial, and social activities that release high concentrations of aerosols, NOx, CO2, and greenhouse gases into the environment. According to reports from the World Health Organization (2019), about 91% of the global population resides in areas affected by poor air quality, which results in poor health conditions, thus causing about 7 million deaths annually and the destruction of the ecosystem. Despite the myriad of proposals to curb these growing concerns caused by air pollutants, air pollution seems to know no bounds because their causatives in terms of the activities that lead to air pollution including manufacturing, incineration, combustion of coal etc. are necessary for human existence and sustenance. Strategic alteration of production patterns and the replacement of conventional heating systems have been proposed as air pollution control measures; however, due to the increased demands posed by basic necessities such as transportation, food, deforestation, and industrial processes, it has become necessary to use smart high-performance data-centric systems/artificial intelligence as air pollution forecasting tools that can examine the sources of these pollutants, predict their prevalence, determine their eventual consequences, as well as proffer informed decisions for contingency actions. In this chapter, topics covered include “deep- and machine-learning applications in air quality modeling, air quality prediction, modeling of particle dispersion/filters, heating, ventilation, and air-conditioning systems, industrial air quality control systems concerning data-centric intelligent systems, as well as previous and recent developments and application of these systems in air quality monitoring, assessment, and pollution control.”}
}
@incollection{SIDDIQUI2022169,
title = {Chapter 12 - Application of artificial intelligence and machine learning in blockchain technology},
editor = {Rajiv Pandey and Sunil Kumar Khatri and Neeraj kumar Singh and Parul Verma},
booktitle = {Artificial Intelligence and Machine Learning for EDGE Computing},
publisher = {Academic Press},
pages = {169-185},
year = {2022},
isbn = {978-0-12-824054-0},
doi = {https://doi.org/10.1016/B978-0-12-824054-0.00001-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128240540000010},
author = {Zeeshan Ali Siddiqui and Mohd Haroon},
keywords = {Blockchain, Machine learning, Artificial intelligence, Edge computing, Architecture},
abstract = {Blockchain technology is a distributed, decentralized, immutable ledger. It is used to store encrypted data; on the other hand, in artificial intelligence, human natural intelligence can be simulated. All the characteristics of the human brain may be programmed with artificial intelligence. Blockchain technology may be thought of as a body and artificial intelligence as its brain. In blockchain technology, if artificial intelligence approaches are used, then data collection, data enabling, data analytic, and decision-making of data collection can be improved. With both these technologies, we will be able to affect and enact upon data in different ways. Also, they may be proven as game-changers in the exploitation of data. At the same time, machine learning approaches may enhance the architecture of blockchain technology. Blockchain technology can make artificial intelligence further rational and comprehensible. We can trace the trail of decisions and determine why a particular decision was taken by a machine learning algorithm and on the other hand, blockchain technology records data and variables that go through in the decision-making process in machine learning. In this chapter, we have discussed key concepts of blockchain technology and applications of artificial intelligence and machine learning in the blockchain. This chapter also investigated edge computing as a potential use case of blockchain technology.}
}
@article{RAMMER2022104555,
title = {Artificial intelligence and industrial innovation: Evidence from German firm-level data},
journal = {Research Policy},
volume = {51},
number = {7},
pages = {104555},
year = {2022},
issn = {0048-7333},
doi = {https://doi.org/10.1016/j.respol.2022.104555},
url = {https://www.sciencedirect.com/science/article/pii/S0048733322000798},
author = {Christian Rammer and Gastón P. Fernández and Dirk Czarnitzki},
keywords = {Artificial Intelligence, Innovation, CIS data, Germany},
abstract = {This paper analyses the link between the use of Artificial Intelligence (AI) and innovation performance in firms. Based on firm-level data from the German part of the Community Innovation Survey (CIS) 2018, we examine the role of different AI methods and application areas in innovation. The results show that 5.8% of firms in Germany were actively using AI in their business operations or products and services in 2019. We find that the use of AI is associated with annual sales with world-first product innovations in these firms of about €16 billion (i.e. 18% of total annual sales of world-first innovations). In addition, AI technologies have been used in process innovation that contributed to about 6% of total annual cost savings of the German business sector. Firms that apply AI broadly (using different methods for different applications areas) and that have already several years of experience in using AI obtain significantly higher innovation results. These positive findings on the role of AI for innovation have to be interpreted with caution as they refer to a specific country (Germany) in a situation where AI started to diffuse rapidly.}
}
@article{POURMEHDI2022107808,
title = {Analysis and evaluation of challenges in the integration of Industry 4.0 and sustainable steel reverse logistics network},
journal = {Computers & Industrial Engineering},
volume = {163},
pages = {107808},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2021.107808},
url = {https://www.sciencedirect.com/science/article/pii/S0360835221007129},
author = {Mohammad Pourmehdi and Mohammad Mahdi Paydar and Pezhman Ghadimi and Amir Hossein Azadnia},
keywords = {Steel industry, Industry 4.0, Adoption challenges, Reverse logistics, Sustainability, Interpretive structural modelling, Fuzzy analytical network process},
abstract = {Industry 4.0 (I4.0) is a comparatively new phenomenon, and it is most probable that developing countries would face challenges in adapting it for improving the processes of supply chains and moving toward sustainability. The steel industry is the core of industrial growth, and it has an indispensable role in the development of countries. Steel is a highly recyclable product, meaning that it can be reused infinitely, increasing the significance of its reverse logistics. Although many studies have been conducted in the area of I4.0 and supply chain management, less attention has been devoted to finding and analyzing potential challenges of I4.0 technologies integration in steel reverse logistics activities. Therefore, this study is conducted to identify and analyse the challenges to efficient integration of I4.0 and sustainable steel reverse logistics system. Data collection is conducted with the assistance of qualified experts familiar with the steel supply chain and I4.0 concept. The interrelations of challenges are specified by Interpretive Structural Modeling, and the final ranking of challenges is determined through the Fuzzy Analytical Network Process. After validating the completed questionnaires, the absence of experts in I4.0, lack of clear comprehension of I4.0 concepts, training programs, and governmental policies and support are determined as the most critical challenges. Finally, the results and discussion, which can help practitioners in the efficient adoption of I4.0 to have a sustainable reverse logistics system, are presented.}
}
@article{BI2022,
title = {Achieving dynamic privacy measurement and protection based on reinforcement learning for mobile edge crowdsensing of IoT},
journal = {Digital Communications and Networks},
year = {2022},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2022.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S2352864822001614},
author = {Renwan Bi and Mingfeng Zhao and Zuobin Ying and Youliang Tian and Jinbo Xiong},
keywords = {Mobile edge crowdsensing, Dynamic privacy measurement, Personalized privacy threshold, Privacy protection, Reinforcement learning},
abstract = {With the maturity and development of 5G field, Mobile Edge CrowdSensing (MECS), as an intelligent data collection paradigm, provides a broad prospect for various applications in IoT. However, sensing users as data uploaders lack a balance between data benefits and privacy threats, leading to conservative data uploads and low revenue or excessive uploads and privacy breaches. To solve this problem, a Dynamic Privacy Measurement and Protection (DPMP) framework is proposed based on differential privacy and reinforcement learning. Firstly, a DPM model is designed to quantify the amount of data privacy, and a calculation method for personalized privacy threshold of different users is also designed. Furthermore, a Dynamic Private sensing data Selection (DPS) algorithm is proposed to help sensing users maximize data benefits within their privacy thresholds. Finally, theoretical analysis and ample experiment results show that DPMP framework is effective and efficient to achieve a balance between data benefits and sensing user privacy protection, in particular, the proposed DPMP framework has 63% and 23% higher training efficiency and data benefits, respectively, compared to the Monte Carlo algorithm.}
}
@article{RAMU2022103663,
title = {Federated learning enabled digital twins for smart cities: Concepts, recent advances, and future directions},
journal = {Sustainable Cities and Society},
volume = {79},
pages = {103663},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103663},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721009264},
author = {Swarna Priya Ramu and Parimala Boopalan and Quoc-Viet Pham and Praveen Kumar Reddy Maddikunta and Thien Huynh-The and Mamoun Alazab and Thanh Thi Nguyen and Thippa Reddy Gadekallu},
keywords = {Digital Twin, Federated Learning, Internet of Things, Virtual replica, Smart city},
abstract = {Recent advances in Artificial Intelligence (AI) and the Internet of Things (IoT) have facilitated continuous improvement in smart city based applications such as smart healthcare, transportation, and environmental management. Digital Twin (DT) is an AI-based virtual replica of the real-world physical entity. DTs have been successfully adopted in manufacturing and industrial sectors, they are however still at the early stage in smart city based applications. The major reason for this lag is the lack of trust and privacy issues in sharing sensitive data. Federated Learning (FL) is a technology that could be integrated along with DT to ensure privacy preservation and trustworthiness. This paper focuses on the integration of these two promising technologies for adoption in real-time and life-critical scenarios, as well as for ease of governance in smart city based applications. We present an extensive survey on the various smart city based applications of FL models in DTs. Based on the study, some prominent challenges and future directions are presented for better FL–DT integration in future applications.}
}
@article{KIM2022117405,
title = {Accurate and prompt answering framework based on customer reviews and question-answer pairs},
journal = {Expert Systems with Applications},
volume = {203},
pages = {117405},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117405},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422007473},
author = {Eun Kim and Hyejung Yoon and Jungeun Lee and Misuk Kim},
keywords = {Question answering, E-commerce market, Customer reviews, Natural language processing},
abstract = {As e-commerce markets have gradually expanded, online shopping malls have provided various services aiming to secure competitiveness. A service for providing an accurate and prompt response when a customer writes an inquiry regarding a product represents a space directly connected to the customer and plays an important role, as it is directly related to product sales. However, the current online shopping mall answering service has disadvantages, e.g., it takes time for an administrator to write an answer directly, or to provide an answer within a set of answers. In this paper, we propose an answer framework for solving this problem, based on customer reviews. When a user writes a query, the framework provides an appropriate answer in real time through the system’s question-and-answer pairs and customer reviews. The framework’s performance is verified through a qualitative evaluation. In addition, it is confirmed that a customized model for reflecting the characteristics of each shopping mall can be created by using additional information from the collected data. The proposed framework is expected to support customers’ online shopping through more reliable and efficient information retrieval, and to reduce shopping mall operation and maintenance costs.}
}
@article{BOUAYAD20223280,
title = {Nowcasting and Forecasting Morocco GDP growth using Google Trends data},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {10},
pages = {3280-3285},
year = {2022},
note = {10th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.10.129},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322021395},
author = {Imane Bouayad and Jihad Zahir and Adil Ez-zetouni},
keywords = {Nowcasting, Forecasting, Gross Domestic Product, Google Trends, web mining},
abstract = {Search analytics and web data are widely used by media, politicians, economists, and scientists in various decision-making processes, it offers new opportunities to improve economic and demographic insights, and complement traditional data sources. In this paper, we intend to explore the potential of Google trends data as a valuable alternative data source to forecast and nowcast Gross Domestic Product (GDP) growth in Morocco. The method we follow consists of constructing a Google trends index and using it to improve an auto-regressive model for forecasting and nowcasting GDP growth. The study finds that indeed the addition of an Internet search index improves GDP growth forecasting. In the following pages, we will discuss the reasons for the varied success and potential avenues for future research.}
}
@article{FAVI2022118671,
title = {Sustainable life cycle and energy management of discrete manufacturing plants in the industry 4.0 framework},
journal = {Applied Energy},
volume = {312},
pages = {118671},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2022.118671},
url = {https://www.sciencedirect.com/science/article/pii/S0306261922001374},
author = {Claudio Favi and Marco Marconi and Marco Mandolini and Michele Germani},
keywords = {Energy/material flows, Sustainable manufacturing, Plant metabolism, Manufacturing plant, Life cycle assessment, Industry 4.0},
abstract = {Industry 4.0 (I4.0), through the digitalization and interconnection of manufacturing processes, can offer opportunities to improve production systems' sustainability. Despite the increasing number of scientific review papers related to I4.0 and production sustainability, most approaches and tools for sustainability evaluation lack of a tangible implementation framework. The paper presents a framework that originated from the plant metabolism concept, a simplified version of industrial metabolism. It is based on Energy Material Flow Analysis (EMFA) and Life Cycle Assessment (LCA) tools for production plants' economic and sustainability assessment, using the I4.0 enabling technologies. A Multi-Criteria Decision Making (MCDM) method combines the two sustainability pillars for aiding companies in optimizing their production processes towards a reduction of energy/material flows. The combination of EMFA, LCA and MCDM tools into a plant metabolism-based model is the main novelty of this paper. The framework consists of three main phases. The first phase allows to model the manufacturing system by defining the plant layout, the assets, and the input/output flows. The second phase allows gathering information from the manufacturing plant to assess environmental and economic Key Performance Indicators (KPIs) following the LCA principles. The third phase consists of post-processing results, minimizing specific KPIs for establishing the optimal production scenario. A washing machine plant has been chosen as a case study to demonstrate the proposed method's capability in authentic contexts. Besides, the effectiveness in supporting companies in the analysis, identifying criticalities, and the proper energy and material flows management of production plants has been verified. Plant managers could use this framework for managing the production plans. From the scientific standpoint, the proposed method positively contributes to integrating the existing state of the art studies concerning the I4.0-related framework for the sustainability assessment and energy/material flows minimization of production systems.}
}
@article{HU2022103059,
title = {EGC: A novel event-oriented graph clustering framework for social media text},
journal = {Information Processing & Management},
volume = {59},
number = {6},
pages = {103059},
year = {2022},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2022.103059},
url = {https://www.sciencedirect.com/science/article/pii/S0306457322001625},
author = {Die Hu and Dan Feng and Yulai Xie},
keywords = {Text clustering, Semantic features, Graph representation, Data mining},
abstract = {With the popularity of social platforms such as Sina Weibo, Tweet, etc., a large number of public events spread rapidly on social networks and huge amount of textual data are generated along with the discussion of netizens. Social text clustering has become one of the most critical methods to help people find relevant information and provides quality data for subsequent timely public opinion analysis. Most existing neural clustering methods rely on manual labeling of training sets and take a long time in the learning process. Due to the explosiveness and the large-scale of social media data, it is a challenge for social text data clustering to satisfy the timeliness demand of users. This paper proposes a novel unsupervised event-oriented graph clustering framework (EGC), which can achieve efficient clustering performance on large-scale datasets with less time overhead and does not require any labeled data. Specifically, EGC first mines the potential relations existing in social text data and transforms the textual data of social media into an event-oriented graph by taking advantage of graph structure for complex relations representation. Secondly, EGC uses a keyword-based local importance method to accurately measure the weights of relations in event-oriented graph. Finally, a bidirectional depth-first clustering algorithm based on the interrelations is proposed to cluster the nodes in event-oriented graph. By projecting the relations of the graph into a smaller domain, EGC achieves fast convergence. The experimental results show that the clustering performance of EGC on the Weibo dataset reaches 0.926 (NMI), 0.926 (AMI), 0.866 (ARI), which are 13%–30% higher than other clustering methods. In addition, the average query time of EGC clustered data is 16.7ms, which is 90% less than the original data.}
}
@article{ALSHAHRANI2022101617,
title = {An attention-based view of AI assimilation in public sector organizations: The case of Saudi Arabia},
journal = {Government Information Quarterly},
volume = {39},
number = {4},
pages = {101617},
year = {2022},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101617},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000538},
author = {Albandari Alshahrani and Denis Dennehy and Matti Mäntymäki},
keywords = {Artificial intelligence, Decision making, Attention-based view, Public sector},
abstract = {Artificial Intelligence (AI) has been suggested to have transformative potential for public sector organizations through enabling increased productivity and novel ways to deliver public services. In order to materialize the transformative potential of AI, public sector organizations need to successfully assimilate AI in their operational activities. However, AI assimilation in the public sector appears to be fragmented and lagging the private sector, and the phenomena has really limited attention from academic research community. To address this gap, we adopt the case study approach to explore three Saudi-Arabian public sector organizations and analyze the results using the attention-based view of the organization (ABV) as the theoretical lens. This study elucidates the challenges related AI assimilation in public sector in terms of how organizational attention is focused situated and distributed during the assimilation process. Five key challenges emerged from the cases studied, namely (i) misalignment between AI and management decision-making, (ii) tensions with linguistics and national culture, (iii) developing and implementing AI infrastructure, (iv) data integrity and sharing, and (v) ethical and governance concerns. The findings reveal a re-enforcing relationship between the situated attention and structural distribution of attention that can accelerate the successful assimilation of AI in public sector organizations.}
}
@article{CHEN20222354,
title = {Data Model Classification for Interoperability in the Industry},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {10},
pages = {2354-2359},
year = {2022},
note = {10th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.10.060},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322020699},
author = {Y. CHEN and D. ANNEBICQUE and V. CARRE-MENETRIER and A. PHILIPPOT and T. DANEAU},
keywords = {Industry 4.0, data model classification, manufacturing, interoperability},
abstract = {In the context of industry 4.0, interoperability is a major challenge for the manufacturing world. With new use cases heavily depending on industrial data analysis, data structuration through model has become essential for system and process description. However, diversities in data model types due to silo working between domains, represent a challenge for interoperability. Models don't have a clear definition of different domains and there is a need for alignment. This study proposes a classification of different types of data models based on capability criteria to help model definition alignment.}
}
@article{TOLIOPOULOS202259,
title = {Sboing4Real: A real-time crowdsensing-based traffic management system},
journal = {Journal of Parallel and Distributed Computing},
volume = {162},
pages = {59-75},
year = {2022},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2022.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S0743731522000193},
author = {Theodoros Toliopoulos and Nikodimos Nikolaidis and Anna-Valentini Michailidou and Andreas Seitaridis and Theodoros Nestoridis and Chrysa Oikonomou and Anastasios Temperekidis and Fotios Gioulekas and Anastasios Gounaris and Nick Bassiliades and Panagiotis Katsaros and Apostolos Georgiadis and Fotis K. Liotopoulos},
keywords = {Vehicle traffic monitoring, IoT, Stream processing, Massive parallelism, OLAP},
abstract = {This work describes the architecture of the back-end engine of a real-time traffic data processing and satellite navigation system. The role of the engine is to process real-time feedback, such as speed and travel time, provided by in-vehicle devices and derive real-time reports and traffic predictions through leveraging historical data as well. We present the main building blocks and the versatile set of data sources and processing platforms that need to be combined together to form a fully-functional and scalable solution. We also present performance results focusing on meeting system requirements while keeping the need for computing resources low. The lessons and results presented are of value to additional real-time applications that rely on both recent and historical data. Finally, we discuss the application of the aforementioned solution to a successful pilot study, where the full system was deployed and processed data from 800 taxis for a period of 3 months.}
}
@article{TURET2022102056,
title = {Hybrid methodology for analysis of structured and unstructured data to support decision-making in public security},
journal = {Data & Knowledge Engineering},
volume = {141},
pages = {102056},
year = {2022},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2022.102056},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X22000544},
author = {Jean Gomes Turet and Ana Paula Cabral Seixas Costa},
keywords = {Machine learning, Public security, Decision-making process},
abstract = {This work proposes a hybrid methodology that enables the integration of structured and unstructured data to support the decision-making process in public security contexts. The proposed methodology facilitates classification and prediction of crime in a given region, making it possible to identify actions to improve public security based on the results. The integration of the data takes place in two main steps: (1) loading and analyzing structured data made available by government agencies; and (2) absorbing, classifying, and analyzing unstructured data from digital platforms such as Twitter, Where I Was Robbed, and CityCop. In this way, it becomes possible to transform these unstructured data into structured data to be incorporated into a historical database on which algorithms can act to classify, measure, and predict crime. To illustrate the applicability of this methodology, we conducted a study in the city of Recife, Brazil. Structured and unstructured data were gathered in order to conduct a neighborhood classification analysis of crime hot spots. Based on that analysis, we conducted a series of actions intended to bring improvements to the region by the local police. We obtained an increase in the algorithms’ accuracy rate of 80%, indicating that public security organizations can base their actions on the results of the proposed methodology.}
}
@article{HE2022399,
title = {Using a linear regression approach to sequential interindustry model for time-lagged economic impact analysis},
journal = {Structural Change and Economic Dynamics},
volume = {62},
pages = {399-406},
year = {2022},
issn = {0954-349X},
doi = {https://doi.org/10.1016/j.strueco.2022.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S0954349X22000522},
author = {Kehan He and Zhifu Mi and D'Maris Coffman and Dabo Guan},
keywords = {Input-Output analysis, Sequential Interindustry model, Economic system modelling, Time series, Impact analysis},
abstract = {The input-output (IO) model is a powerful economic tool with many extended applications. However, one of the widely criticized drawbacks is its rather lengthy time lag in data preparation, making it impossible to apply IO in high-resolution time-series analysis. The conventional IO model is thus unfortunately unsuited for time-series analysis. In this study, we present an innovative algorithm that integrates linear regression techniques into a derivative of the IO method, the Sequential Interindustry Model (SIM), to overcome the inherent shortcomings of statistical lags in conventional IO studies. The regressed relationship can thus be used to predict, in the short term, the accumulated chronological impacts induced by fluctuations in sectorial economic demands under disequilibrium conditions. A simulated calculation is presented to serve as an illustration and verification of the new method. In the future, this application can be extended beyond economic studies to broader problems of system analysis.}
}
@article{KHAN2022107735,
title = {A Temperature-Aware Trusted Routing Scheme for Sensor Networks: Security Approach},
journal = {Computers & Electrical Engineering},
volume = {98},
pages = {107735},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.107735},
url = {https://www.sciencedirect.com/science/article/pii/S0045790622000477},
author = {Tayyab Khan and Karan Singh and Manisha Manjul and Mohammad Nazir Ahmad and Azlan Mohd Zain and Ali Ahmadian},
keywords = {Trust establishment, routing, Security, deep learning, internal threats, communication trust, energy trust, data trust, network lifetime},
abstract = {ABSTRACT
This paper presents a hybrid trust model, and a multifactor, depending on trust value of sensor nodes, remaining energy, and hop count, routing strategy known as Temperature-Aware Trusted Routing Scheme (TTRS). In fact, it establishes the shortest and most trusted routing path. The multifactor strategy selects trustworthy nodes to forward data and reduce energy utilization due to secure shorter routing paths. TTRS incorporates an efficient multifactor hotspot node detection algorithm (HNDA) along with route discovery as well as route maintenance mechanism to detect malicious relay nodes for consistent data delivery in an unattended environment. Experimental results express the admirable average performance gain of TTRS in terms of accurate trust evaluation, network lifetime, packet delivery rate, and average energy consumption per node, as compared to ATRP, EOSR, and SQEER. Consequently, TTRS is more accurate than the aforementioned competitive schemes under different loads in a hostile environment.}
}
@article{SHIROIWA202262,
title = {Developing a New Region-Specific Preference-Based Measure in East and Southeast Asia},
journal = {Value in Health Regional Issues},
volume = {32},
pages = {62-69},
year = {2022},
issn = {2212-1099},
doi = {https://doi.org/10.1016/j.vhri.2022.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212109922001339},
author = {Takeru Shiroiwa and Tatsunori Murata and Jeonghoon Ahn and Xue Li and Ryota Nakamura and Yot Teerawattananon and Zhao Kun and Asrul Akmal Shafie and Haidee Valverde and Hilton Lam and Kwong Ng and Mardiati Nadjib and Raoh-Fang Pwu and Ryan Rachmad Nugraha and Yong-Chen Chen and Takashi Fukuda},
keywords = {East and Southeast Asia, preference-based measure, qualitative study, quality-adjusted life years},
abstract = {Objectives
Almost all preference-based measures (PBMs) have been developed in Western countries, with none having been formulated in Asian countries. In this study, we construct a new generic PBM based on concept elicitation using interview surveys in East and Southeast Asian countries and qualitative analysis.
Methods
This cross-sectional study included 225 adults recruited from 9 East and Southeast Asian countries or regions (Indonesia, Japan, Korea, mainland China, Malaysia, the Philippines, Singapore, Taiwan, and Thailand). Trained interviewers conducted semistructured interviews with 25 participants from the general population of each country/region. Qualitative data were analyzed using a content analysis approach. The selection of items was determined based on interview surveys and team member discussions. The description of items was considered based on a detailed qualitative analysis of the interview survey.
Results
A new region-specific PBM—the Asia PBM 7 dimensions instrument—was designed. It reflects East and Southeast Asian values and comprises 7 items: pain, mental health, energy, mobility, work/school, interpersonal interactions, and burden to others.
Conclusions
The new region-specific instrument is one of the first PBMs developed in the context of non-Western countries. The Asia PBM 7 dimensions contains 7 items that address the core concepts of health-related quality of life that are deemed important based on East and Southeast Asian health concepts.}
}
@article{LIU2022118504,
title = {Uneven development of the lead industry leads to regional differences in blood lead levels of children},
journal = {Environmental Pollution},
volume = {293},
pages = {118504},
year = {2022},
issn = {0269-7491},
doi = {https://doi.org/10.1016/j.envpol.2021.118504},
url = {https://www.sciencedirect.com/science/article/pii/S0269749121020868},
author = {Yang Liu and Chengdong Xu and Feiyan Liu and Gexin Xiao and Shaoqi Zhou and Liming Huang and Ni Lin and Jianyi Li and Dong Chen and Qi Fu and Huijun Wang and Qingfeng Du},
keywords = {Blood lead levels, Lead industry, Regional inequality, Children's health, China},
abstract = {Children's exposure to lead is a global health problem, especially in low- and middle-income countries. However, research on the relationship between children's blood lead levels (BLLs) and the development of the lead industry is still limited. This study examined whether children's BLLs were associated with the development of lead industry in different regions. Using survey data on the BLLs of children living in 250 prefectures in China with corresponding data on their economic factors and lead industries, we explored the regional variation of children's BLLs using statistical methods. The results show that the level of economic development in leaded areas was associated with inequity in children's BLLs and met the environmental Kuznets hypothesis. In areas without lead industries, there was little correlation between the level of economic development and the BLLs of children and thus the environmental Kuznets hypothesis was not supported. Lead mines, lead smelting and chemical companies are major sources of blood lead in children living in leaded areas. This study demonstrated the success of control policies for lead-acid battery manufacturers in promoting the prevention and control of childhood lead poisoning in China. China should consciously support the improvement of children's BLLs in undeveloped areas with lead industries through national financing and policies to avoid the continuous effects of the regional inequality problem of high children's BLLs.}
}
@article{WANG2022109344,
title = {Smart contract-based caching and data transaction optimization in mobile edge computing},
journal = {Knowledge-Based Systems},
volume = {252},
pages = {109344},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109344},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122006748},
author = {Ge Wang and Chunlin Li and Yong Huang and Xiangli Wang and Youlong Luo},
keywords = {Mobile edge computing, Blockchain, Smart contract, Data caching, Data transaction},
abstract = {The emergence of mobile edge computing can provide technical support for the development of Internet services and for coping with massive data traffic, thereby reducing network latency and ensuring efficient network operations and service delivery. However, the mobile edge computing environment is prone to data loss and privacy leakage, and data security and reliability cannot be guaranteed. The application of blockchain technology ensures the stability and dependability of data caching and transactions. In order to guarantee the security of data caching in the mobile edge computing environment and minimize the response time of caching servers, this paper proposes a decentralized data caching strategy in the mobile edge computing environment. The strategy uses a greedy algorithm to make the transmission delay of the requested content as small as possible under the multiple constraints of the storage space of each server and whether the content is cached on the server. To address the problem that data trading platforms are unable to afford the computation and storage of massive amounts of data and cannot guarantee that the data will not be leaked, this paper proposes a secure decentralized data transaction program. The scheme promotes the increase of transaction turnover rate and improves the revenue of both participating parties by establishing a buyer–seller matching algorithm. According to the experimental results, the proposed data caching strategy can improve the cache hit rate and reduce the transmission delay; the proposed data transaction solution can increase the revenue of both the data holder and the data buyer.}
}
@article{XIAO2022448,
title = {Modeling and application of marketing and distribution data based on graph computing},
journal = {Global Energy Interconnection},
volume = {5},
number = {4},
pages = {448-460},
year = {2022},
issn = {2096-5117},
doi = {https://doi.org/10.1016/j.gloei.2022.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S2096511722000834},
author = {Kai Xiao and Daoxing Li and Xiaohui Wang and Pengtian Guo},
keywords = {Marketing and distribution connection, Graph data, Graph computing, Knowledge graph, Data model},
abstract = {Integrating marketing and distribution businesses is crucial for improving the coordination of equipment and the efficient management of multi-energy systems. New energy sources are continuously being connected to distribution grids; this, however, increases the complexity of the information structure of marketing and distribution businesses. The existing unified data model and the coordinated application of marketing and distribution suffer from various drawbacks. As a solution, this paper presents a data model of “one graph of marketing and distribution” and a framework for graph computing, by analyzing the current trends of business and data in the marketing and distribution fields and using graph data theory. Specifically, this work aims to determine the correlation between distribution transformers and marketing users, which is crucial for elucidating the connection between marketing and distribution. In this manner, a novel identification algorithm is proposed based on the collected data for marketing and distribution. Lastly, a forecasting application is developed based on the proposed algorithm to realize the coordinated prediction and consumption of distributed photovoltaic power generation and distribution loads. Furthermore, an operation and maintenance (O&M) knowledge graph reasoning application is developed to improve the intelligent O&M ability of marketing and distribution equipment.}
}
@article{SONG2022110360,
title = {Evaluation of hydraulic fracturing effect on coalbed methane reservoir based on deep learning method considering physical constraints},
journal = {Journal of Petroleum Science and Engineering},
volume = {212},
pages = {110360},
year = {2022},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2022.110360},
url = {https://www.sciencedirect.com/science/article/pii/S0920410522002479},
author = {Hongqing Song and Shuyi Du and Jiaosheng Yang and Yang Zhao and Mingxu Yu},
keywords = {Coalbed methane reservoir, Hydraulic fracturing effect, Machine learning, Deep neural network with physical constraints, Crack half-length},
abstract = {Data-driven deep learning algorithms have shown good performance in the field of petroleum industry. However, some research has begun to be keen to incorporate physical laws into machine learning algorithms, so as to establish a “data + physical laws” dual-drive model, which can more effectively guide deep learning. In this study, reservoir geology, hydraulic fracturing, and dynamic production data were considered to establish a fracturing effect evaluation model for coalbed methane reservoirs. The combined network is designed to fully excavate the characteristics of dynamic and static data and solve the problem that the network ignores static data due to excessive dimensions of dynamic data. Furthermore, a neural network considering physical constraints was developed to better evaluate the fracturing effect by incorporating the initial conditions and expert experiences into the loss function. The deep learning-based fracturing effect evaluation model not only fits data-driven methods including reservoir geology, hydraulic fracturing and dynamic production data, but also adheres to the guidance of physical constraints. The experimental results show that compared with the conventional machine learning methods, the fracturing effect evaluation model has better performance on the prediction of crack half-length and permeability after fracturing due to combined network and physical constraints, with the overall RMSE of 6.11 m and 0.533mD respectively. In addition, through the analysis of influencing factors, it can be obtained that reservoir geology and hydraulic fracturing parameters can contribute more than 90% to the prediction of fracture half-length. Moreover, reservoir geology, hydraulic fracturing and dynamic data all play an important role in the permeability after fracturing, among which dynamic data has the highest contribution rate, with more than 40%.}
}
@incollection{BATHULA2022507,
title = {Chapter 22 - Digital healthcare data management using blockchain technology in genomics and COVID-19},
editor = {Arpana Parihar and Raju Khan and Ashok Kumar and Ajeet Kumar Kaushik and Hardik Gohel},
booktitle = {Computational Approaches for Novel Therapeutic and Diagnostic Designing to Mitigate SARS-CoV-2 Infection},
publisher = {Academic Press},
pages = {507-518},
year = {2022},
isbn = {978-0-323-91172-6},
doi = {https://doi.org/10.1016/B978-0-323-91172-6.00024-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323911726000248},
author = {Sreenivas Reddy Bathula},
keywords = {COVID-19, insurance, telemedicine, point-of-care testing, big data, artificial intelligence, blockchain},
abstract = {From birth certificate until death certificate, a person accumulates healthcare data. Each time a person has contact with a healthcare professional some type of record is produced, be it paper, electronic, or both. In one year, a normal healthy American may visit the dentist twice, see a doctor for a wellness visit, call a physician for a bad cold, and refill a dozen allergy prescriptions. Each one of these encounters becomes a part of the many records stored somewhere in the archives of healthcare data. Much of the data is merely entered into a computer system so that the provider can receive payment, and then the data are added to a massive “warehouse.” Each one of these records can provide insight not only into an individual’s well-being but may, in fact, affect healthcare across similar groups based on age, gender, or location, and provide an analytic base to determine insurance rates, study disease trends, and modify treatment protocols. This administrative type of information claims and encounters eligibility and enrollment is still vastly underused. This is due in part to the massive amounts of administrative data, in part to their complexity, and in part to their misuse in the past. Studies of this type of data are only now beginning to receive proper time and attention due to Coronavirus disease-2019. The process of converting healthcare data into useful information is the focus of this book chapter.}
}
@article{CHEN2022108895,
title = {Pest incidence forecasting based on Internet of Things and Long Short-Term Memory Network},
journal = {Applied Soft Computing},
volume = {124},
pages = {108895},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.108895},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622002666},
author = {Ching-Ju Chen and Yuan-Shuo Li and Chen-Yu Tai and Ying-Cheng Chen and Yueh-Min Huang},
keywords = {Smart agriculture, Long Short-Term Memory, Machine Learning, Artificial intelligence, Internet of Things, Long-range, Pest prevention and cure, Weather factors},
abstract = {The infestation of litchi stink bugs (Tessaratoma papillosa) has always had a significant impact on the yield of longan plantations. Pest control is critical for farmers to detect and timely suppress the occurrence of pests while effectively reducing damages. Environmental factors, climate change in particular, have contributed to the growing population of pests whereas weather can vary in different terrains, locations, and time. Due to the geographical and topographical conditions of Taiwan, this study focuses on investigating fruit plantations on sloping land in subtropics with distinct seasonal changes. The article aims at forecasting meteorological data based on Long short-term memory network (LSTM) and identifying the correlation between pest infestation and environmental factors through Machine Learning (ML). In this section, the structure and experimental process of the research will be outlined. At the first stage, meteorological information of the experimented site is obtained through the self-designed IoT (Internet of Things) system and wireless long-distance transmission technology. Since meteorological information forecasted is displayed in time series, multi-layer LSTM and bidirectional LSTM are used to solve the problem. Finally, environmental data and field surveys conducted for pest surveillance will be employed to forecast the severity of pest infestation through KNN, SVM, and random forest models. The result of the experiment shows that LSTM performs well in weather forecasting with 96% R-Squared values whereas the accuracy rate of pest prediction conducted by Machine Learning (ML) is 85%. The study verifies that meteorological factors do affect pest incidence. For example, the population of litchi stink bugs increase easily under suitable temperature, humidity, and sunlight. LSTM is superior in providing solutions for long-range dependence in statistics. This article shall present regions with shifting weather patterns, meteorological conditions and time length forecasted corresponding to the oceanic climate, as well as the correlation between pest population and environmental factors.}
}
@article{DHIMAN2022,
title = {Application of UPIoT based power monitoring system},
journal = {Materials Today: Proceedings},
year = {2022},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2022.09.131},
url = {https://www.sciencedirect.com/science/article/pii/S2214785322059430},
author = {Amandeep Dhiman and Rehana Perveen},
keywords = {Equipment monitoring, Invasive power monitoring, Non-Invasive power monitoring, Ubiquitous power Internet of Things},
abstract = {Power monitoring through the Internet of Things (IoT) is growing in demand concerning to current trends like electric vehicles, and energy conservation. A system that can monitor this continuously changing demand and adapt itself according to the user requirements is called a smart system. This is only possible by monitoring continuous power output and controlling the gathered data for valuable information with the help of smart systems and IoT devices. This paper discusses the structure of Ubiquitous power Internet of Things (UPIoT) and power monitoring by using UPIoT. The monitoring of data is done by two methods, the first is non-invasive power monitoring and the second is invasive power monitoring. The proposed devices transmit real-time data to the thingspeak cloud by using the ESP8266 Wi-Fi module. The performance of both systems is analyzed by using an electric blower.}
}
@article{MASHALAH2022102837,
title = {The impact of digital transformation on supply chains through e-commerce: Literature review and a conceptual framework},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {165},
pages = {102837},
year = {2022},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2022.102837},
url = {https://www.sciencedirect.com/science/article/pii/S1366554522002216},
author = {Heider Al Mashalah and Elkafi Hassini and Angappa Gunasekaran and Deepa {Bhatt (Mishra)}},
keywords = {Digital transformation, e-commerce, Network analysis, Supply chains, Systematic literature review},
abstract = {One of the profound impacts of digitalization on supply chains is manifested through e-commerce. The latter has significantly grown during the last two decades, with further amplifications during the COVID-19 pandemic. This has created operational and policy making challenges for firms when deciding about how best to manage the resulting growth in e-commerce. While the impact of e-commerce on supply chains has been widely recognized in the literature, there was no effort to systematically review the literature, conceptualize some of the challenges and propose future research directions. This paper fills this gap by reviewing 153 publications from 1999 to 2019. We classify the reviewed literature based on which supply chain drivers were investigated, as well as, the employed research methodology. In addition, we conduct network and content analysis to uncover the main research themes and potential research directions namely, developing analytical centred; modelling based ecosystem for environment; leveraging data mining to enhance sustainability; balance between growth and sustainability; consumer demand and uncertainty; coordination in e-commerce logistics; last mile alternatives and cost management of innovative technique implementations. Furthermore, based on our literature review, we propose a conceptual framework where we interlink supply chain stages with a firm’s business strategy, digital transformation strategy and performance.}
}
@article{KUMAR2022108455,
title = {Applications of the internet of things for optimizing warehousing and logistics operations: A systematic literature review and future research directions},
journal = {Computers & Industrial Engineering},
volume = {171},
pages = {108455},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.108455},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222004892},
author = {Devinder Kumar and Rajesh {Kr Singh} and Ruchi Mishra and Samuel {Fosso Wamba}},
keywords = {IoT, Industry 4.0, Logistics and Warehousing, PRISMA approach, TMC framework, Systematic literature review},
abstract = {The introduction of Industry 4.0 technologies such as the Internet of Things (IoT), artificial intelligence (AI), cloud computing, and others has revolutionised the traditional warehousing and logistics industry, resulting in significant changes to various operations and decision-making. Despite the undeniable importance of this topic, the primary research on the impact of IoT technology is inconsistent and scattered. The present study aims to review state-of-art literature on the application of IoT technology in the warehousing and logistics field and suggests a path for the future research through an in-depth analysis of studies done in this area. Sixty-four research articles were carefully selected after a thorough search of the Scopus and EBSCO databases, covering the period from January 2011 to 07th December 2021, to examine the applications of the IoT in the warehousing and logistics business. These articles were thoroughly reviewed and classified in terms of year-wise distribution, major publication outlets, types of study, and highly cited papers to understand the evolution and ongoing trends in this field. The findings reveal that majority of the studies on IoT in the warehousing and logistics domain have been conducted in developed countries. While logistics has been widely investigated, studies on the warehousing domain are limited. Also, there is an under-presentation of various theories in IoT research. The study highlights various gaps by synthesising existing literature and provides a fertile ground for conducting future research in this domain. Supply chain practitioners and researchers will find this review timely and valuable, which offers several valuable implications for them.}
}
@article{CHEN2022,
title = {Reflection on the equitable attribution of responsibility for artificial intelligence-assisted diagnosis and treatment decisions},
journal = {Intelligent Medicine},
year = {2022},
issn = {2667-1026},
doi = {https://doi.org/10.1016/j.imed.2022.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2667102622000353},
author = {Antian Chen and Chenyu Wang and Xinqing Zhang},
keywords = {Artificial intelligence, Diagnosis, Treatment, Ethics, Responsibility attribution},
abstract = {Artificial intelligence (AI) is developing rapidly and is being used in several medical capacities, including assisting in diagnosis and treatment decisions. As a result, this raises the conceptual and practical problem of how to distribute responsibility when AI-assisted diagnosis and treatment have been used and patients are harmed in the process. Regulations on this issue have not yet been established. It would be beneficial to tackle responsibility attribution prior to the development of biomedical AI technologies and ethical guidelines. In general, human doctors acting as superiors need to bear responsibility for their clinical decisions. However, human doctors should not bear responsibility for the behavior of an AI doctor that is practicing medicine independently. According to the degree of fault—which includes internal institutional ethics, the AI bidding process in procurement, and the medical process—clinical institutions are required to bear corresponding responsibility. AI manufacturers are responsible for creating accurate algorithms, network security, and insuring patient privacy protection. However, the AI itself should not be subjected to legal evaluation since there is no need for it to bear responsibility. Corresponding responsibility should be borne by the employer, in this case the medical institution.}
}
@article{YANG2022421,
title = {Worldwide validation of an Earth Polychromatic Imaging Camera (EPIC) derived radiation product and comparison with recent reanalyses},
journal = {Solar Energy},
volume = {243},
pages = {421-430},
year = {2022},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2022.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X2200559X},
author = {Xiaoyi Yang and Jamie M. Bright and Christian A. Gueymard and Brendan Acord and Peng Wang},
keywords = {Deep-space remote sensing, Solar radiation, Solar resource assessment, EPIC DSCOVR, Validation},
abstract = {A very recent gridded product for the hourly global horizontal irradiance (GHI), derived from the measurements of the Earth Polychromatic Imaging Camera (EPIC) onboard the Deep Space Climate Observatory (DSCOVR) launched by a NOAA/NASA/USAF consortium, is validated at 31 locations worldwide, from January, 2017 to June, 2019. In contrast to those traditional methods that leverage (simplified) radiative transfer, this EPIC-derived product uses machine learning – a random forest model – to map out the connection between satellite-observed variables of various kinds and GHI. Nonetheless, the detailed validation conducted here shows that the quality of this EPIC-derived GHI dataset not only does not outperform those traditional gridded solar radiation datasets, but also contains undesirable artifacts that can be possibly attributed to inadequacies in the machine-learning procedure. For these reasons, it is not recommended to use this EPIC-derived dataset in its current form for solar resource assessment purposes.}
}
@incollection{KOLTAY2022145,
title = {Chapter 6 - Roles and education of information and data professionals},
editor = {Tibor Koltay},
booktitle = {Research Data Management and Data Literacies},
publisher = {Chandos Publishing},
pages = {145-180},
year = {2022},
series = {Chandos Information Professional Series},
isbn = {978-0-12-824475-3},
doi = {https://doi.org/10.1016/B978-0-12-824475-3.00006-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128244753000060},
author = {Tibor Koltay},
keywords = {Data librarian, Data scientist, Data science, Research data management, Data literacy, Social-constructionist approaches, Connectivism, Scholarship of teaching, Inquiry-based learning},
abstract = {This chapter is based on a nonexhaustive treatment of selected issues. The first subsection identifies the main professional groups involved in data-related activities in academic libraries and beyond. In the second subsection, educational issues are targeted with regard to the education of information professionals for research data management, as well as for data literacy. The third subsection examines similarities and convergences between the pedagogy of educating for literacies. Pedagogical approaches, including social-constructionist, cognitive, and connectivist approaches, as well as the Scholarship of Teaching, are characterized here briefly. Inquiry-based learning and the ideas for breaking out of silos are also portrayed, and the tasks of visualization are described as well.}
}
@article{YANG2022102590,
title = {Identifying intercity freight trip ends of heavy trucks from GPS data},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {157},
pages = {102590},
year = {2022},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2021.102590},
url = {https://www.sciencedirect.com/science/article/pii/S1366554521003458},
author = {Yitao Yang and Bin Jia and Xiao-Yong Yan and Jiangtao Li and Zhenzhen Yang and Ziyou Gao},
keywords = {Intercity freight trip ends, Heavy truck, GPS data, Time threshold method, Spatiotemporal characteristics},
abstract = {The intercity freight trips of heavy trucks are basic data for transportation system planning and management. In recent decades, extracting intercity freight trips from GPS data has gradually become the main alternative to traditional surveys. Identifying freight trip ends (origin and destination) is the first task in trip extraction. Although many trip end identification methods have been proposed in previous studies, most of these studies subjectively determined key parameters and ignored the complex characteristics of truck trajectory and freight activities. In this paper, we propose a data-driven trip end identification method based on massive GPS data of heavy trucks in China. First, we capture heavy truck trajectory characteristics under the influence of GPS drift to identify truck stops from GPS data. Second, we analyze the temporal characteristics of truck activities and use freight-related point-of-interest (POI) data and highway network GIS data to identify valid trip ends from truck stops. The results of method validation suggest that the accuracy of our proposed method is significantly improved in comparison with the benchmark methods. We further extract intercity freight trips from the identified trip ends and analyze the spatiotemporal characteristics of intercity freight trips in China.}
}
@article{DUAN2022336,
title = {Fed-DR-Filter: Using global data representation to reduce the impact of noisy labels on the performance of federated learning},
journal = {Future Generation Computer Systems},
volume = {137},
pages = {336-348},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22002412},
author = {Shaoming Duan and Chuanyi Liu and Zhengsheng Cao and Xiaopeng Jin and Peiyi Han},
keywords = {Federated learning, Label noise, Data filtering, Deep learning, Local differential privacy, Privacy-preserving data representation},
abstract = {The label noise is a serious problem limiting the performance of federated learning. According to the performance evaluation for the trained federated models, data selection strategies or client selection strategies are used to solve this problem in previous studies. However, these methods require additional clean data to strengthen the election results, and they rely heavily on an initial model that is robust enough to not accumulate errors. To address these problems, we propose a novel data filtering method to deal with label noise in federated learning, which is called Fed-DR-Filter. Unlike previous methods, Fed-DR-filter focuses on identifying clean data by taking advantage of the correlation of the global data representations. The proposed solution transforms the private data into privacy-preserving data representations in each client, and identifies clean data based on the centralized data representations on the server. To evaluate the performance of Fed-DR-Filter, we conduct extensive experiments on three real-world datasets. The evaluation results show that our method outperforms the state-of-the-art approaches and is robust to various data distributions and noise levels.}
}
@article{CAO2022103558,
title = {An analytical model for quantifying the efficiency of traffic-data collection using instrumented vehicles},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {136},
pages = {103558},
year = {2022},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2022.103558},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X22000079},
author = {Peng Cao and Zhiqiang Xiong and Xiaobo Liu},
keywords = {Instrumented vehicles, Data collection, Efficiency, Stochastic geometry theory},
abstract = {Emerging instrumented vehicles (IVs), when equipped with high-precision positioning devices (e.g., DGPS) and ranging sensors (e.g., radar, LIDAR, cameras), are capable of generating high-quality traffic data. This study evaluates the efficiency of such data-collection procedures; this remains largely unknown because variable penetration rates of IVs rarely arise in the real world. We propose an analytical model that establishes a quantitative relationship between the ratio of collected trajectory points to total traffic trajectory points (RCT) and the IV penetration rate, according to stochastic geometry theory. With this, the data-collection efficiency (DCE) of IVs can be effectively evaluated. A simulation approach is developed to generate IV data and thereby validate the proposed analytical model, using a comprehensive set of traffic scenarios; these data consist of eight micro-trajectory datasets from the next-generation simulation (NGSIM) program and four typical sensor IV deployments. The numerical analysis demonstrates that the model perfectly reflects the simulated IV data for all traffic scenarios. In addition, an analytical comparison of the DCEs for fixed sensors, probe vehicles, and IVs reveals that IVs are the most efficient method for collecting traffic data in road networks. This study proposes a theory to predict the percentage of trajectory points that can be collected by a certain percentage of IVs within the entire traffic flow.}
}
@incollection{AMIN202225,
title = {Chapter Two - State-of-the-art in process safety and digital system},
editor = {Faisal Khan and Hans Pasman and Ming Yang},
series = {Methods in Chemical Process Safety},
publisher = {Elsevier},
volume = {6},
pages = {25-59},
year = {2022},
booktitle = {Methods to Assess and Manage Process Safety in Digitalized Process System},
issn = {2468-6514},
doi = {https://doi.org/10.1016/bs.mcps.2022.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2468651422000010},
author = {Md Tanjin Amin and Rajeevan Arunthavanathan and Md Alauddin and Faisal Khan},
keywords = {Process safety, Digitization, Digitalization, Digital transformation, Digital process},
abstract = {This chapter presents an overview of the current progress in digital process systems' safety. It starts with defining crucial terminologies associated with digital process systems, followed by a brief description of the stimulating factors behind the growth of digital process systems. Key opportunities and challenges of digital transformation in process industries are also discussed. A bibliometric analysis is performed to numerically understand digital process safety growth. It is found that the past decade has seen increasing attention from the research community due to the inauguration of the Industry 4.0 concept. Finally, a roadmap is provided for future developments in digital process safety.}
}
@article{BELLOMARINI2022407,
title = {Data science with Vadalog: Knowledge Graphs with machine learning and reasoning in practice},
journal = {Future Generation Computer Systems},
volume = {129},
pages = {407-422},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21004179},
author = {Luigi Bellomarini and Ruslan R. Fayzrakhmanov and Georg Gottlob and Andrey Kravchenko and Eleonora Laurenza and Yavor Nenov and Stéphane Reissfelder and Emanuel Sallinger and Evgeny Sherkhonov and Sahar Vahdati and Lianlong Wu},
keywords = {Knowledge Graphs, Data science, Machine learning, Reasoning, Probabilistic reasoning},
abstract = {Following the recent successful examples of large technology companies, many modern enterprises seek to build Knowledge Graphs to provide a unified view of corporate knowledge, and to draw deep insights using machine learning and logical reasoning. There is currently a perceived disconnect between the traditional approaches for data science, typically based on machine learning and statistical modeling, and systems for reasoning with domain knowledge. In this paper, we demonstrate how to perform a broad spectrum of data science tasks in a unified Knowledge Graph environment. This includes data wrangling, complex logical and probabilistic reasoning, and machine learning. We base our work on the state-of-the-art Knowledge Graph Management System Vadalog, which delivers highly expressive and efficient logical reasoning and provides seamless integration with modern data science toolkits such as the Jupyter platform. We argue that this is a significant step forward towards practical, holistic data science workflows that combine machine learning and reasoning in data science.}
}
@incollection{HOVENGA202217,
title = {Chapter 2 - Global and national infrastructures supporting digital health ecosystems},
editor = {Evelyn Hovenga and Heather Grain},
booktitle = {Roadmap to Successful Digital Health Ecosystems},
publisher = {Academic Press},
pages = {17-33},
year = {2022},
isbn = {978-0-12-823413-6},
doi = {https://doi.org/10.1016/B978-0-12-823413-6.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128234136000082},
author = {Evelyn Hovenga and Heather Grain},
keywords = {Ecosystem, Interoperability, Complex systems, Value propositions, Politics, Networks},
abstract = {Foundational infrastructure requirements in this chapter and lists of the form of studies that can be used to study any national, regional, or organisational digital health infrastructure are identified. Some criteria that may be used to evaluate overall performance are provided. Digital health foundational needs and adaptive complex digital health ecosystems are described. Examples of national digital health strategies adopted by Australia, the United Kingdom, New Zealand, and the United States are provided, noting missing foundational infrastructure components that continue the fragmentation of technical applications and data repositories. There is an urgent need for strong national non-hierarchical leadership promoting and supporting innovation, including greater clinical engagement. This chapter provides the rationale for the adoption of national roadmaps.}
}
@article{LI2022101821,
title = {Deep learning method for Chinese multisource point of interest matching},
journal = {Computers, Environment and Urban Systems},
volume = {96},
pages = {101821},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2022.101821},
url = {https://www.sciencedirect.com/science/article/pii/S0198971522000655},
author = {Pengpeng Li and Jiping Liu and An Luo and Yong Wang and Jun Zhu and Shenghua Xu},
keywords = {Multisource POI, Deep learning, Word2vec, Text-CNN, MLP, ESIM},
abstract = {Multisource point of interest (POI) matching refers to the pairing of POIs that refer to the same geographic entity in different data sources. This also constitutes the core issue in geospatial data fusion and update. The existing methods cannot effectively capture the complex semantic information from a text, and the manually defined rules largely affect matching results. This study developed a multisource POI matching method based on deep learning that transforms the POI pair matching problem into a binary classification problem. First, we used three different Chinese word segmentation methods to segment the POI text attributes and used the segmentation results to train the Word2Vec model to generate the corresponding word vector representation. Then, we used the text convolutional neural network (Text-CNN) and multilayer perceptron (MLP) to extract the POI attributes' features and generate the corresponding feature vector representation. Finally, we used the enhanced sequential inference model (ESIM) to perform local inference and inference combination on each attribute to realize the classification of POI pairs. We used the POI dataset containing Baidu Map, Tencent Map, and Gaode Map from Chengdu to train, verify, and test the model. The experimental results show that the matching precision, recall rate, and F1 score of the proposed method exceed 98% on the test set, and it is significantly better than the existing matching methods.}
}
@article{CHEN2022132617,
title = {Green financial risk management based on intelligence service},
journal = {Journal of Cleaner Production},
volume = {364},
pages = {132617},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.132617},
url = {https://www.sciencedirect.com/science/article/pii/S0959652622022168},
author = {Haibei Chen and Xianglian Zhao},
keywords = {Green finance, Financial risk, Risk management, Intelligence service},
abstract = {Risk management is an important issue of green finance, and it is also a prominent issue of green economic development. The resolution of green financial risk will help protect the interests of all stakeholders and promote the development of green finance. This study suggests that intelligence service provides new ideas and ways for green financial risk management. Applying intelligence service to green financial risk management will contribute to the sustainable development of green finance and enrich the theoretical system of intelligence science. This study first builds an intelligence service system of green financial risk management from five aspects: intelligence demand, intelligence collection, intelligence processing, intelligence application, and intelligence tracking. A questionnaire is designed based on this system. The first batch of green finance pilot cities in China (Ganjiang, Gui'an, Guangzhou, Huzhou, Quzhou, Changji, Hami, and Karamay) are investigated. This study uses a regression model to analyze the data and analyzes the intelligence service status of green financial risk management in pilot cities. The research divides those green finance pilot cities into eastern, central, and western regions. It shows obvious differences in the intelligence service elements in the eastern, central, and western regions of green financial risk management. The eastern region pays more attention to the three elements of intelligence demand, intelligence application, and intelligence tracking when carrying out green financial risk management. In the process of green financial risk management in the western region, there are obvious deficiencies in the two elements of intelligence collection and intelligence processing, which may be due to the lack of advanced digital equipment and effective digital resource. The central region lies between the eastern and western regions on intelligence service of green financial risk management. Based on the above results, this study proposes that establishing an intelligence center, sharing intelligence resources, improving digital technology, and updating intelligence cases can enhance the effectiveness of intelligence service in the risk management of green finance.}
}
@article{SAIHI20222944,
title = {A Survey of the Underlying Success Factors of Maintenance Digital Transformation},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {10},
pages = {2944-2949},
year = {2022},
note = {10th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.10.179},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322021930},
author = {Afef Saihi and Mohamed Ben-Daya and Rami As'ad},
keywords = {Maintenance, Digital transformation, enabler, success factor, organization},
abstract = {Advances in information technology and sensors, efficient connectivity, and ground-breaking computational ability are proving to be game-changer for improving maintenance strategies and production outcomes. The integration of conventional maintenance concepts with disruptive technological developments leads to significant changes in current maintenance practices in a response to the digitalized context requirements. However, despite the availability of technology and its relative affordability, many maintenance digital transformation (MDT) initiatives fail to accomplish their goals. This is due to the fact that technology alone is not sufficient for an organization to successfully digitalize its operations. Several challenges including the absence of a business case, limited analytical capabilities, uncertainties about new technologies, and impact of the human factor are hindering the success of attempted MDT efforts. MDT enablers reflect various aspects and span different implicated areas of the organization. This study seeks to develop a comprehensive and structured list of the underpinning factors driving the success of MDT. To that end, the authors conducted a systematic literature review in order to extract the various factors highlighted in the literature. Subsequently, a purification phase was conducted which consisted of merging the redundant factors together, then mapping them into various thematic categories based on the aspect covered. The final consolidated list comprises 63 enablers of MDT that are classified into 14 categories. This research enriches the extant relevant literature and provides guidance to practitioners in this field.}
}
@article{SHADBOLT2022100612,
title = {The challenges of data in future pandemics},
journal = {Epidemics},
volume = {40},
pages = {100612},
year = {2022},
issn = {1755-4365},
doi = {https://doi.org/10.1016/j.epidem.2022.100612},
url = {https://www.sciencedirect.com/science/article/pii/S1755436522000548},
author = {Nigel Shadbolt and Alys Brett and Min Chen and Glenn Marion and Iain J. McKendrick and Jasmina Panovska-Griffiths and Lorenzo Pellis and Richard Reeve and Ben Swallow},
keywords = {Data and models, Data ecosystem, Data lifecycles, FAIR data, Pandemic preparedness, COVID-19},
abstract = {The use of data has been essential throughout the unfolding COVID-19 pandemic. We have needed it to populate our models, inform our understanding, and shape our responses to the disease. However, data has not always been easy to find and access, it has varied in quality and coverage, been difficult to reuse or repurpose. This paper reviews these and other challenges and recommends steps to develop a data ecosystem better able to deal with future pandemics by better supporting preparedness, prevention, detection and response.}
}
@article{BIARD202291,
title = {Reliability Assessment of an Electrical Network with Digital Twins},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {19},
pages = {91-96},
year = {2022},
note = {5th IFAC Workshop on Advanced Maintenance Engineering, Services and Technologies AMEST 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.09.189},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322014045},
author = {Gabrielle Biard and Georges Abdul-Nour},
keywords = {Digital Twin, Reliability, Complex systems, Electrical industry, Asset management},
abstract = {Assessing power systems’ reliability and condition is a difficult task. This is partly due to the complexity of the many interrelated components that compose these systems. As a result, traditional reliability assessment methods are inadequate. This raises the question of whether digital twins can be used to assess the reliability of power systems. The objective of this paper is to consolidate information on the use of digital twins in the electrical industry and demonstrate how they can be used to assess the reliability of such complex systems. To accomplish this, a literature review is conducted. Then a method for evaluating the reliability of a power system with DTs is proposed.}
}
@article{FRIEDERICH2022546,
title = {Process Mining for Dynamic Modeling of Smart Manufacturing Systems: Data Requirements},
journal = {Procedia CIRP},
volume = {107},
pages = {546-551},
year = {2022},
note = {Leading manufacturing systems transformation – Proceedings of the 55th CIRP Conference on Manufacturing Systems 2022},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2022.05.023},
url = {https://www.sciencedirect.com/science/article/pii/S2212827122003079},
author = {Jonas Friederich and Giovanni Lugaresi and Sanja Lazarova-Molnar and Andrea Matta},
keywords = {Model generation, discrete event simulation, process mining, machine behavior, reliability models},
abstract = {Modern manufacturing systems can benefit from the use of digital tools to support both short- and long-term decisions. Meanwhile, such systems reached a high level of complexity and are frequently subject to modifications that can quickly make the digital tools obsolete. In this context, the ability to dynamically generate models of production systems is essential to guarantee their exploitation on the shop-floors as decision-support systems. The literature offers approaches for generating digital models based on real-time data streams. These models can represent a system more precisely at any point in time, as they are continuously updated based on the data. However, most approaches consider only isolated aspects of systems (e.g., reliability models) and focus on a specific modeling purpose (e.g., material flow identification). The research challenge is therefore to develop a novel framework that systematically enables the combination of models extracted through different process mining algorithms. To tackle this challenge, it is critical to define the requirements that enable the emergence of automated modeling and simulation tasks. In this paper, we therefore derive and define data requirements for the models that need to be extracted. We include aspects such as the structure of the manufacturing system and the behavior of its machines. The paper aims at guiding practitioners in designing coherent data structures to enable the coupling of model generation techniques within the digital support system of manufacturing companies.}
}
@article{HAJEK2022103709,
title = {Recent developments in smart city assessment: A bibliometric and content analysis-based literature review},
journal = {Cities},
volume = {126},
pages = {103709},
year = {2022},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2022.103709},
url = {https://www.sciencedirect.com/science/article/pii/S0264275122001482},
author = {Petr Hajek and Abdelrahman Youssef and Veronika Hajkova},
keywords = {Smart city, Assessment, Framework, Bibliometric analysis, Content analysis, Literature review},
abstract = {Cities around the world are increasingly competing to upgrade their infrastructure and smartness levels to attract talent, become more effective and sustainable. However, assessing the progress of smart cities is often challenging due to the lack of theoretical foundation and consensus on an assessment methodology. These contradictions can pose major constraints on the development of the smart city concept and its implementation in practice. This paper analyzes a set of 164 articles published between 2010 and 2020 that deal with smart city assessment. The present study aims to identify the most influential research and key research themes, and suggests future research directions in the field of smart city assessment. A bibliometric analysis is used to reveal the most influential articles and their associations. Furthermore, a content analysis is performed to explore recent developments in the field of smart city assessment in terms of research hotspots and research themes. The analysis reveals the existence of 11 research themes and their timelines. The most influential research addresses (1) multiple-criteria decision-based performance measurement frameworks, (2) data connectivity challenges, (3) composite indexes for smart sustainable cities, (4) holistic performance evaluations of smart cities, and (5) the characteristics of indicator sets. Based on these results, current advances in smart city assessment are discussed, and future research directions in this field are suggested.}
}
@article{CHANG2022103587,
title = {Predicting aspect-based sentiment using deep learning and information visualization: The impact of COVID-19 on the airline industry},
journal = {Information & Management},
volume = {59},
number = {2},
pages = {103587},
year = {2022},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2021.103587},
url = {https://www.sciencedirect.com/science/article/pii/S0378720621001610},
author = {Yung-Chun Chang and Chih-Hao Ku and Duy-Duc Le Nguyen},
keywords = {Aspect-based Sentiment Analysis, Social Media Analysis, Natural Language Processing, Deep Learning, Information Visualization, Bidirectional Encoder Representations from Transformers},
abstract = {ABSTRACT
This study investigates customer satisfaction through aspect-level sentiment analysis and visual analytics. We collected and examined the flight reviews on TripAdvisor from January 2016 to August 2020 to gauge the impact of COVID-19 on passenger travel sentiment in several aspects. Till now, information systems, management, and tourism research have paid little attention to the use of deep learning and word embedding techniques, such as bidirectional encoder representations from transformers, especially for aspect-level sentiment analysis. This paper aims to identify perceived aspect-based sentiments and predict unrated sentiments for various categories to address this research gap. Ultimately, this study complements existing sentiment analysis methods and extends the use of data-driven and visual analytics approaches to better understand customer satisfaction in the airline industry and within the context of the COVID-19. Our proposed method outperforms baseline comparisons and therefore contributes to the theoretical and managerial literature.}
}
@incollection{NEALJOSHUA2022391,
title = {Chapter 20 - The use of digital technologies in the response to SARS-2 CoV2-19 in the public health sector},
editor = {Patricia Ordóñez {de Pablos} and Kwok Tai Chui and Miltiadis D. Lytras},
booktitle = {Digital Innovation for Healthcare in COVID-19 Pandemic},
publisher = {Academic Press},
pages = {391-418},
year = {2022},
series = {Information Technologies in Healthcare Industry},
isbn = {978-0-12-821318-6},
doi = {https://doi.org/10.1016/B978-0-12-821318-6.00003-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128213186000037},
author = {Eali Stephen {Neal Joshua} and Debnath Bhattacharyya and N. {Thirupathi Rao}},
keywords = {COVID-19, Digital, Artificial intelligence, Machine learning, Public healthcare, Natural language processing, Pandemic},
abstract = {In order to promote public health response to COVID-19, digital technologies are being used around the world. These include population surveillance, case identification, contact tracing, and intervention assessment based on mobility data and public communication. These rapid responses are made possible by the millions of mobile phones in use, massive online data sets, connected devices, low-cost computer resources and machines, and advances in natural language processing. To achieve this goal, a comprehensive review of digital innovations for COVID-19 response to public health around the world is being conducted, including a look at their limitations and implementation obstacles such as legal or ethical issues, privacy concerns, and organizational and personnel issues. We investigate the need for international strategies to improve pandemic control and future preparedness for COVID-19 and other infectious diseases through the regulation, assessment, and use of digital technologies, as well as the need for international strategies to regulate, assess, and use digital technology in pandemic management.}
}
@article{LIU2022775,
title = {Risk Prediction of Digital Transformation of Manufacturing Supply Chain Based on Principal Component Analysis and Backpropagation Artificial Neural Network},
journal = {Alexandria Engineering Journal},
volume = {61},
number = {1},
pages = {775-784},
year = {2022},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2021.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S1110016821003707},
author = {Caihong Liu},
keywords = {Digital transformation, manufacturing supply chain (MSC), risk factor, backpropagation neural network (BPNN), principal component analysis (PCA)},
abstract = {Digital transformation of manufacturing is a hot topic among strategic managers of manufacturing companies. The crux of digital transformation lies in the digitalization of manufacturing supply chain (MSC). However, the digital transformation of the MSC is highly uncertain, owing to the dynamic and complex changes of its nodes and structure in response to growing customer demand and fierce market competition. To propel the MSC digital transformation, it is crucial to effectively identify and predict the risk factors in the course of digital transformation. Therefore, this paper attempts to help manufacturing companies in China to successfully switch to a digital MSC. Firstly, the risk sources of the MSC digitization were identified, and complied into an evaluation index system for the digital transformation of the MSC. Next, the principal component analysis (PCA) was performed to reduce the dimension of the original data by revealing the three key principal components, and then the characteristic parameters of risk prediction are selected, so as to simplify the structure of neural network and improve the speed and efficiency of network training. On this basis, a backpropagation neural network (BPNN) was constructed for predicting the risks in MSC digitization. The results of training the model based on some data show that the proposed BPNN model has a good predictive effect. Furthermore, our model was compared with the traditional artificial neural network (ANN) model on a test set. The comparison demonstrates that our model achieved better effect than the traditional model in risk prediction. The results also show that the selected three principal components are reasonable, and the evaluation index system is valuable. The research results provide new insights to the smooth digital transformation of the MSC.}
}
@article{DURAIVELU2022,
title = {Digital transformation in manufacturing industry – A comprehensive insight},
journal = {Materials Today: Proceedings},
year = {2022},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2022.07.409},
url = {https://www.sciencedirect.com/science/article/pii/S2214785322051008},
author = {K Duraivelu},
keywords = {Digital transformation, Manufacturing industry, Smart manufacturing, Digital factory, Industry 4.0},
abstract = {Digital disruption has upended the entire manufacturing industry across the world. Industry 4.0 has witnessed many opportunities from the advanced technologies to enhance efficiency in the existing manufacturing processes through automation, artificial intelligence and machine learning approaches. This article states the necessity of digital transformation (DX) in the manufacturing industry for improving quality and efficiency, reducing waste and cost reduction, adapting quickly to changes in the customer demands and market, and creating services and innovative products. The two most common types of DX in the manufacturing industry are process DX – digitizing the existing processes to improve the operational efficiency; product and service DX – creating new experiences and digital services for customers to improve customer satisfaction. This article also sets out to explore the challenges being faced by the manufacturing industry during the course of DX. The success factors of DX in the manufacturing industry could be associated with one of the three dimensions: organization, environment, and technology. The major steps for effective implementation of DX that a manufacturing company should consider are also discussed.}
}
@article{YANG2022101800,
title = {Can digital financial inclusion promote female entrepreneurship? Evidence and mechanisms},
journal = {The North American Journal of Economics and Finance},
volume = {63},
pages = {101800},
year = {2022},
issn = {1062-9408},
doi = {https://doi.org/10.1016/j.najef.2022.101800},
url = {https://www.sciencedirect.com/science/article/pii/S106294082200136X},
author = {Xiaolan Yang and Yidong Huang and Mei Gao},
keywords = {Digital financial inclusion, Female entrepreneurship, CFPS},
abstract = {Female entrepreneurship is important for business and economic development. However, women face greater obstacles than men in accessing financing and information, making it more difficult for them to engage in entrepreneurship. This paper examines the impact of digital financial inclusion on female entrepreneurship by using a national sample consisting of matched data from a digital financial inclusion index and a nationally representative survey. The results show that digital financial inclusion significantly promotes women’s entrepreneurial behavior. We find that digital financial inclusion can ease women’s financing constraints and provide business information to alleviate their information constraints. Furthermore, the development of digital financial inclusion improves women’s work flexibility, inspiring them to engage in entrepreneurship. In addition, digital financial inclusion has a greater effect on entrepreneurship among vulnerable women, such as those with less education or a lack of financial autonomy and those living in areas with high gender inequality, which supports the idea that digital financial inclusion can empower women.}
}
@article{YALCIN2022121193,
title = {The use of multi-criteria decision-making methods in business analytics: A comprehensive literature review},
journal = {Technological Forecasting and Social Change},
volume = {174},
pages = {121193},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.121193},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521006260},
author = {Ahmet Selcuk Yalcin and Huseyin Selcuk Kilic and Dursun Delen},
keywords = {Business analytics, Decision support, Multi-criteria decision making (MCDM), Multi-attribute decision-making (MADM), Multi-objective decision-making (MODM)},
abstract = {Business analytics (BA) systems are considered significant investments for enterprises because they have the potential to considerably improve firms’ performance. With the value offered by BA, companies are able to discover the hidden information in the data, improve decision-making processes, and support strategic planning. On the other hand, because there are multiple criteria and multiple alternatives involved in most decision-making situations, multi-criteria decision-making (MCDM) methods play an important role in BA practices. Providing inputs to the components of descriptive or predictive analytics or being used as a decision-making tool for evaluating the alternatives within prescriptive analytics exemplify the roles. Therefore, the use of hidden information discovered by business analytics and the need for utilizing the right MCDM method for optimal decision-making made these two concepts inseparable. In this paper, in order to review the use of MCDM methods in BA, the subject of BA is investigated from a taxonomical perspective (descriptive, predictive, and prescriptive), and its connection with MCDM techniques is revealed. Similarly, MCDM methods are studied using two main categories, multi-attribute decision making (MADM) and multi-objective decision making (MODM) methods. Furthermore, tabular and graphical analyses are also performed within the proposed review methodology. To the best of our knowledge, this review is the first attempt that holistically considers the use of MCDM methods in BA.}
}
@article{OLSZAK20221754,
title = {Business Intelligence Systems for Innovative Development of Organizations},
journal = {Procedia Computer Science},
volume = {207},
pages = {1754-1762},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.233},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922011188},
author = {Celina M. Olszak},
keywords = {Business Intelligence, innovative development, ICT, organizations},
abstract = {Today, it is believed that Business Intelligence (BI) systems have become a strategic tool for economic growth, determining the competitiveness of many organizations and their innovative development. A theory as well a practice show that BI systems are used mainly to: (a) develop modern strategies and business models; (b) creative sources of competitive advantage; (c) make fundamental transformations in organizations; and (d) integrate and develop the entire ecosystem. Unfortunately, the topic of components that determinate an innovative development of organizations based on BI is still a poorly understood issue. The study investigates a topic of BI and proposes a framework to provide BI-based innovative development of organizations. The framework contains four components: (a) digital strategy and support from top management; (b) BI infrastructure and tools; (c) information and knowledge repositories; and (d) organizational culture. The framework has been subjected to initial verification by conducting 150 direct interviews in small and medium enterprises among owners, top executives, and managers.}
}
@incollection{YANG2022,
title = {Building Energy Management Systems},
booktitle = {Reference Module in Earth Systems and Environmental Sciences},
publisher = {Elsevier},
year = {2022},
isbn = {978-0-12-409548-9},
doi = {https://doi.org/10.1016/B978-0-323-90386-8.00025-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323903868000255},
author = {Tong Yang and Derek Clements-Croome and Matthew Marson},
keywords = {Building automation, Energy management, Interoperability and adaptability, Sustainable design and operation, Technology and system integration},
abstract = {Building energy management systems (BEMS) are integrated building automation and energy management systems, utilizing IT or ICT, intelligent and interoperable digital communication technologies promoting a holistic approach to controls and providing adaptive operational optimization. The system may have multiple levels from individual sensors and actuators to users’ interface, to facilitate data collection, analysis, diagnose, trend finding, and decision-making. BEMS could provide flexible access to the building automation systems from several different platforms and locations. By using service-oriented abstractions to connect building, systems, and people, BEMS dynamically control indoor climate in a cost-effective manner and ensures the comfort, safety, and wellbeing of the occupants in buildings.}
}
@article{MEDIAVILLA20221126,
title = {Review and analysis of artificial intelligence methods for demand forecasting in supply chain management},
journal = {Procedia CIRP},
volume = {107},
pages = {1126-1131},
year = {2022},
note = {Leading manufacturing systems transformation – Proceedings of the 55th CIRP Conference on Manufacturing Systems 2022},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2022.05.119},
url = {https://www.sciencedirect.com/science/article/pii/S2212827122004036},
author = {Mario Angos Mediavilla and Fabian Dietrich and Daniel Palm},
keywords = {Demand Forecasting, Supply Chain Management, Artificial Intelligence, Machine Learning, Deep Learning, Review, Analysis},
abstract = {The proper selection of a demand forecasting method is directly linked to the success of supply chain management (SCM). However, today’s manufacturing companies are confronted with uncertain and dynamic markets. Consequently, classical statistical methods are not always appropriate for accurate and reliable forecasting. Algorithms of Artificial intelligence (AI) are currently used to improve statistical methods. Existing literature only gives a very general overview of the AI methods used in combination with demand forecasting. This paper provides an analysis of the AI methods published in the last five years (2017-2021). Furthermore, a classification is presented by clustering the AI methods in order to define the trend of the methods applied. Finally, a classification of the different AI methods according to the dimensionality of data, volume of data, and time horizon of the forecast is presented. The goal is to support the selection of the appropriate AI method to optimize demand forecasting.}
}
@article{PERDANA2022100547,
title = {Data analytics in small and mid-size enterprises: Enablers and inhibitors for business value and firm performance},
journal = {International Journal of Accounting Information Systems},
volume = {44},
pages = {100547},
year = {2022},
issn = {1467-0895},
doi = {https://doi.org/10.1016/j.accinf.2021.100547},
url = {https://www.sciencedirect.com/science/article/pii/S146708952100049X},
author = {Arif Perdana and Hwee Hoon Lee and SzeKee Koh and Desi Arisandi},
keywords = {IT business value, Data analytics, Dual factor concept, Resource-based view, RBV, Small-and-midsize enterprises, SMEs, IT-enabled resources},
abstract = {A critical question arises as to whether data analytics (DA) can bring value and improve organizational performance. The benefit offered by DA can be achieved only when organizations are able to direct their attention on the conditioning factors that amplify business value. At the same time, organizations should cautiously resolve the issues that dampen DA business value. This study applied resource-based view (RBV) and the dual factor concept to understand such factors within the Small and Mid-size Enterprises (SMEs) context. The results revealed that information and systems qualities were the catalysts for data analytics business value, whereas lack of understanding and concerns over data security and privacy were the most salient predictors that could prevent SMEs from realizing DA business value. Our study highlights the importance of understanding both enablers and inhibitors in IT business value research. We also offer strategies to stakeholders to help SMEs realize DA business value.}
}
@article{LIU2022101847,
title = {Exploring the effect of urban spatial development pattern on carbon dioxide emissions in China: A socioeconomic density distribution approach based on remotely sensed nighttime light data},
journal = {Computers, Environment and Urban Systems},
volume = {96},
pages = {101847},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2022.101847},
url = {https://www.sciencedirect.com/science/article/pii/S0198971522000916},
author = {Shirao Liu and Jingwei Shen and Guifen Liu and Yizhen Wu and Kaifang Shi},
keywords = {Urban spatial development pattern, Carbon dioxide emissions, Nighttime light data, NPP-VIIRS, Socioeconomic density distribution, China},
abstract = {Exploring the effect of urban spatial development pattern (UPD) on carbon dioxide emissions (CDEs) (EUC) is important for understanding low-carbon sustainable development. Numerous studies on EUC have mainly focused on individual cities or regions within the mixed conclusions due to the lack of reliable UPD indices and reasonable methods. Thus, taking China's 257 prefecture-level cities as experimental objects, a novel system approach was developed from the perspective of socioeconomic density distribution (SED) index to measure UPD on the basis of the Suomi National Polar-orbiting Partnership (NPP) visible infrared imaging radiometer suite (VIIRS) nighttime light data. EUC was then analyzed on the basis of the dynamic panel data model from multiple perspectives. Results show that the SED index can effectively measure UPD with rich spatial information from multiple dimensions. The coefficients of SED and (SED)2 are 0.129 and − 1.240, respectively, indicating that EUC shows a clear inverted U-shaped curve in China, i.e., an increase in UPD compactness increases CDEs at the beginning, and when a certain height is reached, an increase in UPD compactness decreases CDEs. Heterogeneity analysis indicates a U-shaped curve of EUC is found in megalopolis, and inverse U-shaped curve are observed in medium and small cities. Bus passenger volume, energy consumption, infrastructure, and housing demand are proven as the transmission factors of EUC. It is suggested that utilizing the positive externality effect of agglomeration and accelerating the inflection point of the inverse U-shaped curve may be necessary because the improvement of urban socioeconomic agglomeration will improve the UPD compactness and reduce CDEs.}
}
@article{LIANG2022115410,
title = {Assessing the validity of mobile device data for estimating visitor demographics and visitation patterns in Yellowstone National Park},
journal = {Journal of Environmental Management},
volume = {317},
pages = {115410},
year = {2022},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2022.115410},
url = {https://www.sciencedirect.com/science/article/pii/S0301479722009835},
author = {Yun Liang and Junjun Yin and Bing Pan and Michael S. Lin and Lauren Miller and B. Derrick Taff and Guangqing Chi},
keywords = {Mobile device data, Visitor demographics, Temporal visitation patterns, National park},
abstract = {Monitoring visitor demographics and temporal visitation patterns can help national park managers understand their visitors and allocate resources more effectively. Traditional approaches, such as visitor surveys or vehicle counts, are limited by time, space, labor, and financial resources. More recently, mobile device data have been adopted for monitoring visitors in park-related or tourism research. However, few studies validated mobile device data with traditional visitor surveys or count data. Combining mobile device data with the American Community Survey (ACS), this study assessed mobile device data's validity in a national park context with three approaches: Points of Interest (POIs), visitor demographics, and temporal visitation patterns. The results revealed that only half of the POIs inside Yellowstone National Park are valid. Compared to traditional visitor surveys, mobile device data are limited due to platform bias and the exclusion of international visitors, resulting in discrepancies in visitor demographics, such as education and income levels. Conversely, mobile device data have strong correlations with count data regarding monthly and daily visitation patterns. The results suggest that with careful consideration, mobile device data can serve as an additional and complementary source of information to traditional survey data for understanding visitor demographics and temporal visitation patterns.}
}
@article{ZHANG2022101779,
title = {Digital twin-driven intelligent production line for automotive MEMS pressure sensors},
journal = {Advanced Engineering Informatics},
volume = {54},
pages = {101779},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101779},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622002373},
author = {Quanyong Zhang and Shengnan Shen and Hui Li and Wan Cao and Wen Tang and Jing Jiang and Mingxing Deng and Yunfan Zhang and Beikang Gu and Kangkang Wu and Kun Zhang and Sheng Liu},
keywords = {Digital twin, Multi-source heterogeneous data acquisition, Parallel control, Real-time monitoring and mapping, Process optimization},
abstract = {The equipment and technological processes used in manufacturing electronic products are gradually being automated and networked. Currently, digital twin technology continues to evolve and mature. The electronics manufacturing industry is undergoing an intelligent and digital transformation. Micro-electro-mechanical system (MEMS) sensors have been widely used in the automotive field due to their small size, low cost, and high reliability. In this study, a new intelligent production line for automotive MEMS pressure sensors driven by digital twin is individually designed. The intelligent production line system consists of physical production lines, digital production lines, twin data, and data service systems. The technology of multi-source heterogeneous data acquisition is used to process and analyze data collected in real time in a physical production line. Based on the technology of parallel control, the physical and digital production lines are synchronized. To obtain optimal process parameters, a process database is established through the analysis of the key processes of the production line. Three types of automotive MEMS pressure sensors are successfully manufactured in the constructed digital twin-driven intelligent production line. The intelligent production line can realize 24-h unattended operation. The product yield is above 98 %, and the takt time is less than 16 s.}
}
@incollection{THOMASIAN2022623,
title = {Chapter 12 - Conclusions},
editor = {Alexander Thomasian},
booktitle = {Storage Systems},
publisher = {Morgan Kaufmann},
pages = {623},
year = {2022},
isbn = {978-0-323-90796-5},
doi = {https://doi.org/10.1016/B978-0-32-390796-5.00021-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323907965000218},
author = {Alexander Thomasian},
keywords = {Data preservation, provenance data cleansing},
abstract = {We discuss few topics not covered in the book to encourage readers to pursue them on their own.}
}
@article{TANG2022103833,
title = {Automatic number plate recognition (ANPR) in smart cities: A systematic review on technological advancements and application cases},
journal = {Cities},
volume = {129},
pages = {103833},
year = {2022},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2022.103833},
url = {https://www.sciencedirect.com/science/article/pii/S0264275122002724},
author = {Junqing Tang and Li Wan and Jennifer Schooling and Pengjun Zhao and Jun Chen and Shufen Wei},
keywords = {Automatic license plate recognition, Automatic number plate recognition, Automatic vehicle identification, Traffic sensing, Systematic literature review},
abstract = {Automatic Number Plate Recognition (ANPR) technology has been intensively engaged in managing the smartification and digitalization of cities in recent years as an effective tool for acquiring information about vehicle movements. As a traffic sensing technology, it has been popular across multiple scientific fields such as urban science, computer vision, and transportation management. However, we still lack a comprehensive review of this smart sensing technology, especially covering the current state and perspectives of how the technology can be leveraged in different aspects of urban management and what policy and social implications can be drawn from its application cases. In this paper, a systematic review of ANPR is delivered to discuss three aspects: the first aspect covers the technical advancements of ANPR technology; the second aspect focuses on analyzing the influential factors of its sensing performance in various contexts; the third aspect surveys the application cases of this technology and its practical implications from a user's perspective. Policy comparisons, emerging themes, and major underdeveloped areas are subsequently discussed and identified. Finally, four future ANPR research propositions in the smart city context are suggested with discussions of both theoretical and practical implications for scholars and practitioners.}
}
@article{YANG2022106417,
title = {Laser-induced breakdown spectroscopy combined with a convolutional neural network: A promising methodology for geochemical sample identification in Tianwen-1 Mars mission},
journal = {Spectrochimica Acta Part B: Atomic Spectroscopy},
volume = {192},
pages = {106417},
year = {2022},
issn = {0584-8547},
doi = {https://doi.org/10.1016/j.sab.2022.106417},
url = {https://www.sciencedirect.com/science/article/pii/S0584854722000611},
author = {Fan Yang and Lu-Ning Li and Wei-Ming Xu and Xiang-Feng Liu and Zhi-Cheng Cui and Liang-Chen Jia and Yang Liu and Jun-Hua Xu and Yu-Wei Chen and Xue-Sen Xu and Jian-Yu Wang and Hai Qi and Rong Shu},
keywords = {Laser-induced breakdown spectroscopy, Convolutional neural network, Sampling distance, Multi-distance spectra, MarSCoDe},
abstract = {As an in-situ and stand-off detection technique, laser-induced breakdown spectroscopy (LIBS) can perform efficient geochemical sample identification and classification with chemometrics, and therefore LIBS has played a shining role in planetary exploration missions. Unlike in laboratory experiments, the LIBS sampling distance in field detection for planetary exploration naturally varies. The considerable spectral differences caused by the varying distance can be a critical challenge for chemometrics model training and testing. In this research, we address this issue by focusing on the construction of a chemometrics model with powerful learning ability rather than the conventional spectral data processing for distance correction. Specifically, we have investigated the performance of a designed deep convolutional neural network (CNN) on datasets consisting of multi-distance spectra. More than 18,000 LIBS spectra were collected by a duplicate model of the MarSCoDe instrument for China's Tianwen-1 Mars mission, at eight different distances ranging from 2.0 m to 5.0 m. These spectra were acquired from 39 geochemical standard samples, which were classified by the deep CNN. The competence of the CNN is compared with that of four alternative chemometrics, i. e. back-propagation neural network, support vector machine, linear discriminant analysis, and logistic regression. The CNN can surpass the other four algorithms in terms of overall prediction accuracy. In addition, we have inspected the dependence of the CNN performance on the distance number involved in the training set and the data properties of the testing set. Furthermore, it has been revealed that the CNN model can behave even better if an extremely simple distance correction procedure is supplemented. Our results show that CNN is an extraordinary chemometrics for material classification on multi-distance spectra datasets, implying that CNN-LIBS is a promising methodology for geochemical sample identification/classification in Tianwen-1 mission and other future planetary exploration missions, and in even more field detection scenarios with varying sampling distance.}
}
@article{REN2022127709,
title = {Evaluating geographic and social inequity of urban parks in Shanghai through mobile phone-derived human activities},
journal = {Urban Forestry & Urban Greening},
volume = {76},
pages = {127709},
year = {2022},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2022.127709},
url = {https://www.sciencedirect.com/science/article/pii/S1618866722002527},
author = {Xiyuan Ren and ChengHe Guan},
keywords = {Geographic and social inequity, Urban park, Mobile phone data, Recreational activity, Low-recreation-demand population},
abstract = {The equity of urban park access has received great attention from studies on public service provision. However, individuals’ growing demands for recreational activities have brought diversity and complexity to park usages, drawing doubts on traditional measurements of park accessibility. To fill the gap, this study explores park equity issues with a dataset containing 12.03 million mobile phone users who accessed one of the 332 parks in Shanghai. We measured community-level park accessibility with two traditional place-based indicators – park area proportion and Gaussian-based 2SFCA accessibility, and three innovative activity-based indicators – park activity frequency, park activity trip length, and park activity duration. We then explored the geographic and social inequity by calculating Gini index and conducting correlation analysis. The results show that place-based and activity-based indicators presented citywide differences, indicating a significant impact of human activities on urban park accessibility. The geographic inequality of park distribution was undermined by people’s actual park usages. However, residents in communities with higher quality of built-environment had higher park activity frequency while shorter trip length, and social inequity of park access among the total population was more obvious than the low-recreation-demand population. Therefore, policy-makers should rethink how to provide park resources to address the inequity issues brought by human activities. Our study contributes to the existing literature in the following ways: (1) compared place-based park accessibility and activity-based park accessibility in the same context, and (2) identified low-recreation-demand population as a comparison group to explore impacts of recreation demand on park equity.}
}
@article{ALWAN2022109384,
title = {Time-series clustering for sensor fault detection in large-scale Cyber–Physical Systems},
journal = {Computer Networks},
volume = {218},
pages = {109384},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2022.109384},
url = {https://www.sciencedirect.com/science/article/pii/S1389128622004182},
author = {Ahmed A. Alwan and Allan J. Brimicombe and Mihaela Anca Ciupala and Seyed Ali Ghorashi and Andres Baravalle and Paolo Falcarin},
keywords = {Cyber–physical systems (CPSs), Wireless sensor networks(WSNs), Time-series clustering, Dynamic time warping, K-shape, Characteristics based time-series clustering},
abstract = {Large-scale Cyber–Physical Systems (CPSs) are information systems that involve a vast network of sensor nodes and other devices that stream observations in real-time and typically are deployed in uncontrolled, broad geographical terrains. Sensor node failures are inevitable and unpredictable events in large-scale CPSs, which compromise the integrity of the sensors measurements and potentially reduce the quality of CPSs services and raise serious concerns related to CPSs safety, reliability, performance, and security. While many studies were conducted to tackle the challenge of sensor nodes failure detection using domain-specific solutions, this paper proposes a novel sensor nodes failure detection approach and empirically evaluates its validity using a real-world case study. This paper investigates time-series clustering techniques as a feasible solution to identify sensor nodes malfunctions by detecting long-segmental outliers in their observations’ time series. Three different time-series clustering techniques have been investigated using real-world observations collected from two various sensor node networks, one of which consists of 275 temperature sensors distributed around London. This study demonstrates that time-series clustering effectively detects sensor node’s continuous (halting/repeating) and incipient faults. It also showed that the feature-based time series clustering technique is a more efficient long-segmental outliers detection mechanism compared to shape-based time-series clustering techniques such as DTW and K-Shape, mainly when applied to shorter time-series windows.}
}
@article{WUTTKE2022226,
title = {Synthetic Demand Generation with Seasonality for Data Mining on a Data-Farmed Data Basis of a Two-Echelon Supply Chain},
journal = {Procedia Computer Science},
volume = {204},
pages = {226-234},
year = {2022},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.08.027},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922007657},
author = {Alexander Wuttke and Joachim Hunker and Anne Antonia Scheidler and Markus Rabe},
keywords = {Data Farming, Knowledge Discovery in Databases, Data Mining, Simulation, Supply Chains, Synthetic Demand, Demand Generator},
abstract = {A widely used method in the context of supply chain analytics and management is data mining. It is used to discover patterns in a supply chain's data basis. Besides preprocessing observational real-world data, simulation can be used to create a suitable data basis. This process is referred to as data farming and involves using a simulation model as a data generator. A common input to a simulation model of a supply chain is demand of stock keeping units that is likely to project to the model's behavior. When testing novel approaches or in planning stages, demand of real-world supply chains is not always available or viable to adept. In this case, synthetically created demand can be used. A general approach of realistic demand generation with seasonality by a demand generator in the context of data farming is presented and further exemplified on a data farming and data mining framework of a two-echelon supply chain.}
}
@article{RAFFIN2022130,
title = {A reference architecture for the operationalization of machine learning models in manufacturing},
journal = {Procedia CIRP},
volume = {115},
pages = {130-135},
year = {2022},
note = {10th CIRP Global Web Conference – Material Aspects of Manufacturing Processes},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2022.10.062},
url = {https://www.sciencedirect.com/science/article/pii/S2212827122014974},
author = {Tim Raffin and Tobias Reichenstein and Jonas Werner and Alexander Kühl and Jörg Franke},
keywords = {Machine Learning, Deep Learning, MLOps, Manufacturing},
abstract = {Inherent characteristics of machine learning algorithms such as their probabilistic nature, their reliance on large datasets as well as their need for constant retraining pose major challenges to the operationalization of machine learning models (MLOps) in the manufacturing domain. As such systems are known to quickly accumulate technical debt due to system-level interdependencies of code, data, and models, clear abstractions boundaries are mandatory. Therefore, this publication derives a systematic functional decomposition of an MLOps system tailored to the manufacturing industry into specific domains and contexts. Moreover, a concrete deployment view is provided, and possible future research directions are discussed.}
}
@article{LI2022119120,
title = {Health-Conscious vehicle battery state estimation based on deep transfer learning},
journal = {Applied Energy},
volume = {316},
pages = {119120},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2022.119120},
url = {https://www.sciencedirect.com/science/article/pii/S0306261922005013},
author = {Shuangqi Li and Hongwen He and Pengfei Zhao and Shuang Cheng},
keywords = {Transportation electrification, Electric vehicles, Battery energy storage, Deep transfer learning, Battery management system, Battery state estimation},
abstract = {Establishing an accurate mathematical model is fundamental to managing, monitoring, and protecting the battery pack in electric vehicles (EVs). The application of the deep learning algorithm-based state estimation method can significantly improve the accuracy and stability of the battery model but is hindered by the great demand for training data. This paper addresses the challenge of health-conscious battery modeling by utilizing multi-source data based on a novel deep transfer learning method. Firstly, a cloud-based battery management framework is designed, which is able to collect and process battery operation data from various EVs and provide a foundation for deploying the transfer learning method. Battery healthy state information in the collected dataset is labeled by a generic perception model, which can be commonly used to quantify the aging state of different battery packs and facilitate the knowledge transfer process. Additionally, a deep transfer learning method is developed to boost the training process of the battery model, where the operation data from different types of EVs can be used for establishing state estimators. The method is verified by the battery operation data collected from two types of electric buses. With the developed healthy state perception model and transfer learning method, battery model error can be limited to 2.43% and 1.27% in the whole life cycle.}
}
@article{VANDEWETERING2022e11484,
title = {The role of enterprise architecture-driven dynamic capabilities and operational digital ambidexterity in driving business value under the COVID-19 shock},
journal = {Heliyon},
volume = {8},
number = {11},
pages = {e11484},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e11484},
url = {https://www.sciencedirect.com/science/article/pii/S2405844022027724},
author = {Rogier {van de Wetering}},
keywords = {Dynamic capabilities, Enterprise architecture (EA), EA-Driven dynamic capabilities, Digital dynamic capability, Operational digital ambidexterity, Business value under COVID-19},
abstract = {This article builds upon the dynamic capabilities view and argues that firms that developed their dynamic capabilities using enterprise architecture (EA) are better equipped to cope with the COVID-19 shock. An online survey collected data from 414 senior practitioners, business and IT managers, and executives. The study’s research model containing three hypotheses was assessed by applying Partial Least Squares (PLS) structural equation modeling (SEM), PLS-SEM. Outcomes point out that dynamic capabilities driven by EA enhance the firm’s digital dynamic capability and, therefore, the competencies to manage digital technologies. This capability subsequently enhances the firms' operational digital ambidexterity. Also, outcomes show that operational digital ambidexterity significantly impacts business value. This study advances our knowledge and insights on developing EA-driven dynamic capabilities under COVID-19 and unfolds key areas where decision-makers should invest in enhancing business value.}
}
@article{RUAN2022157075,
title = {Spatial-temporal NDVI pattern of global mangroves: A growing trend during 2000–2018},
journal = {Science of The Total Environment},
volume = {844},
pages = {157075},
year = {2022},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2022.157075},
url = {https://www.sciencedirect.com/science/article/pii/S0048969722041729},
author = {Linlin Ruan and Min Yan and Li Zhang and XiangShun Fan and Haoxiang Yang},
keywords = {Global mangroves, NDVI, Precipitation, Temperature, Sea surface salinity},
abstract = {Mangroves are coastal vegetation with high ecological and economic value that are mainly distributed in tropical and subtropical intertidal zones. In the past, they have been degraded by extensive deforestation for agricultural and aquatic land. In recent years, mangroves have been protected and sustainably used through considerable measures of conservation, restoration and afforestation, but the health trends of mangroves during this process are not clear. To identify the mangrove health conditions and dynamics, we investigated the spatial-temporal trends of global mangroves using the Moderate Resolution Imaging Spectroradiometer (MODIS) normalized difference vegetation index (NDVI) dataset during 2000–2018. The results illustrated that 1) Asian mangroves had the highest NDVI values, especially in Southeast Asia (0.80), while the average NDVI of African mangroves was the lowest (0.67). NDVI values higher than 0.80 were mainly located in Southeast Asia and South America, which accounted for 24.0 % and 7.1 % of the global mangrove area, respectively. 2) Globally, the proportion of mangrove forests that increased significantly (23.6 %, p value < 0.05) was approximately twice as large as the significant decrease (10.7 %, p value < 0.05). Asia, where mangroves are widespread, accounts for nearly half of the world's significant increase (10.8 %) and decrease (4.6 %). Generally, the annual average NDVI for global mangroves exhibited a slow increasing trend from 2000 to 2018 (p value = 0.13). 3) The global mangrove NDVI showed a positive correlation with precipitation (Rprep = 0.79, p value < 0.01) and temperature (Rtemp = 0.37, p value < 0.01), while it was inhibited by sea surface salinity (Rsss = −0.45, p value < 0.01) on a scale of 1° of latitude. 4) The results of the overall growth trend of mangroves indicated that global mangrove conservation appeared to achieve initial success, but direct or potential factors, such as salinity stress, natural disasters, small-scale deforestation, construction of coastal facilities, and sea level rise, still threaten the survival of mangroves, leading to a decline in their health status. This study provides information on the health status of mangrove ecosystems and can assist in formulating subsequent conservation and management measures.}
}
@article{VARADHARAJAN2022105024,
title = {BASIN-3D: A brokering framework to integrate diverse environmental data},
journal = {Computers & Geosciences},
volume = {159},
pages = {105024},
year = {2022},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2021.105024},
url = {https://www.sciencedirect.com/science/article/pii/S0098300421003058},
author = {Charuleka Varadharajan and Valerie C. Hendrix and Danielle S. Christianson and Madison Burrus and Catherine Wong and Susan S. Hubbard and Deborah A. Agarwal},
keywords = {Data integration, Multiscale diverse data, Synthesis, Environmental data},
abstract = {Diverse observational and simulation datasets are needed to understand and predict complex ecosystem behavior over seasonal to decadal and century time-scales. Integration of these datasets poses a major barrier towards advancing environmental science, particularly due to differences in the structure and formats of data provided by various sources. Here, we describe BASIN-3D (Broker for Assimilation, Synthesis and Integration of eNvironmental Diverse, Distributed Datasets), a data integration framework designed to dynamically retrieve and transform heterogeneous data from different sources into a common format to provide an integrated view. BASIN-3D enables users to adopt a standardized approach for data retrieval and avoid customizations for the data type or source. We demonstrate the value of BASIN-3D with two use cases that require integration of data from regional to watershed spatial scales. The first application uses the BASIN-3D Python library to integrate time-series hydrological and meteorological data to provide standardized inputs to analytical and machine learning codes in order to predict the impacts of hydrological disturbances on large river corridors of the United States. The second application uses the BASIN-3D Django framework to integrate diverse time-series data in a mountainous watershed in East River, Colorado, United States to enable scientific researchers to explore and download data through an interactive web portal. Thus, BASIN-3D can be used to support data integration for both web-based tools, as well as data analytics using Python scripting and extensions like Jupyter notebooks. The framework is expected to be transferable to and useful for many other field and modeling studies.}
}
@article{TUMBAJOY2022681,
title = {Enabling Industry 4.0 impact assessment with manufacturing system simulation: an OEE based methodology},
journal = {Procedia CIRP},
volume = {107},
pages = {681-686},
year = {2022},
note = {Leading manufacturing systems transformation – Proceedings of the 55th CIRP Conference on Manufacturing Systems 2022},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2022.05.045},
url = {https://www.sciencedirect.com/science/article/pii/S2212827122003298},
author = {Luisa M. Tumbajoy and Mariela Muñoz-Añasco and Sebastian Thiede},
keywords = {Smart Manufacturing, Industry 4.0, Key Performance Indicator, Simulation},
abstract = {Increasing digitalization in manufacturing, often associated with terms like Industry 4.0 (I4.0) or Smart Manufacturing, is a topic of crucial concern for manufacturing companies. Different digital technologies (DTs) can be integrated into manufacturing processes and systems aiming at increasing flexibility, product quality or productivity. The type and scope of potential DTs must be carefully selected when planning and improving a manufacturing system. The definition and configuration could be supported by simulation techniques that assess the DTs' impact on the manufacturing system and its final performance. However, parametrizing the DTs into a simulation tool is not straightforward since appropriate models might be challenging to obtain and actual impacts of DTs are uncertain. Against this background, the paper presents methods to enable a simulation-based assessment while considering the impact of not just individual but also a combination of DTs. The paper introduces a framework to define the base characteristics of selected DTs within a manufacturing system and their parameterization into a commercial simulation tool. Furthermore, the usability and expectable results are demonstrated in a case study.}
}
@incollection{ZOHURI202287,
title = {Chapter 4 - Structured and unstructured data processing},
editor = {Bahman Zohuri and Farhang Mossavar-Rahmani and Farahnaz Behgounia},
booktitle = {Knowledge is Power in Four Dimensions: Models to Forecast Future Paradigm},
publisher = {Academic Press},
pages = {87-119},
year = {2022},
isbn = {978-0-323-95112-8},
doi = {https://doi.org/10.1016/B978-0-323-95112-8.00004-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780323951128000040},
author = {Bahman Zohuri and Farhang Mossavar-Rahmani and Farahnaz Behgounia},
keywords = {Big data, Data analytics, Data productive, Structured data, Unstructured data},
abstract = {The amount of data that are being created and stored on a global level is almost inconceivable, and it just keeps growing. That means there is even more potential to glean key insights from business information—yet only a small percentage of data is actually analyzed. What does that mean for businesses? How can they make better use of the raw information that flows into their organizations every day? With respect to the mass categorization that is central to most computer operations, there are two types of relevant data, which affect the speed of assimilation as well as information recall: structured data and unstructured data. Smart robots need both types of data in order to sort and process these data as fast they receive them to the level of trusted degree for their processing procedure and set assignment, known as service-level agreement. Please note that with minor editing and manipulation, the materials presented in this chapter have been borrowed from the book published from Zohuri and Moghaddam2 with permission from both authors and publisher as well.}
}
@article{BATCHU2022104571,
title = {On improving the performance of DDoS attack detection system},
journal = {Microprocessors and Microsystems},
volume = {93},
pages = {104571},
year = {2022},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2022.104571},
url = {https://www.sciencedirect.com/science/article/pii/S0141933122001235},
author = {Raj Kumar Batchu and Hari Seetha},
keywords = {DDoS attacks, Data preprocessing, Feature selection, Extreme learning machine, CICDDoS-2019 dataset},
abstract = {A DDoS (Distributed Denial of Service) attack is a harmful way of preventing regular access to a targeted machine, resources, or any network by flooding the target or its neighbouring infrastructure with massive traffic in an attempt to cause an interruption. As a result, the network environment's security has suffered significantly. Although numerous ways have been proposed in previous studies, there is still room for new ones as attacker patterns, and strategies change rapidly. This work designs a quick and efficient detection model to identify the latest real-world attacks. An attempt was made for an effective data pre-processing that includes both memory optimization and hybrid feature selection to improve the model's generalizability. Furthermore, the extreme learning machine (ELM) classifier is analyzed with the extracted features by varying weight ranges, hidden neurons, and activation functions to classify the attacks. Experiments are conducted using the CICDDoS-2019 traffic data. The experimental outcomes indicate that the suggested model is superior to previous strategies, with a detection accuracy of 99.94%.}
}
@article{LIU2022100187,
title = {DIA-Based Proteomics Identifies IDH2 as a Targetable Regulator of Acquired Drug Resistance in Chronic Myeloid Leukemia},
journal = {Molecular & Cellular Proteomics},
volume = {21},
number = {2},
pages = {100187},
year = {2022},
issn = {1535-9476},
doi = {https://doi.org/10.1016/j.mcpro.2021.100187},
url = {https://www.sciencedirect.com/science/article/pii/S1535947621001596},
author = {Wei Liu and Yaoting Sun and Weigang Ge and Fangfei Zhang and Lin Gan and Yi Zhu and Tiannan Guo and Kexin Liu},
keywords = {drug resistance, DIA, imatinib, adriamycin, IDH2, Chronic Myeloid Leukemia},
abstract = {Drug resistance is a critical obstacle to effective treatment in patients with chronic myeloid leukemia. To understand the underlying resistance mechanisms in response to imatinib mesylate (IMA) and adriamycin (ADR), the parental K562 cells were treated with low doses of IMA or ADR for 2 months to generate derivative cells with mild, intermediate, and severe resistance to the drugs as defined by their increasing resistance index. PulseDIA-based (DIA [data-independent acquisition]) quantitative proteomics was then employed to reveal the proteome changes in these resistant cells. In total, 7082 proteins from 98,232 peptides were identified and quantified from the dataset using four DIA software tools including OpenSWATH, Spectronaut, DIA-NN, and EncyclopeDIA. Sirtuin signaling pathway was found to be significantly enriched in both ADR-resistant and IMA-resistant K562 cells. In particular, isocitrate dehydrogenase (NADP(+)) 2 was identified as a potential drug target correlated with the drug resistance phenotype, and its inhibition by the antagonist AGI-6780 reversed the acquired resistance in K562 cells to either ADR or IMA. Together, our study has implicated isocitrate dehydrogenase (NADP(+)) 2 as a potential target that can be therapeutically leveraged to alleviate the drug resistance in K562 cells when treated with IMA and ADR.}
}
@article{KINKEL2022102375,
title = {Prerequisites for the adoption of AI technologies in manufacturing – Evidence from a worldwide sample of manufacturing companies},
journal = {Technovation},
volume = {110},
pages = {102375},
year = {2022},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2021.102375},
url = {https://www.sciencedirect.com/science/article/pii/S0166497221001565},
author = {Steffen Kinkel and Marco Baumgartner and Enrica Cherubini},
keywords = {Artificial intelligence (AI), Machine learning (ML), Industry 4.0, Digital skills, Technology adoption, Technology-organization-environment framework},
abstract = {In current discussions, Artificial Intelligence (AI) is ascribed great influence on production processes. Research on AI has seen tremendous growth in recent years. However, most of the research has focused primarily on various AI technologies, and less on prerequisites and enablers for adoption of AI at firm-level. This is surprising, given the fact that many companies are still struggling to establish AI in their production and to drive their AI adoption forward. To close this gap, this study analyses the impact of various technological, organizational and environmental (TOE) prerequisites for a successful adoption of AI technologies in manufacturing. Based on a cross-national survey of 655 company representatives from the manufacturing industry, our results contribute to a better understanding of why some companies are more determined than others when it comes to implementing AI in their production. We find evidence that organizational factors, such as digital skills, company size, and R&D intensity, have the greatest impact on the adoption of AI in manufacturing. Furthermore, in order to gain new insights into the interplay of new technology adoption and global production strategies, this paper addresses the question of which factors explain a primarily domestic or globally oriented technology adoption. We find that especially research-intensive, knowledge-based and service-oriented companies tend to roll out AI technologies not only at their domestic but also at their foreign production sites.}
}
@article{LI2022102803,
title = {Assessing personal travel exposure to on-road PM2.5 using cellphone positioning data and mobile sensors},
journal = {Health & Place},
volume = {75},
pages = {102803},
year = {2022},
issn = {1353-8292},
doi = {https://doi.org/10.1016/j.healthplace.2022.102803},
url = {https://www.sciencedirect.com/science/article/pii/S1353829222000648},
author = {Qiuping Li and Shen Liang and Yang Xu and Lin Liu and Suhong Zhou},
keywords = {Travel exposure, On-road PM concentrations, Cellphone positioning data, Mobile sensors},
abstract = {PM2.5 pollution imposes substantial health risks on urban residents. Previous studies mainly focused on assessing peoples' exposures at static locations, such as homes or workplaces. There has been a scarcity of research that quantifies the dynamic PM2.5 exposures of people when they travel in cities. To address this gap, we use cellphone positioning data and PM2.5 concentration data collected from smart sensors along roads in Guangzhou, China, to assess personal travel exposure to on-road PM2.5. First, we extract the trips of cellphone users from their trajectories and use the shortest path algorithm to calculate their travel routes on the road network. Second, the travel exposure of each user is estimated by associating their movement patterns with PM2.5 concentrations on roads. The result shows that most users’ average travel exposures per hour fall within the range of 20 ug/m3 to 75 ug/m3. Travel exposure varies across users, and 54.0% of users experience low travel exposure throughout the day, 25.5% of users experience high travel exposure in the evening, and 20.5% of users experience high travel exposure in the afternoon. Furthermore, the impacts of on-road PM2.5 on urban populations are uneven across roads. More attention should be given to roads with high PM2.5 concentrations and traffic flows in each period, such as Huan Shi Middle Road in the morning, Inner Ring Road in the afternoon, and Xinjiao Middle Road in the evening. The findings in this study can contribute to a more in-depth understanding of the relationship between air pollution and the travel activities of urban populations.}
}