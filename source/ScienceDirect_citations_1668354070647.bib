@article{PAVEL20224837,
title = {The potential of a data centred approach & knowledge graph data representation in chemical safety and drug design},
journal = {Computational and Structural Biotechnology Journal},
volume = {20},
pages = {4837-4849},
year = {2022},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2022.08.061},
url = {https://www.sciencedirect.com/science/article/pii/S2001037022003956},
author = {Alisa Pavel and Laura A. Saarimäki and Lena Möbus and Antonio Federico and Angela Serra and Dario Greco},
keywords = {Knowledge graph, Big data, Data integration, Toxicology, Drug design, Chemical safety},
abstract = {Big Data pervades nearly all areas of life sciences, yet the analysis of large integrated data sets remains a major challenge. Moreover, the field of life sciences is highly fragmented and, consequently, so is its data, knowledge, and standards. This, in turn, makes integrated data analysis and knowledge gathering across sub-fields a demanding task. At the same time, the integration of various research angles and data types is crucial for modelling the complexity of organisms and biological processes in a holistic manner. This is especially valid in the context of drug development and chemical safety assessment where computational methods can provide solutions for the urgent need of fast, effective, and sustainable approaches. At the same time, such computational methods require the development of methodologies suitable for an integrated and data centred Big Data view. Here we discuss Knowledge Graphs (KG) as a solution to a data centred analysis approach for drug and chemical development and safety assessment. KGs are knowledge bases, data analysis engines, and knowledge discovery systems all in one, allowing them to be used from simple data retrieval, over meta-analysis to complex predictive and knowledge discovery systems. Therefore, KGs have immense potential to advance the data centred approach, the re-usability, and informativity of data. Furthermore, they can improve the power of analysis, and the complexity of modelled processes, all while providing knowledge in a natively human understandable network data model.}
}
@article{CREMIN2022138,
title = {Big data: Historic advances and emerging trends in biomedical research},
journal = {Current Research in Biotechnology},
volume = {4},
pages = {138-151},
year = {2022},
issn = {2590-2628},
doi = {https://doi.org/10.1016/j.crbiot.2022.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S2590262822000090},
author = {Conor John Cremin and Sabyasachi Dash and Xiaofeng Huang},
keywords = {Big data, Big data in biomedicine, Data analytics in biomedical research, Multiomics big data, Biomedical data management, Big data in personalized medicine},
abstract = {Big data is transforming biomedical research by integrating massive amounts of data from laboratory experiments, clinical investigations, healthcare records, and the internet of things. Specifically, the increasing rate at which information is obtained from omics technologies (genomics, epigenomics, transcriptomics, proteomics, metabolomics, and pharmacogenomics) is providing an opportunity for future advances in personalized medicine that are paving the way to improved patient care. The recent advances in omics technologies are profoundly contributing to big data in biomedicine and are anticipated to aid in disease diagnosis and patient care management. Herein, we critically review the major computational techniques, algorithms, and their outcomes that have contributed to recent advances in big data generated from biomedical research in various complex human diseases, such as cancer and infectious diseases. Finally, we discuss trends in the field and the future directions that must be considered to advance the influence of big data on biomedical research and its translation in the healthcare industry.}
}
@article{JACOBBRASSARD2022,
title = {Big data: Using databases and registries},
journal = {Seminars in Vascular Surgery},
year = {2022},
issn = {0895-7967},
doi = {https://doi.org/10.1053/j.semvascsurg.2022.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S089579672200062X},
author = {Jean Jacob-Brassard and Charles {de Mestral}},
abstract = {ABSTRACT
The field of vascular surgery is in constant evolution. Administrative data and registries can provide important contemporary evidence to inform clinical decision making and delivery of health services. This review outlines some important considerations for retrospective studies using administrative health databases and registries. First, these data sources have advantages (e.g., real-world applicability, timely data access, and relatively lower research cost) and disadvantages (e.g., potential missing data, selection bias, and confounding bias) that may be more or less relevant to different administrative databases or registries. Second, a framework to guide data source selection and provide a summary of frequently used data sources in vascular surgery research is discussed. Third, a retrospective study design warrants planned exposure, outcome, and covariate definitions and, when studying an exposure–outcome association, careful consideration of confounders through direct acyclic graphs. Finally, investigators must plan the most appropriate analytic approach, and we distinguish descriptive, explanatory, and predictive analyses.}
}
@article{ZHAO202256,
title = {Metaverse: Perspectives from graphics, interactions and visualization},
journal = {Visual Informatics},
volume = {6},
number = {1},
pages = {56-67},
year = {2022},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2022.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X22000158},
author = {Yuheng Zhao and Jinjing Jiang and Yi Chen and Richen Liu and Yalong Yang and Xiangyang Xue and Siming Chen},
keywords = {Metaverse, Virtual reality/Augmented reality, Computer graphics, User interaction, Immersive visualization},
abstract = {The metaverse is a visual world that blends the physical world and digital world. At present, the development of the metaverse is still in the early stage, and there lacks a framework for the visual construction and exploration of the metaverse. In this paper, we propose a framework that summarizes how graphics, interaction, and visualization techniques support the visual construction of the metaverse and user-centric exploration. We introduce three kinds of visual elements that compose the metaverse and the two graphical construction methods in a pipeline. We propose a taxonomy of interaction technologies based on interaction tasks, user actions, feedback and various sensory channels, and a taxonomy of visualization techniques that assist user awareness. Current potential applications and future opportunities are discussed in the context of visual construction and exploration of the metaverse. We hope this paper can provide a stepping stone for further research in the area of graphics, interaction and visualization in the metaverse.}
}
@article{PRODHAN2022105327,
title = {A review of machine learning methods for drought hazard monitoring and forecasting: Current research trends, challenges, and future research directions},
journal = {Environmental Modelling & Software},
volume = {149},
pages = {105327},
year = {2022},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2022.105327},
url = {https://www.sciencedirect.com/science/article/pii/S1364815222000330},
author = {Foyez Ahmed Prodhan and Jiahua Zhang and Shaikh Shamim Hasan and Til Prasad {Pangali Sharma} and Hasiba Pervin Mohana},
keywords = {Machine learning, Deep learning, Forecasting, Drought, Big data},
abstract = {Machine learning is a dynamic field with wide-ranging applications, including drought modeling and forecasting. Drought is a complex, devastating natural disaster for which it is challenging to develop effective prediction models. Therefore, our review focuses on basic information about machine learning methods (MLMs) and their potential applications in developing efficient and effective drought forecasting models. We observed that MLMs have achieved significant advances in the robustness, effectiveness, and accuracy of the algorithms for drought modelling in recent years. The performance comparison of MLMs with other models provides a comprehensive conception of different model evaluation metrics. Further challenges of MLMs, such as inadequate training data sets, noise, outliers, and observation bias for spatial data sets, are explored. Finally, our review conveys in-depth understanding to researchers on machine learning applications in forecasting and modeling and provides drought mitigation strategy guidance for policymakers.}
}
@article{CARTOLOVNI2022104738,
title = {Ethical, legal, and social considerations of AI-based medical decision-support tools: A scoping review},
journal = {International Journal of Medical Informatics},
volume = {161},
pages = {104738},
year = {2022},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2022.104738},
url = {https://www.sciencedirect.com/science/article/pii/S1386505622000521},
author = {Anto Čartolovni and Ana Tomičić and Elvira {Lazić Mosler}},
keywords = {Artificial intelligence, Medical ethics, Decision-making, Transparency, ELSI, Ethics by design, decision-making, medical AI, bioethics, digital health},
abstract = {Introduction
Recent developments in the field of Artificial Intelligence (AI) applied to healthcare promise to solve many of the existing global issues in advancing human health and managing global health challenges. This comprehensive review aims not only to surface the underlying ethical and legal but also social implications (ELSI) that have been overlooked in recent reviews while deserving equal attention in the development stage, and certainly ahead of implementation in healthcare. It is intended to guide various stakeholders (eg. designers, engineers, clinicians) in addressing the ELSI of AI at the design stage using the Ethics by Design (EbD) approach.
Methods
The authors followed a systematised scoping methodology and searched the following databases: Pubmed, Web of science, Ovid, Scopus, IEEE Xplore, EBSCO Search (Academic Search Premier, CINAHL, PSYCINFO, APA PsycArticles, ERIC) for the ELSI of AI in healthcare through January 2021. Data were charted and synthesised, and the authors conducted a descriptive and thematic analysis of the collected data.
Results
After reviewing 1108 papers, 94 were included in the final analysis. Our results show a growing interest in the academic community for ELSI in the field of AI. The main issues of concern identified in our analysis fall into four main clusters of impact: AI algorithms, physicians, patients, and healthcare in general. The most prevalent issues are patient safety, algorithmic transparency, lack of proper regulation, liability & accountability, impact on patient-physician relationship and governance of AI empowered healthcare.
Conclusions
The results of our review confirm the potential of AI to significantly improve patient care, but the drawbacks to its implementation relate to complex ELSI that have yet to be addressed. Most ELSI refer to the impact on and extension of the reciprocal and fiduciary patient-physician relationship. With the integration of AIbased decision making tools, a bilateral patient-physician relationship may shift into a trilateral one.}
}
@article{KEDDY2022e130,
title = {Using big data and mobile health to manage diarrhoeal disease in children in low-income and middle-income countries: societal barriers and ethical implications},
journal = {The Lancet Infectious Diseases},
volume = {22},
number = {5},
pages = {e130-e142},
year = {2022},
issn = {1473-3099},
doi = {https://doi.org/10.1016/S1473-3099(21)00585-5},
url = {https://www.sciencedirect.com/science/article/pii/S1473309921005855},
author = {Karen H Keddy and Senjuti Saha and Samuel Kariuki and John Bosco Kalule and Farah Naz Qamar and Zoya Haq and Iruka N Okeke},
abstract = {Summary
Diarrhoea is an important cause of morbidity and mortality in children from low-income and middle-income countries (LMICs), despite advances in the management of this condition. Understanding of the causes of diarrhoea in children in LMICs has advanced owing to large multinational studies and big data analytics computing the disease burden, identifying the important variables that have contributed to reducing this burden. The advent of the mobile phone has further enabled the management of childhood diarrhoea by providing both clinical support to health-care workers (such as diagnosis and management) and communicating preventive measures to carers (such as breastfeeding and vaccination reminders) in some settings. There are still challenges in addressing the burden of diarrhoeal diseases, such as incomplete patient information, underrepresented geographical areas, concerns about patient confidentiality, unequal partnerships between study investigators, and the reactive approach to outbreaks. A transparent approach to promote the inclusion of researchers in LMICs could address partnership imbalances. A big data umbrella encompassing cloud-based centralised databases to analyse interlinked human, animal, agricultural, social, and climate data would provide an informative solution to the development of appropriate management protocols in LMICs.}
}
@article{XU2022105396,
title = {An overview of visualization and visual analytics applications in water resources management},
journal = {Environmental Modelling & Software},
volume = {153},
pages = {105396},
year = {2022},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2022.105396},
url = {https://www.sciencedirect.com/science/article/pii/S1364815222001025},
author = {Haowen Xu and Andy Berres and Yan Liu and Melissa R. Allen-Dumas and Jibonananda Sanyal},
keywords = {Big Data, Hydroinformatics, Visual Analytics, Visualization, Human-Computer Interaction},
abstract = {Recent advances in information, communication, and environmental monitoring technologies have increased the availability, spatiotemporal resolution, and quality of water-related data, thereby leading to the emergence of many innovative big data applications. Among these applications, visualization and visual analytics, also known as the visual computing techniques, empower the synergy of computational methods (e.g., machine learning and statistical models) with human reasoning to improve the understanding and solution toward complex science and engineering problems. These approaches are frequently integrated with geographic information systems and cyberinfrastructure to provide new opportunities and methods for enhancing water resources management. In this paper, we present a comprehensive review of recent hydroinformatics applications that employ visual computing techniques to (1) support complex data-driven research problems, and (2) support the communication and decision-makings in the water resources management sector. Then, we conduct a technical review of the state-of-the-art web-based visualization technologies and libraries to share our experiences on developing shareable, adaptive, and interactive visualizations and visual interfaces for water resources management applications. We close with a vision that applies the emerging visual computing technologies and paradigms to develop the next generation of hydroinformatics applications.}
}
@article{MADAN2022101774,
title = {AI adoption and diffusion in public administration: A systematic literature review and future research agenda},
journal = {Government Information Quarterly},
pages = {101774},
year = {2022},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2022.101774},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X22001101},
author = {Rohit Madan and Mona Ashok},
keywords = {Public administration, Public values, AI tensions, Absorptive capacity, Data governance, AI adoption, AI diffusion},
abstract = {Artificial Intelligence (AI) implementation in public administration is gaining momentum heralded by the hope of smart public services that are personalised, lean, and efficient. However, the use of AI in public administration is riddled with ethical tensions of fairness, transparency, privacy, and human rights. We call these AI tensions. The current literature lacks a contextual and processual understanding of AI adoption and diffusion in public administration to be able to explore such tensions. Previous studies have outlined risks, benefits, and challenges with the use of AI in public administration. However, a large gap remains in understanding AI tensions as they relate to public value creation. Through a systematic literature review grounded in public value management and the resource-based view of the firms, we identify technology-organisational-environmental (TOE) contextual variables and absorptive capacity as factors influencing AI adoption as discussed in the literature. To our knowledge, this is the first paper that outlines distinct AI tensions from an AI implementation and diffusion perspective within public administration. We develop a future research agenda for the full AI innovation lifecycle of adoption, implementation, and diffusion.}
}
@article{CORSI2022100310,
title = {Ultimate approach and technologies in smart healthcare: A broad systematic review focused on citizens},
journal = {Smart Health},
volume = {26},
pages = {100310},
year = {2022},
issn = {2352-6483},
doi = {https://doi.org/10.1016/j.smhl.2022.100310},
url = {https://www.sciencedirect.com/science/article/pii/S2352648322000447},
author = {Alana Corsi and Fabiane {Florencio de Souza} and Regina Negri Pagani and João Luiz Kovaleski},
keywords = {Smart cities, Smart healthcare. smart citizens. Citizen's role. technology},
abstract = {Smart Cities are city models that emerged to face the problems of current city configurations, promoting improvement in infrastructure and the provision of essential services through technological implementation. The provision of health services is necessary and a civil right, being one of the dimensions proposed in Smart Cities, represented by Smart Healthcare. This model of cities, as well as its dimensions, have great appeal in the technological application, as the main means of promoting smart services. However, it appears that the approach to the role of the citizen in the promotion of intelligence is neglected, leaving questions about the role of the citizen in Smart Cities. Thus, the present study aimed to identify the technological structures applied in Smart Healthcare, allowing us to identify the role of the citizen in the promotion of smarter health services. A systematic literature review was carried out using the Methodi Ordinatio, resulting in a portfolio composed of 26 articles with scientific relevance. From the content analysis, four main approaches were identified, as well as technologies and methods to address one of the biggest challenges of health technologies: data security and privacy. From this, the role of the citizen in the Smart Healthcare was evidenced, aiming to contribute to the planning of projects and the development of future research to consider with more attention the participation of citizens.}
}
@article{YOON2022104578,
title = {Virtual sensing in intelligent buildings and digitalization},
journal = {Automation in Construction},
volume = {143},
pages = {104578},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104578},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522004484},
author = {Sungmin Yoon},
keywords = {Virtual sensors, Virtual sensor calibration, Virtual sensing applications, Intelligent buildings, Digital twins, Building digitalization},
abstract = {Virtual sensing technologies have a huge potential in an informative and reliable sensing environment, which is essential to provide and maintain intelligent services in building life-cycle and digitalization. However, there remains a lack of comprehensive literature reviews and suggestions regarding virtual sensing applications in the building sector. The existing virtual sensing classification affords limited insight into virtual sensor modeling, verification, and calibration in building operations. Therefore, this paper reviews existing virtual sensors and applications and characterizes up-to-date virtual sensing technologies, with a focus on virtual sensors and virtual sensor calibration. First, virtual sensors are classified into built-in and in-situ ones according to their modeling and verification environment. The review also examines how virtual sensors have been used for observation, fault detection and diagnosis, and control in buildings. Second, virtual sensor calibration methods are mainly classified into virtual built-in calibration and virtual in-situ calibration. Finally, key calibration strategies proposed in previous studies are summarized. Through this comprehensive review and a consideration of the field-centric building characteristics and building life-cycle, this review proposes virtual sensor categorizations and highlights research challenges and directions in virtual-sensing-driven intelligent building systems to provide greater insight into the fundamentals and methodologies of holistic virtual sensing. Thus, the results of this review are expected to contribute to enhancing the availability and reliability of virtual sensors in the long-term in order to harness them as a novel sensing system in the context of the building life-cycle and digitalization.}
}
@article{LIAO202213114,
title = {Innovations of carbon-neutral petroleum pipeline: A review},
journal = {Energy Reports},
volume = {8},
pages = {13114-13128},
year = {2022},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2022.09.187},
url = {https://www.sciencedirect.com/science/article/pii/S2352484722019138},
author = {Qi Liao and Yongtu Liang and Renfu Tu and Liqiao Huang and Jianqin Zheng and Guotao Wang and Haoran Zhang},
keywords = {Petroleum pipeline, Carbon-neutral, Intelligent operation, Emission reduction},
abstract = {As one of the major energy-intensive industries, petroleum pipelines are facing with huge pressure from carbon-neutral policies. Conforming to green development, the traditional pipeline industry should advance intelligent transition and take the reduction of carbon emissions as a strategic priority. Focusing on effective and low-carbon operation of petroleum pipelines, this review elaborates the challenges and solutions covering four aspects, including the system reform, intelligent monitoring and control, intelligent operation management and integrating with the clean energy transmission network. The related literature and industrial practices have been systematically reviewed to conclude with general guidelines and examples for competitiveness enhancement, energy saving and emission reduction. Future directions are also proposed on the basis of the research gaps.}
}
@article{LIAO2022104304,
title = {Knowledge synthesis of intelligent decision techniques applications in the AECO industry},
journal = {Automation in Construction},
volume = {140},
pages = {104304},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104304},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522001777},
author = {Longhui Liao and Lirong Quan and Chuan Yang and Linhui Li},
keywords = {Intelligent decision technique, Knowledge synthesis, Decision support, Neural network},
abstract = {Intelligent decision techniques (IDTs) have been increasingly applied to support (or even replace) decision-makers to make accurate decisions, such as supplier selection and energy retrofit, in the architecture, engineering, construction, and operations (AECO) industry. However, concerning substantial applications, fragmented knowledge of IDTs has prevented them from reaching their full potential. By evaluating 254 related articles, this study aims to investigate the status quo of IDTs applications in the AECO industry and synthesize knowledge in this domain. To this end, a mixed method, which integrates bibliometric analysis focusing on keywords co-occurrence analysis and citation burst detection, and systematic evaluation based on a 3D structure (knowledge, logic, and time), was conducted. A bottom-up knowledge structure was established, including knowledge basis, specific IDTs, five pillar topics, as well as current challenges and future directions. This study contributes to scholarship in the targeted domain and provides theoretical and practical references for both researchers and practitioners.}
}
@article{YOHANANDHAN2022107718,
title = {A holistic review on Cyber-Physical Power System (CPPS) testbeds for secure and sustainable electric power grid – Part – I: Background on CPPS and necessity of CPPS testbeds},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {136},
pages = {107718},
year = {2022},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.107718},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521009443},
author = {Rajaa Vikhram Yohanandhan and Rajvikram Madurai Elavarasan and Rishi Pugazhendhi and Manoharan Premkumar and Lucian Mihet-Popa and Vladimir Terzija},
keywords = {Critical infrastructure protection, Cyber attack, Cyber-physical power system testbed, Cyber security, Real-time testbed, Smart grid, Sustainability},
abstract = {The integration of advanced Information and Communication Technologies (ICTs) in the conventional electric power grid is evolving into a Cyber-Physical Power System (CPPS). The seamless integration of control, communication, and computing operations allow CPPS to be fully monitored and controlled. Threats, vulnerabilities, and catastrophic attacks will intrude as CPPS monitoring, protection, and control functions advance. For the CPPS to operate safely, securely, and efficiently, sustainable cybersecurity solutions must be developed, and the power grid's reliability and resilience must be maintained even when exposed to unfavorable network conditions. While more distributed and renewable energy sources are connected to the grid, cybersecurity helps to ensure the supply of electricity is sustainable and of high quality. The validation of such sustainable cybersecurity analysis goes beyond the traditional power grid network analysis, which means that the test should integrate the physical and cyber system behavior and respond to the network attacks. To analyze the cybersecurity and cyberattacks in the practical CPPS, comprehensive and realistic CPPS testbeds are needed. The heterogeneous nature of the CPPS concept urges multidisciplinary testbeds with various functions and capabilities to evaluate the new cyber-attacks, vulnerabilities, and threats in CPPS. Using this CPPS testbed framework, the different types of cyber-attack can be detected, and detection algorithm can be evaluated, and helps to enhance the development of sustainable cybersecurity defenses for realistic CPPS environment with the increasingly dense integration of distributed energy resources (DERs). This Part-I paper review the CPPS testbeds in the view of the physical power system layer, sensing layer, communication layer, control layer, application layer, test platforms, and research goals with the fusion of cyber and physical systems. In addition, this review presented an overview, structure, and application-based evaluation of existing testbeds from the industry and institutions. The various research areas in CPPS are reviewed first to show the research trends on different aspects of CPPS which have gained significant attention in the past decade. The necessity of testbeds for cyberattacks and sustainable cybersecurity analysis in CPPS are then described. Finally, the NIST framework for CPS, CPPS domains, and research areas are presented. Further the Part-II paper will review the classification, overview, and assessment of CPPS testbeds.}
}
@article{JIAO2022,
title = {Practice of big data and artificial intelligence in epidemic surveillance and containment},
journal = {Intelligent Medicine},
year = {2022},
issn = {2667-1026},
doi = {https://doi.org/10.1016/j.imed.2022.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S266710262200078X},
author = {Zengtao Jiao and Hanran Ji and Jun Yan and Xiaopeng Qi},
keywords = {Epidemic prevention and control, Epidemiological investigation, Artificial intelligence, Big data, Early warning},
abstract = {Faced with the current time-sensitive COVID-19 pandemic, the overburdened healthcare systems resulted in a strong demand to develop newer methods to control the spread of the pandemic. Big data and artificial intelligence (AI) have been leveraged amid the COVID-19 pandemic; however, little is known about its use for supporting public health efforts. In epidemic surveillance and containment, efforts are needed to treat critical patients, track and manage the health status of residents, isolate suspected cases, develop vaccines and antiviral drugs. The applications of emerging practices of artificial intelligence and big data have become powerful "weapons" to fight against the pandemic and provide strong support in pandemic prevention and control, such as early warning, analysis and judgment, interruption and intervention of epidemic, to achieve goals of early detection, early report, early diagnosis, early isolation and early treatment, and these are the decisive factors to control the spread of the epidemic and reduce the mortality. This paper systematically summarizes the application of big data and AI in epidemic, and describes practical cases and challenges with emphasis in epidemic prevention and control. The included studies showed that big data and AI have the potential strength to fight against COVID-19. However, many of the proposed methods are not yet widely accepted. Thus, the most rewarding research will be on methods promising value beyond COVID-19. More efforts are needed for developing standardized reporting protocols or guidelines for practice.}
}
@article{ALANNE2022103445,
title = {An overview of machine learning applications for smart buildings},
journal = {Sustainable Cities and Society},
volume = {76},
pages = {103445},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103445},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721007186},
author = {Kari Alanne and Seppo Sierla},
keywords = {Smart building, Intelligent building, Learning, HVAC, Reinforcement learning, Energy efficiency},
abstract = {The efficiency, flexibility, and resilience of building-integrated energy systems are challenged by unpredicted changes in operational environments due to climate change and its consequences. On the other hand, the rapid evolution of artificial intelligence (AI) and machine learning (ML) has equipped buildings with an ability to learn. A lot of research has been dedicated to specific machine learning applications for specific phases of a building's life-cycle. The reviews commonly take a specific, technological perspective without a vision for the integration of smart technologies at the level of the whole system. Especially, there is a lack of discussion on the roles of autonomous AI agents and training environments for boosting the learning process in complex and abruptly changing operational environments. This review article discusses the learning ability of buildings with a system-level perspective and presents an overview of autonomous machine learning applications that make independent decisions for building energy management. We conclude that the buildings’ adaptability to unpredicted changes can be enhanced at the system level through AI-initiated learning processes and by using digital twins as training environments. The greatest potential for energy efficiency improvement is achieved by integrating adaptability solutions at the timescales of HVAC control and electricity market participation.}
}
@article{YANG202223,
title = {Big data and reference intervals},
journal = {Clinica Chimica Acta},
volume = {527},
pages = {23-32},
year = {2022},
issn = {0009-8981},
doi = {https://doi.org/10.1016/j.cca.2022.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0009898122000018},
author = {Dan Yang and Zihan Su and Min Zhao},
keywords = {Indirect method, Reference interval, Data pre-processing, Verification, Big data},
abstract = {Although reference intervals (RIs) play an important role in clinical diagnosis, there remain significant differences with respect to race, gender, age and geographic location. Accordingly, the Clinical Laboratory Standards Institute (CLSI) EP28-A3c has recommended that clinical laboratories establish RIs appropriate to their subject population. Unfortunately, the traditional and direct approach to establish RIs relies on the recruitment of a sufficient number of healthy individuals of various age groups, collection and testing of large numbers of specimens and accurate data interpretation. The advent of the big data era has, however, created a unique opportunity to “mine” laboratory information. Unfortunately, this indirect method lacks standardization, consensus support and CLSI guidance. In this review we provide a historical perspective, comprehensively assess data processing and statistical methods, and post-verification analysis to validate this big data approach in establishing laboratory specific RIs.}
}
@article{YABE2022101777,
title = {Mobile phone location data for disasters: A review from natural hazards and epidemics},
journal = {Computers, Environment and Urban Systems},
volume = {94},
pages = {101777},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2022.101777},
url = {https://www.sciencedirect.com/science/article/pii/S0198971522000217},
author = {Takahiro Yabe and Nicholas K.W. Jones and P. Suresh C. Rao and Marta C. Gonzalez and Satish V. Ukkusuri},
keywords = {Mobile phone location data, Disaster risk management, Natural Hazards, Epidemics, Data for development},
abstract = {Rapid urbanization and climate change trends, intertwined with complex interactions of various social, economic, and political factors, have resulted in an increase in the frequency and intensity of disaster events. While regions around the world face urgent demands to prepare for, respond to, and to recover from such disasters, large-scale location data collected from mobile phone devices have opened up novel approaches to tackle these challenges. Mobile phone location data have enabled us to observe, estimate, and model human mobility dynamics at an unprecedented spatio-temporal granularity and scale. The COVID-19 pandemic, in particular, has spurred the use of mobile phone location data for pandemic and disaster management. However, there is a lack of a comprehensive review that synthesizes the last decade of work and case studies leveraging mobile phone location data for response to and recovery from natural hazards and epidemics. We address this gap by summarizing the existing work, and point to promising areas and future challenges for using mobile phone location data to support disaster response and recovery.}
}
@article{MA2022100002,
title = {Individual mobility prediction review: Data, problem, method and application},
journal = {Multimodal Transportation},
volume = {1},
number = {1},
pages = {100002},
year = {2022},
issn = {2772-5863},
doi = {https://doi.org/10.1016/j.multra.2022.100002},
url = {https://www.sciencedirect.com/science/article/pii/S2772586322000028},
author = {Zhenliang Ma and Pengfei Zhang},
keywords = {Individual mobility prediction, Personalized transportation, Deep learning, Data quality, Model interpretability},
abstract = {The ‘sharing’ business models and on-demand services have been altering city dwellers’ travel habits from buying the means of transport to buying mobility services based on needs. The capability to proactively provide personalized services (e.g., travel recommendations and dynamic pricing) is the future of smart multimodal mobility systems, in which the individual mobility prediction technique (predict where/when for a next trip) is a key enabler to achieve that. With the advancement of data collection and computing techniques, the individual mobility prediction problem has been gaining increasing interest, but yet receives little attention in applications and differs in problem definitions and methodologies developed given varied data sources and application contexts. In addition, there are many review studies on collective mobility predictions (e.g., travel demand/traffic flows), but no review study on the individual mobility prediction. To address these issues and fill the gap, the review synthesizes existing studies on individual mobility prediction in transport (data/problem/methodology/applications), identifies remaining research needs, as well as discusses methodological considerations and potential future transport applications. The review highlights the value of individual mobility prediction in driving proactive service provisions and mobility management in multimodal mobility systems. Methodologically, it is critical to pay more attention to data validation, data specification, and model interpretability in developing learning-based prediction models. Practically, it is of high value to study the individual mobility prediction with arbitrary prediction times (the time when the prediction is made) and prediction horizons (how far in the future).}
}
@article{SARIYER2022,
title = {Clustering of Firms Based on Environmental, Social, and Governance Ratings: Evidence from BIST Sustainability Index},
journal = {Borsa Istanbul Review},
year = {2022},
issn = {2214-8450},
doi = {https://doi.org/10.1016/j.bir.2022.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S221484502200093X},
author = {Görkem Sariyer and Dilvin Taşkın},
keywords = {BIST Sustainability Index, cluster analysis, environmental, social, and governance (ESG) ratings},
abstract = {In this paper, companies listed on the Borsa Istanbul (BIST) Sustainability Index are analyzed by performing a cluster analysis based on their environmental, social, and governance (ESG) scores. The results prove that firms with higher ESG ratings do not necessarily perform well in all ESG aspects. The outcomes of the cluster analysis reveal that firms with higher environmental and social scores are the cluster with the most prominent firms in terms of size but with low profitability. However, the group that scored poorly in environmental and social practices but the highest governance pillar was the highest performing in terms of the return on assets. This paper highlights the significance of forming clusters and linking sustainability practices with performance characteristics.}
}
@article{BENSLAMA2022101504,
title = {Prosumer in smart grids based on intelligent edge computing: A review on Artificial Intelligence Scheduling Techniques},
journal = {Ain Shams Engineering Journal},
volume = {13},
number = {1},
pages = {101504},
year = {2022},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2021.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S2090447921002409},
author = {Sami {Ben Slama}},
keywords = {Smart grid, Edge computing, Prosumer, Internet of things, Artificial Intelligence, Machine learning},
abstract = {Smart Grid technology has been considered an attractive research issue due to its efficiency in solving energy demand, storage, and power transmission. The integration of IoT technology in the Smart Grids is a critical way to accelerate the digitization of the power grid and is useful for the efficient performance of the energy grid infrastructure. For efficient real-time data analysis and decision-making, the Internet of Things will incorporate various communication systems seamlessly. To achieve efficient communication between all Internet of Things, devices are expected to use multiple means, including smart sensors, cable and wireless communication. Improved Internet of Things sensor technologies and connectivity could theoretically prevent or minimize the potential to natural disaster transmission lines, improve transmission power capacity and reduce economic losses. A smart grid is a variety of sensors, devices, and data sets that continuously capture high-resolution data equal to individual IoT conditions. A vast amount of data is one of the biggest challenges on the Internet of Things. Edge Computing is trying to process data close to linked sensors to address this problem, where the data is gathered and processed. This paper aims to investigate the edge computing solutions for the smart grid. A comprehensive review of both emerging issues and edge computing in the Smart Grid environment is discussed and explained. There are two primary components to the energy sharing process among Prosumers: information/digital technologies and Artificial Intelligence Scheduling Techniques. Each of them is mentioned in detail to discuss the Prosumer smart Grid. Furthermore, Edge Computing and classifications (cloudlet, Fog computing and Multi-Access) are among the suitable network methods mentioned in this paper. Some techniques and methodologies have been extensively covered to improve reader awareness of the Prosumer smart grid system.}
}
@article{CANAVERAHERRERA2022102970,
title = {On the relation between ‘resilience’ and ‘smartness’: A critical review},
journal = {International Journal of Disaster Risk Reduction},
volume = {75},
pages = {102970},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.102970},
url = {https://www.sciencedirect.com/science/article/pii/S2212420922001893},
author = {Juan Sebastián Cañavera-Herrera and Junqing Tang and Timea Nochta and Jennifer M. Schooling},
keywords = {Smart city, Resilience, Sustainability, Digital technology, Data security},
abstract = {Cities continue to face significant challenges that test their capacity for resilience. With the development of smart cities, there needs to be a better understanding of how the introduction of smart technologies will affect urban resilience. To address this issue, this article presents a critical review of the literature on smart cities and smart technologies focussing on representations of resilience. The findings reveal that discussing resilience in relation to smart city components of the data layer, digital technologies and the physical city can provide some degree of clarity despite the existence of a multiplicity of definitions and interpretations. Furthermore, the analysis indicates that the nature of relationships between ‘smartness’ and ‘resilience’ remains contested, and largely dependent on the perceived role of digital technologies in resilience-building processes. This in turn is influenced by how these technologies are used and what the intention and expectations are in relation to their use. In order to address these issues, we conclude that further interdisciplinary research, extending to the physical, social and environmental systems of cities, is needed to better understand the relations between smartness and resilience.}
}
@article{DEBAUCHE20227494,
title = {Cloud and distributed architectures for data management in agriculture 4.0 : Review and future trends},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {9},
pages = {7494-7514},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821002664},
author = {Olivier Debauche and Saïd Mahmoudi and Pierre Manneback and Frédéric Lebeau},
keywords = {Agriculture 4.0, Smart farming, Smart agriculture, Lambda architecture, Kappa architecture, Edge computing, Fog computing, Micro-service architecture, Data lake, Data house, Blockchain, Osmotic computing, Dew computing},
abstract = {The Agriculture 4.0, also called Smart Agriculture or Smart Farming, is at the origin of the production of a huge amount of data that must be collected, stored, and processed in a very short time. Processing this massive quantity of data needs to use specific infrastructure that use adapted IoT architectures. Our review offers a comparative panorama of Central Cloud, Distributed Cloud Architectures, Collaborative Computing Strategies, and new trends used in the context of Agriculture 4.0. In this review, we try to answer 4 research questions: (1) Which storage and processing architectures are best suited to Agriculture 4.0 applications and respond to its peculiarities? (2) Can generic architectures meet the needs of Agriculture 4.0 application cases? (3) What are the horizontal development possibilities that allow the transition from research to industrialization? (4) What are the vertical valuations possibilities to move from algorithms trained in the cloud to embedded or stand-alone products? For this, we compare architectures with 8 criteria (User Proximity, Latency & Jitter, Network stability, high throughput, Reliability, Scalability, Cost Effectiveness, Maintainability), and analyze the advantages and disadvantages of each of them.}
}
@article{K2022104724,
title = {A review of preserving privacy in data collected from buildings with differential privacy},
journal = {Journal of Building Engineering},
volume = {56},
pages = {104724},
year = {2022},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2022.104724},
url = {https://www.sciencedirect.com/science/article/pii/S2352710222007379},
author = {Janghyun K and Barry H and Tianzhen H and Marc A. P},
keywords = {Differential privacy, Building, Meter, Data},
abstract = {Significant amounts of data are collected in buildings. While these data have great potential for maximizing the energy efficiency of buildings in general, only a small portion of the data are accessible to researchers, government, and industry for analyses. Concerns about privacy are one of the major barriers prohibiting access to these data. Privacy preservation techniques are generally applied to this problem not only to preserve underlying privacy but also to improve the usefulness of data. Among various privacy preserving techniques, differential privacy has become one of the more popular solutions since its introduction in 2006. Differential privacy is a mathematical measure for protecting privacy so that one's privacy cannot be incurred by participating in a database. Although significant research improvements have been made for more than a decade, applying differential privacy to data collected in buildings is still an immature field of study. Because implementing differential privacy on a certain use case is not straightforward and can be achieved with various configurations, it is important to understand variation of configurations with different use cases around data collected from buildings. This literature review aims to introduce what has been done to implement differential privacy in data collected in buildings, and to discuss associated challenges and potential future research opportunities.}
}
@article{MELO2022107964,
title = {Open benchmarks for assessment of process monitoring and fault diagnosis techniques: A review and critical analysis},
journal = {Computers & Chemical Engineering},
volume = {165},
pages = {107964},
year = {2022},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2022.107964},
url = {https://www.sciencedirect.com/science/article/pii/S0098135422003003},
author = {Afrânio Melo and Maurício M. Câmara and Nayher Clavijo and José Carlos Pinto},
keywords = {Process monitoring, Fault detection, Fault diagnosis, Benchmarks, Datasets, Exploratory data analysis, Open source},
abstract = {The present paper brings together openly available datasets and simulators for testing of process monitoring and fault diagnosis techniques. Some general characteristics of these benchmark models and datasets are then assessed, including the richness of the information, availability of real data, ease of use, challenges that must be considered and potential for scientific advances. A critical comparison is made based on Exploratory Data Analysis (EDA) of readily available datasets. Previous works that used each benchmark are also reviewed and discussed. This reference can be used by researchers and practitioners who wish to choose a reference benchmark that best suits their particular interests and needs.}
}
@article{HENDRICKS2022461,
title = {Cavernous Malformations and Artificial Intelligence: Machine Learning Applications},
journal = {Neurosurgery Clinics of North America},
volume = {33},
number = {4},
pages = {461-467},
year = {2022},
note = {Update on Open Vascular Surgery},
issn = {1042-3680},
doi = {https://doi.org/10.1016/j.nec.2022.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1042368022000377},
author = {Benjamin K. Hendricks and Kavelin Rumalla and Dimitri Benner and Michael T. Lawton},
keywords = {Artificial intelligence, Cavernoma, Cavernous malformation, Deep learning, Machine learning, Model, Statistics, Vascular}
}
@article{TANG2022100289,
title = {Big Data in Forecasting Research: A Literature Review},
journal = {Big Data Research},
volume = {27},
pages = {100289},
year = {2022},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2021.100289},
url = {https://www.sciencedirect.com/science/article/pii/S2214579621001064},
author = {Ling Tang and Jieyi Li and Hongchuan Du and Ling Li and Jun Wu and Shouyang Wang},
keywords = {Big data, Forecasting, Literature review, Prediction models, Information},
abstract = {With the boom in Internet techniques and computer science, a variety of big data have been introduced into forecasting research, bringing new knowledge and improving prediction models. This paper is the first attempt to conduct a literature review on full-scale big data in forecasting research. By source, big data in forecasting research fell into user-generated content data (from the users on social media in texts, photos, etc.), device-monitored data (by meteorological monitors, smart meters, GPS, etc.) and activity log data (for web searching/visiting, online/offline marketing, clinical treatments, laboratory experiments, etc.). Different data types, bearing distinctive information and characteristics, dominated different forecasting tasks, required different analysis technologies and improved different forecasting models. This survey provides an overall review of big data-based forecasting research, details what (regarding data types and sources), where (forecasting hotspots) and how (analysis and forecasting methods used) big data improved prediction, and offers insights into future prospects.}
}
@article{NAYAK2022,
title = {A review on edge analytics: Issues, challenges, opportunities, promises, future directions, and applications},
journal = {Digital Communications and Networks},
year = {2022},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2022.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S2352864822002255},
author = {Sabuzima Nayak and Ripon Patgiri and Lilapati Waikhom and Arif Ahmed},
keywords = {Edge analytics, Edge computing, Edge devices, Big data, Sensor, Artificial intelligence, Machine learning, Smart technology, Healthcare},
abstract = {Edge technology aims to bring cloud resources (specifically, the computation, storage, and network) to the closed proximity of the edge devices, i.e., smart devices where the data are produced and consumed. Embedding computing and application in edge devices lead to emerging of two new concepts in edge technology: edge computing and edge analytics. Edge analytics uses some techniques or algorithms to analyse the data generated by the edge devices. With the emerging of edge analytics, the edge devices have become a complete set. Currently, edge analytics is unable to provide full support to the analytic techniques. The edge devices cannot execute advanced and sophisticated analytic algorithms following various constraints such as limited power supply, small memory size, limited resources, etc. This article aims to provide a detailed discussion on edge analytics. The key contributions of the paper are as follows-a clear explanation to distinguish between the three concepts of edge technology: edge devices, edge computing, and edge analytics, along with their issues. In addition, the article discusses the implementation of edge analytics to solve many problems and applications in various areas such as retail, agriculture, industry, and healthcare. Moreover, the research papers of the state-of-the-art edge analytics are rigorously reviewed in this article to explore the existing issues, emerging challenges, research opportunities and their directions, and applications.}
}
@article{ALAGADOR2022115172,
title = {Operations research applicability in spatial conservation planning},
journal = {Journal of Environmental Management},
volume = {315},
pages = {115172},
year = {2022},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2022.115172},
url = {https://www.sciencedirect.com/science/article/pii/S0301479722007459},
author = {Diogo Alagador and Jorge Orestes Cerdeira},
keywords = {Climate change, Computational sustainability, Conservation planning, Mathematical programming, Optimization, Spatial analysis},
abstract = {A large fraction of the current environmental crisis derives from the large rates of human-driven biodiversity loss. Biodiversity conservation questions human practices towards biodiversity and, therefore, largely conflicts with ordinary societal aspirations. Decisions on the location of protected areas, one of the most convincing conservation tools, reflect such a competitive endeavor. Operations Research (OR) brings a set of analytical models and tools capable of resolving the conflicting interests between ecology and economy. Recent technological advances have boosted the size and variety of data available to planners, thus challenging conventional approaches bounded on optimized solutions. New models and methods are needed to use such a massive amount of data in integrative schemes addressing a large variety of concerns. This study provides an overview on the past, present and future challenges that characterize spatial conservation models supported by OR. We discuss the progress of OR models and methods in spatial conservation planning and how those models may be optimized through sophisticated algorithms and computational tools. Moreover, we anticipate possible panoramas of modern spatial conservation studies supported by OR and we explore possible avenues for the design of optimized interdisciplinary collaborative platforms in the era of Big Data, through consortia where distinct players with different motivations and services meet. By enlarging the spatial, temporal, taxonomic and societal horizons of biodiversity conservation, planners navigate around multiple socioecological/environmental equilibria and are able to decide on cost-effective strategies to improve biodiversity persistence under complex environments.}
}
@article{PELLAT2022,
title = {Artificial intelligence: A review of current applications in hepatocellular carcinoma imaging},
journal = {Diagnostic and Interventional Imaging},
year = {2022},
issn = {2211-5684},
doi = {https://doi.org/10.1016/j.diii.2022.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2211568422001899},
author = {Anna Pellat and Maxime Barat and Romain Coriat and Philippe Soyer and Anthony Dohan},
keywords = {Hepatocellular carcinoma, Artificial intelligence, Machine learning, Deep learning, Diagnosis, Treatment},
abstract = {Hepatocellular carcinoma (HCC) is the most common type of primary liver cancer and currently the third-leading cause of cancer-related death worldwide. Recently, artificial intelligence (AI) has emerged as an important tool to improve clinical management of HCC, including for diagnosis, prognostication and evaluation of treatment response. Different AI approaches, such as machine learning and deep learning, are both based on the concept of developing prediction algorithms from large amounts of data, or big data. The era of digital medicine has led to a rapidly expanding amount of routinely collected health data which can be leveraged for the development of AI models. Various studies have constructed AI models by using features extracted from ultrasound imaging, computed tomography imaging and magnetic resonance imaging. Most of these models have used convolutional neural networks. These tools have shown promising results for HCC detection, characterization of liver lesions and liver/tumor segmentation. Regarding treatment, studies have outlined a role for AI in evaluation of treatment response and improvement of pre-treatment planning. Several challenges remain to fully integrate AI models in clinical practice. Future research is still needed to robustly evaluate AI algorithms in prospective trials, and improve interpretability, generalizability and transparency. If such challenges can be overcome, AI has the potential to profoundly change the management of patients with HCC. The purpose of this review was to sum up current evidence on AI approaches using imaging for the clinical management of HCC.}
}
@article{NG202223,
title = {National and international kidney failure registries: characteristics, commonalities, and contrasts},
journal = {Kidney International},
volume = {101},
number = {1},
pages = {23-35},
year = {2022},
issn = {0085-2538},
doi = {https://doi.org/10.1016/j.kint.2021.09.024},
url = {https://www.sciencedirect.com/science/article/pii/S0085253821010206},
author = {Monica S.Y. Ng and Vivek Charu and David W. Johnson and Michelle M. O’Shaughnessy and Andrew J. Mallett},
keywords = {data sharing, dialysis, inter-registry collaboration, kidney failure, registry, transplantation},
abstract = {Registries are essential for health infrastructure planning, benchmarking, continuous quality improvement, hypothesis generation, and real-world trials. To date, data from these registries have predominantly been analyzed in isolated “silos,” hampering efforts to analyze “big data” at the international level, an approach that provides wide-ranging benefits, including enhanced statistical power, an ability to conduct international comparisons, and greater capacity to study rare diseases. This review serves as a valuable resource to clinicians, researchers, and policymakers, by comprehensively describing kidney failure registries active in 2021, before proposing approaches for inter-registry research under current conditions, as well as solutions to enhance global capacity for data collaboration. We identified 79 kidney-failure registries spanning 77 countries worldwide. International Society of Nephrology exemplar initiatives, including the Global Kidney Health Atlas and Sharing Expertise to support the set-up of Renal Registries (SharE-RR), continue to raise awareness regarding international healthcare disparities and support the development of universal kidney-disease registries. Current barriers to inter-registry collaboration include underrepresentation of lower-income countries, poor syntactic and semantic interoperability, absence of clear consensus guidelines for healthcare data sharing, and limited researcher incentives. This review represents a call to action for international stakeholders to enact systemic change that will harmonize the current fragmented approaches to kidney-failure registry data collection and research.}
}
@article{MENG2022101,
title = {Applications of neural networks in liver transplantation},
journal = {iLIVER},
volume = {1},
number = {2},
pages = {101-110},
year = {2022},
issn = {2772-9478},
doi = {https://doi.org/10.1016/j.iliver.2022.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S277294782200038X},
author = {Jinwen Meng and Zhikun Liu and Xiao Xu},
keywords = {Artificial intelligence, Liver transplantation, Machine learning, Neural network, Deep learning},
abstract = {The use of neural networks (NNs) as a cutting-edge technique in the medical field has drawn considerable attention. NN models “learn” from a large amount of data and then find corresponding clinical patterns that are challenging for clinicians to recognize. In this study, we focus on liver transplantation (LT), which is an effective treatment for end-stage liver diseases. The management before and after LT produces a massive quantity of medical data, which can be fully processed by NNs. We describe recent progress in the clinical application of NNs to LT in five respects: pre-transplantation evaluation of the donor and recipient, recipient outcome prediction, allocation system development, operation monitoring, and post-transplantation complication prediction. This review provides clinicians and researchers with a description of forefront applications of NNs in the field of LT and discusses prospects and pitfalls.}
}
@article{TRIVEDI20221286,
title = {A Practical Guide to Use of Publicly Available Data Sets for Observational Research in Interventional Radiology},
journal = {Journal of Vascular and Interventional Radiology},
volume = {33},
number = {11},
pages = {1286-1294},
year = {2022},
issn = {1051-0443},
doi = {https://doi.org/10.1016/j.jvir.2022.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S1051044322011241},
author = {Premal S. Trivedi and Vincent M. Timpone and Rustain L. Morgan and Alexandria M. Jensen and Margaret Reid and P. Michael Ho and Osman Ahmed},
abstract = {Observational data research studying access, utilization, cost, and outcomes of image-guided interventions using publicly available “big data” sets is growing in the interventional radiology (IR) literature. Publicly available data sets offer insight into real-world care and represent an important pillar of IR research moving forward. They offer insights into how IR procedures are being used nationally and whether they are working as intended. On the other hand, large data sources are aggregated using complex sampling frames, and their strengths and weaknesses only become apparent after extensive use. Unintentional misuse of large data sets can result in misleading or sometimes erroneous conclusions. This review introduces the most commonly used databases relevant to IR research, highlights their strengths and limitations, and provides recommendations for use. In addition, it summarizes methodologic best practices pertinent to all data sets for planning and executing scientifically rigorous and clinically relevant observational research.}
}
@article{REJEB2022131439,
title = {The Internet of Things and the circular economy: A systematic literature review and research agenda},
journal = {Journal of Cleaner Production},
volume = {350},
pages = {131439},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.131439},
url = {https://www.sciencedirect.com/science/article/pii/S0959652622010617},
author = {Abderahman Rejeb and Zailani Suhaiza and Karim Rejeb and Stefan Seuring and Horst Treiblmaier},
keywords = {Internet of things, Circular economy, Industry 4.0, Enablers, Barriers, Systematic literature review, Framework},
abstract = {In recent years, the concept of a circular economy (CE) has gained importance and attracted significant attention among scholars and practitioners. Research that examines the role of modern technologies in supporting the transition from a linear economy to the CE is therefore highly needed. This article analyzes and classifies existing research at the intersection of the CE and the Internet of Things (IoT), as an enabling technology. While studies on both concepts have proliferated, there is a lack of research that systematizes the literature and clarifies the relationship between the IoT and the CE. In order to achieve this, we reviewed a total of 170 academic articles published between 2007 and 2021 from the Scopus and Web of Science databases. Based on the coding of keywords, four categories can be identified: (1) IoT-related technologies in the CE context, (2) enablers of IoT in the CE, (3) barriers to IoT adoption in the CE, and (4) the impacts of the IoT on the sustainability of (circular) economies. The current study is the first attempt to use a keyword coding approach to better understand IoT research in the CE domain. The review findings identify important drivers and enablers and provide a structured framework for research in this field. Finally, this study highlights several research directions that may provide valuable insights for researchers and practitioners.}
}
@article{LI2022301,
title = {Artificial Intelligence and Mechanical Circulatory Support},
journal = {Heart Failure Clinics},
volume = {18},
number = {2},
pages = {301-309},
year = {2022},
note = {Digital Health},
issn = {1551-7136},
doi = {https://doi.org/10.1016/j.hfc.2021.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S1551713621001148},
author = {Song Li and Gavin W. Hickey and Matthew M. Lander and Manreet K. Kanwar},
keywords = {Artificial intelligence, Machine learning, Mechanical circulatory support, Heart failure}
}
@article{WANG2022112826,
title = {A comprehensive review on the prediction of ship energy consumption and pollution gas emissions},
journal = {Ocean Engineering},
volume = {266},
pages = {112826},
year = {2022},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2022.112826},
url = {https://www.sciencedirect.com/science/article/pii/S0029801822021096},
author = {Kai Wang and Jianhang Wang and Lianzhong Huang and Yupeng Yuan and Guitao Wu and Hui Xing and Zhongyi Wang and Zhuang Wang and Xiaoli Jiang},
keywords = {Energy consumption model, Ship emission prediction, Energy efficiency optimization, Big data analysis, Artificial intelligence, Low-carbon shipping},
abstract = {Ship energy consumption and emission prediction are critical for ship energy efficiency management and pollution gas emission control, both of which are major concerns for the shipping industry and hence continue to attract global attention and research interest. This article examined the energy efficiency data sources, big data analysis for energy efficiency, and analyzed the ship energy consumption and emission prediction models. The ship energy consumption and pollution gas emission prediction models are comprehensively summarized based on the modeling method and principles. The theoretical analysis and artificial intelligence-based ship energy consumption model, as well as the top-down and bottom-up ship emission prediction models, are thoroughly examined in terms of influencing factors, model accuracy, data sources, and practical applications. On this basis, the challenges of ship energy consumption and emission prediction are discussed, and future research suggestions are proposed, providing a foundation for the development of ship energy consumption and emission prediction technologies. The analysis results show that the principles, parameters of concern, and data quality all have a significant impact on the performance of the prediction models. Consequently, the prediction model's accuracy can be improved by combining intelligent algorithms and machine learning. In the future, high precision, self-adapting, ship fuel consumption and emission prediction models based on artificial intelligence technology should be further studied, in order to improve their prediction performance, and thus providing solid foundations for the optimization management and control of the ship energy consumption and emissions.}
}
@article{ALWIS2022103624,
title = {A survey on smart farming data, applications and techniques},
journal = {Computers in Industry},
volume = {138},
pages = {103624},
year = {2022},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2022.103624},
url = {https://www.sciencedirect.com/science/article/pii/S0166361522000197},
author = {Sandya De Alwis and Ziwei Hou and Yishuo Zhang and Myung Hwan Na and Bahadorreza Ofoghi and Atul Sajjanhar},
keywords = {Smart farming, Data analysis, Big data, Machine learning, Digital farming, Predictive farming, Farming industry},
abstract = {The Internet of Things (IoT) and the relevant technologies have had a significant impact on smart farming as a major sub-domain within the field of agriculture. Modern technology supports data collection from IoT devices through several farming processes. The extensive amount of collected smart farming data can be utilized for daily decision making and analysis such as yield prediction, growth analysis, quality maintenance, animal and aquaculture, as well as farm management. This survey focuses on three major aspects of contemporary smart farming. First, it highlights various types of big data generated through smart farming and makes a broad categorization of such data. Second, this paper discusses a comprehensive set of typical applications of big data in smart farming. Third, it identifies and introduces the principal big data and machine learning techniques that are utilized in smart farming data analysis. In doing so, this survey also identifies some of the major, current challenges in smart farming big data analysis.This paper provides a discussion on potential pathways toward more effective smart farming through relevant analytics-guided decision making.}
}
@article{LIU2022101687,
title = {Review on automated condition assessment of pipelines with machine learning},
journal = {Advanced Engineering Informatics},
volume = {53},
pages = {101687},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101687},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622001471},
author = {Yiming Liu and Yi Bao},
keywords = {Big data, Condition assessment, Machine learning, Nondestructive testing, Pipeline, SWOT},
abstract = {Pipelines carrying energy products play vital roles in economic wealth and public safety, but incidents continue occurring. Condition assessment of pipelines is essential to identify anomalies timely. Advanced sensing technologies obtain informative data for condition assessment, while data analysis by human has limited efficiency, accuracy, and reliability. Advances in machine learning offer exciting opportunities for automated condition assessment with minimum human intervention. This paper reviews machine learning approaches to detect, classify, locate, and quantify pipeline anomalies based on intelligent interpretation of routine operation data, nondestructive testing data, and computer vision data. Statistics and uncertainties of performance metrics of machine learning approaches are discussed. An analysis on strengths, weaknesses, opportunities, and threats (SWOT) is performed. Guides for practitioners to perform automated pipeline condition assessment are recommended. This review provide insights into the machine learning approaches for automated pipeline condition assessment. The SWOT analysis will support decision making in the pipeline industry.}
}
@article{NYOMANKUTHAKRISNAWIJAYA2022106813,
title = {Data analytics platforms for agricultural systems: A systematic literature review},
journal = {Computers and Electronics in Agriculture},
volume = {195},
pages = {106813},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2022.106813},
url = {https://www.sciencedirect.com/science/article/pii/S0168169922001302},
author = {Ngakan {Nyoman Kutha Krisnawijaya} and Bedir Tekinerdogan and Cagatay Catal and Rik van der Tol},
keywords = {Data analytics platforms, Agriculture, Systematic literature review, Big Data},
abstract = {With the rapid developments in ICT, the current agriculture businesses have become increasingly data-driven and are supported by advanced data analytics techniques. In this context, several studies have investigated the adopted data analytics platforms in the agricultural sector. However, the main characteristics and overall findings on these platforms are scattered over the various studies, and to the best of our knowledge, there has been no attempt yet to systematically synthesize the features and obstacles of the adopted data analytics platforms. This article presents the results of an in-depth systematic literature review (SLR) that has explicitly focused on the domains of the platforms, the stakeholders, the objectives, the adopted technologies, the data properties and the obstacles. According to the year-wise analysis, it is found that no relevant primary study between 2010 and 2013 was found. This implies that the research of data analytics in agricultural sectors is a popular topic from recent years, so the results from before 2010 are likely less relevant. In total, 535 papers published from 2010 to 2020 were retrieved using both automatic and manual search strategies, among which 45 journal articles were selected for further analysis. From these primary studies, 33 features and 34 different obstacles were identified. The identified features and obstacles help characterize the different data analytics platforms and pave the way for further research.}
}
@article{BOOBALAN2022109048,
title = {Fusion of Federated Learning and Industrial Internet of Things: A survey},
journal = {Computer Networks},
volume = {212},
pages = {109048},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2022.109048},
url = {https://www.sciencedirect.com/science/article/pii/S1389128622001955},
author = {Parimala Boobalan and Swarna Priya Ramu and Quoc-Viet Pham and Kapal Dev and Sharnil Pandya and Praveen Kumar Reddy Maddikunta and Thippa Reddy Gadekallu and Thien Huynh-The},
keywords = {Data storage, IIoT, Federated Learning, Data privacy, Data sharing, Resource management},
abstract = {Industrial Internet of Things (IIoT) lays a new paradigm for the concept of Industry 4.0 and paves an insight for new industrial era. Nowadays smart machines and smart factories use machine learning/deep learning based models for incurring intelligence. However, storing and communicating the data to the cloud and end device leads to issues in preserving privacy. In order to address this issue, Federated Learning (FL) technology is implemented in IIoT by the researchers nowadays to provide safe, accurate, robust and unbiased models. Integrating FL in IIoT ensures that no local sensitive data is exchanged, as the distribution of learning models over the edge devices has become more common with FL. Therefore, only the encrypted notifications and parameters are communicated to the central server. In this paper, we provide a thorough overview on integrating FL with IIoT in terms of privacy, resource and data management. The survey starts by articulating IIoT characteristics and fundamentals of distributed machine learning and FL. The motivation behind integrating IIoT and FL for achieving data privacy preservation and on-device learning are summarized. Then we discuss the potential of using machine learning (ML), deep learning (DL) and blockchain techniques for FL in secure IIoT. Further we analyze and summarize several ways to handle the heterogeneous and huge data. Comprehensive background on data and resource management are then presented, followed by applications of IIoT with FL in automotive, robotics, agriculture, energy, and healthcare industries. Finally, we shed light on challenges, some possible solutions and potential directions for future research.}
}
@article{SHARIF2022103542,
title = {Smart City Dimensions and Associated Risks: Review of literature},
journal = {Sustainable Cities and Society},
volume = {77},
pages = {103542},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103542},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721008088},
author = {Reem Al Sharif and Shaligram Pokharel},
keywords = {Smart cities, Smart city dimensions, Technical risks, Non-technical risks, Risk parameters, Risk assessment tools},
abstract = {Countries have been working on implementing smart city concepts in different regions. The need for the use of information and communication technology in various forms is needed in such cities. There are different dimensions that are to be considered for smart city planning and implementation. This complexity of the dimension, the use of technology, and their integration bring the risk perspectives into the implementation of the smart city concept. If such risks are not adequately understood and addressed, they can create issues in terms of privacy and security and, therefore, the functioning of smart cities. In this review, the identification of dimensions, smart city assessment tools, the available technologies, and the technical and non-technical risk parameters related to smart cities implementation are discussed. The current methods of risk assessment and the possible enhancements are highlighted. The findings of the literature review illustrate that not all smart cities adapt all of the smart city dimensions. The dominant technology used in smart cities’ applications is found to be the Internet of Things, Artificial Intelligence, and blockchain. The paper also provides some research directions for the design, implementation, and operation of smart cities.}
}
@article{WANG2022109056,
title = {Data acquisition for urban building energy modeling: A review},
journal = {Building and Environment},
volume = {217},
pages = {109056},
year = {2022},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2022.109056},
url = {https://www.sciencedirect.com/science/article/pii/S0360132322002955},
author = {Chao Wang and Martina Ferrando and Francesco Causone and Xing Jin and Xin Zhou and Xing Shi},
keywords = {Urban building energy modeling, UBEM, Urban energy simulation, Data acquisition, Data science},
abstract = {Urban Building Energy Modeling (UBEM) is essential for urban energy-related applications. Its generation mainly requires four data inputs, including geometric data, non-geometric data, weather data, and validation and calibration data. A reliable UBEM depends on the quantity and accuracy of the data inputs. However, the lack of available data and the difficulty in determining stochastic data are two of the main barriers in the development of UBEM. To bridge the research gaps, this paper reviews appropriate acquisition approaches for four data inputs, learning from both building science and other disciplines such as geography, transportation and computer science. In addition, detailed evaluations are also conducted in each part of the study, and the performance of the approaches are discussed, as well as the availability and cost of the implemented data. Systematic discussion, multidisciplinary analysis and comprehensive evaluation are the highlights of this review.}
}
@article{JASEENA20223393,
title = {Deterministic weather forecasting models based on intelligent predictors: A survey},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {6, Part B},
pages = {3393-3412},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2020.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S1319157820304729},
author = {K.U. Jaseena and Binsu C. Kovoor},
keywords = {Weather forecasting, Artificial neural networks, Deep learning, Autoencoders, Recurrent neural networks},
abstract = {Weather forecasting is the practice of predicting the state of the atmosphere for a given location based on different weather parameters. Weather forecasts are made by gathering data about the current state of the atmosphere. Accurate weather forecasting has proven to be a challenging task for meteorologists and researchers. Weather information is essential in every facet of life like agriculture, tourism, airport system, mining industry, and power generation. Weather forecasting has now entered the era of Big Data due to the advancement of climate observing systems like satellite meteorological observation and also because of the fast boom in the volume of weather data. So, the traditional computational intelligence models are not adequate to predict the weather accurately. Hence, deep learning-based techniques are employed to process massive datasets that can learn and make predictions more effectively based on past data. The effective implementation of deep learning in various domains has motivated its use in weather forecasting and is a significant development for the weather industry. This paper provides a thorough review of different weather forecasting approaches, along with some publicly available datasets. This paper delivers a precise classification of weather forecasting models and discusses potential future research directions in this area.}
}
@article{ZHA2022,
title = {Microbial dark matter: from discovery to applications},
journal = {Genomics, Proteomics & Bioinformatics},
year = {2022},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2022.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1672022922000377},
author = {Yuguo Zha and Hui Chong and Pengshuo Yang and Kang Ning},
keywords = {Microbiome, Dark matter, Artificial intelligence, Knowledge discovery, Applications},
abstract = {With the rapid increase of the microbiome samples and sequencing data, more and more knowledge about microbial communities has been gained. However, there is still much more to learn about microbial communities, including billions of novel species and genes, as well as countless spatiotemporal dynamic patterns within the microbial communities, which together form the microbial dark matter. In this work, we summarized the dark matter in microbiome research and reviewed current data mining methods, especially artificial intelligence (AI) methods, for different types of knowledge discovery from microbial dark matter. We also provided case studies on using AI methods for microbiome data mining and knowledge discovery. In summary, we view microbial dark matter not as a problem to be solved but as an opportunity for AI methods to explore, with the goal of advancing our understanding of microbial communities, as well as developing better solutions to global concerns about human health and the environment.}
}
@article{OJO2022107266,
title = {Internet of Things and Machine Learning techniques in poultry health and welfare management: A systematic literature review},
journal = {Computers and Electronics in Agriculture},
volume = {200},
pages = {107266},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2022.107266},
url = {https://www.sciencedirect.com/science/article/pii/S0168169922005798},
author = {Rasheed O. Ojo and Anuoluwapo O. Ajayi and Hakeem A. Owolabi and Lukumon O. Oyedele and Lukman A. Akanbi},
keywords = {Behavioral parameters, Environmental parameters, Deep learning, Computer vision, Vocalization},
abstract = {The advent of digital technologies has brought substantial improvements in various domains. This article provides a comprehensive review of research emphasizing AI-enabled IoT applications in poultry health and welfare management. This study focused on poultry welfare since modern poultry management is confronted with issues relating to standardized parameters for welfare assessment and robust monitoring systems, particularly for broilers' health and disease outbreak prevention. Evidence has shown that modern digital technologies have high possibilities for intelligent automation of current and future poultry management operations to facilitate high-quality and low-cost poultry production. Therefore, this study presents a systematic review of the current state-of-the-art AI-enabled IoT systems and their recent advances in developing intelligent systems in this domain. Also, the study provides an overview of the critical applications of identified digital technologies in poultry welfare management. Lastly, the study discusses the challenges and opportunities of AI and IoT in poultry farming.}
}
@article{KEITH2022100824,
title = {Deeper learning in electrocatalysis: realizing opportunities and addressing challenges},
journal = {Current Opinion in Chemical Engineering},
volume = {36},
pages = {100824},
year = {2022},
issn = {2211-3398},
doi = {https://doi.org/10.1016/j.coche.2022.100824},
url = {https://www.sciencedirect.com/science/article/pii/S221133982200034X},
author = {John A Keith and James R McKone and Joshua D Snyder and Maureen H Tang},
abstract = {Emerging techniques in deep learning have created exciting opportunities for next-generation electrochemical technologies. While deep learning has been revolutionizing many research fields, strategies for its implementation for electrocatalysis remain nascent. This Opinion calls on the electrocatalysis community to join together and introduce a paradigm shift by establishing standards for reporting and sharing data from electrocatalysis investigations. We speculate on a possible future where crowd-sourced and standardized data from experimental and computational researchers can be analyzed collectively to better understand fundamental electrochemistry, yielding unprecedented insights for the development of new electrocatalysts. We identify key barriers to realizing this opportunity and how they might be overcome.}
}
@article{ZENG2022100794,
title = {Deep generative molecular design reshapes drug discovery},
journal = {Cell Reports Medicine},
pages = {100794},
year = {2022},
issn = {2666-3791},
doi = {https://doi.org/10.1016/j.xcrm.2022.100794},
url = {https://www.sciencedirect.com/science/article/pii/S2666379122003494},
author = {Xiangxiang Zeng and Fei Wang and Yuan Luo and Seung-gu Kang and Jian Tang and Felice C. Lightstone and Evandro F. Fang and Wendy Cornell and Ruth Nussinov and Feixiong Cheng},
abstract = {Summary
Recent advances and accomplishments of artificial intelligence (AI) and deep generative models have established their usefulness in medicinal applications, especially in drug discovery and development. To correctly apply AI, the developer and user face questions such as which protocols to consider, which factors to scrutinize, and how the deep generative models can integrate the relevant disciplines. This review summarizes classical and newly developed AI approaches, providing an updated and accessible guide to the broad computational drug discovery and development community. We introduce deep generative models from different standpoints and describe the theoretical frameworks for representing chemical and biological structures and their applications. We discuss the data and technical challenges and highlight future directions of multimodal deep generative models for accelerating drug discovery.}
}
@article{IBRAHIM2022112446,
title = {A review on the deployment of demand response programs with multiple aspects coexistence over smart grid platform},
journal = {Renewable and Sustainable Energy Reviews},
volume = {162},
pages = {112446},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2022.112446},
url = {https://www.sciencedirect.com/science/article/pii/S1364032122003525},
author = {Charles Ibrahim and Imad Mougharbel and Hadi Y. Kanaan and Nivine Abou Daher and Semaan Georges and Maarouf Saad},
keywords = {Demand response programs, Approach, Marketing, Technical, Economic objectives, Architecture, Business intelligence},
abstract = {A modern strategy for improving the control of generation, distribution and consumption of electrical energy consists of launching programs affecting the demand on the consumer side. Objectives related to the so-called Demand Response Programs (DRP) are of technical, economic and marketing order. Multiple DRPs are actually proposed and researchers keep on suggesting others. Although DRPs suggestions are still under tests for validation and implementation, an extensive literature exists in this domain. Multiple interdependent objectives are targeted and individual treatment might lead to undesired outcome. It is paramount to perform a holistic review showing the implications of the objectives on each other. The aim is to include them in a consolidated model with assigned weights where intensive what if scenarios will be applied to reach the optimal model settings. Existing reviews and literature in this domain focused on individual or partially correlated aspects. This paper presents a review providing a wide coverage on existing approaches and objectives for implementing DRPs and their relation. Therefore, authors decided to focus on the technical, economic and marketing aspects with the consideration of architectures and business intelligence. Model structures with their variability and dynamicity enable a financially viable model with various market options correlated with the economic and technical aspects. Hence, this mechanism assists in planning adequately and supporting the decision-making process.}
}
@article{KHAN2022100074,
title = {Information sharing in supply chains – Interoperability in an era of circular economy},
journal = {Cleaner Logistics and Supply Chain},
volume = {5},
pages = {100074},
year = {2022},
issn = {2772-3909},
doi = {https://doi.org/10.1016/j.clscn.2022.100074},
url = {https://www.sciencedirect.com/science/article/pii/S2772390922000476},
author = {Athar Ajaz Khan and János Abonyi},
keywords = {Supply chains informatics, Data Integration, Interoperability, Supply chain data standards, Circular economy, SSCM, Optimization, Industry 5.0},
abstract = {In order to realize the goals of Industry 5.0 (I5.0), which has data interoperability as one of its core principles, the future research in the Supply Chain (SC) visibility has to be aligned with socially, economically and environmentally sustainable objectives. Within the purview of circular economy, this paper indicates various aspects and implications of data sharing in the SCs in light of the published research. Taking into consideration the heterogeneity of data sources and standards, this article also catalogs all the major data-sharing technologies being employed in sharing data digitally across the SCs. Drawing on the published research from 2015 to 2021, following the PRISMA framework, this paper presents the state of research in the field of data sharing in SCs in terms of their standardization, optimization, simulation, automation, security and more notably sustainability. Using the co-occurrence metric, bibliometric analysis has been conducted such that the collected research is categorized under various keyword clusters and regional themes. This article brings together two major themes in reviewing the research in the field. Firstly, the bibliometric analysis of the published articles demonstrates the contours of the current state of research and the future possibilities in the field. Secondly, in synthesizing the research on the foundations of sustainability within the CRoss Industry Standard Process for Data Mining (CRISP-DM) framework, this article deals with various aspects and implications of information sharing in the SCs. By bringing these two themes together, this paper affords a prospective researcher with the research vis-à-vis the information sharing in SC, starting from the actual data standards in use to the modality and consequence of their application within the perspective of the circular economy. This article, in essence, indicates how all the aspects of data sharing in SCs may be brought together in service of the paradigm of I5.0.}
}
@article{HAMWI2022101004,
title = {Development and integration of VGG and dense transfer-learning systems supported with diverse lung images for discovery of the Coronavirus identity},
journal = {Informatics in Medicine Unlocked},
volume = {32},
pages = {101004},
year = {2022},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2022.101004},
url = {https://www.sciencedirect.com/science/article/pii/S2352914822001472},
author = {Wael Abdulsalam Hamwi and Muhammad Mazen Almustafa},
keywords = {CXR&CT chest COVID-19 images integration of three pre-trained CNN models Fine-tuning, Image processing, Performance evaluation, Artificial intelligence},
abstract = {The contagious SARS-CoV-2 has had a tremendous impact on the life and health of many communities. It was first rampant in early 2019 and so far, 539 million cases of COVID-19 have been reported worldwide. This is reminiscent of the 1918 influenza pandemic. However, we can detect the infected cases of COVID-19 by analysing either X-rays or CT, which are presumably considered the least expensive methods. In the existence of state-of-the-art convolutional neural networks (CNNs), which integrate image pre-processing techniques with fully connected layers, we can develop a sophisticated AI system contingent on various pre-trained models. Each pre-trained model we involved in our study assumed its role in extracting some specific features from different chest image datasets in many verified sources, such as (Mendeley, Kaggle, and GitHub). First, for CXR datasets associated with the CNN trained model from the beginning, whereby is comprised of four layers beginning with the Conv2D layer, which comprises 32 filters, followed by the MaxPooling and afterwards, we reiterated similarly. We used two techniques to avoid overgeneralization, the early stopping and the Dropout techniques. After all, the output was one neuron to classify both cases of 0 or 1, followed by a sigmoid function; in addition, we used the Adam optimizer owing to the more improved outcomes than what other optimizers conducted; ultimately, we referred to our findings by using a confusion matrix, classification report (Recall & Precision), sensitivity and specificity; in this approach, we achieved a classification accuracy of 96%. Our three integrated pre-trained models (VGG16, DenseNet201, and DenseNet121) yielded a remarkable test accuracy of 98.81%. Besides, our merged models (VGG16, DenseNet201) trained on CT images with the utmost effort; this model held an accurate test of 99.73% for binary classification with the (Normal/Covid-19) scenario. Comparing our results with related studies shows that our proposed models were superior to the previous CNN machine learning models in terms of various performance metrics. Our pre-trained model associated with the CT dataset achieved 100% of the F1score and the loss value was approximately 0.00268.}
}
@article{XU20221664,
title = {Smart breeding driven by big data, artificial intelligence, and integrated genomic-enviromic prediction},
journal = {Molecular Plant},
volume = {15},
number = {11},
pages = {1664-1695},
year = {2022},
issn = {1674-2052},
doi = {https://doi.org/10.1016/j.molp.2022.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1674205222002957},
author = {Yunbi Xu and Xingping Zhang and Huihui Li and Hongjian Zheng and Jianan Zhang and Michael S. Olsen and Rajeev K. Varshney and Boddupalli M. Prasanna and Qian Qian},
keywords = {smart breeding, genomic selection, integrated genomic-enviromic selection, spatiotemporal omics, crop design, machine and deep learning, big data, artificial intelligence},
abstract = {The first paradigm of plant breeding involves direct selection-based phenotypic observation, followed by predictive breeding using statistical models for quantitative traits constructed based on genetic experimental design and, more recently, by incorporation of molecular marker genotypes. However, plant performance or phenotype (P) is determined by the combined effects of genotype (G), envirotype (E), and genotype by environment interaction (GEI). Phenotypes can be predicted more precisely by training a model using data collected from multiple sources, including spatiotemporal omics (genomics, phenomics, and enviromics across time and space). Integration of 3D information profiles (G-P-E), each with multidimensionality, provides predictive breeding with both tremendous opportunities and great challenges. Here, we first review innovative technologies for predictive breeding. We then evaluate multidimensional information profiles that can be integrated with a predictive breeding strategy, particularly envirotypic data, which have largely been neglected in data collection and are nearly untouched in model construction. We propose a smart breeding scheme, integrated genomic-enviromic prediction (iGEP), as an extension of genomic prediction, using integrated multiomics information, big data technology, and artificial intelligence (mainly focused on machine and deep learning). We discuss how to implement iGEP, including spatiotemporal models, environmental indices, factorial and spatiotemporal structure of plant breeding data, and cross-species prediction. A strategy is then proposed for prediction-based crop redesign at both the macro (individual, population, and species) and micro (gene, metabolism, and network) scales. Finally, we provide perspectives on translating smart breeding into genetic gain through integrative breeding platforms and open-source breeding initiatives. We call for coordinated efforts in smart breeding through iGEP, institutional partnerships, and innovative technological support.}
}
@article{ITO2022468,
title = {Improved root cause analysis supporting resilient production systems},
journal = {Journal of Manufacturing Systems},
volume = {64},
pages = {468-478},
year = {2022},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2022.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S0278612522001273},
author = {Adriana Ito and Malin Hagström and Jon Bokrantz and Anders Skoogh and Mario Nawcki and Kanika Gandhi and Dag Bergsjö and Maja Bärring},
keywords = {Root cause analysis, Production disturbances, Production systems, Resilience},
abstract = {Manufacturing companies struggle to be efficient and effective when conducting root cause analyses of production disturbances; a fact which hinders them from creating and developing resilient production systems. This article aims to describe the challenges and enablers identified in current research relating to the different phases of root cause analysis. A systematic literature review was conducted, in which a total of 14 challenges and 17 enablers are identified and described. These correlate to the different phases of root cause analysis. Examples of challenges are “need for expertise”, “employee bias”, “poor data quality” and “lack of data integration”, among others. Examples of enablers are “visualisation tools”, “collaborative platforms”, “thesaurus” and “machine learning techniques”. Based on these findings, the authors also propose potential areas for further research and then design inputs for new solutions to improve root cause analysis. This article provides a theoretical contribution in that it describes the challenges and enablers of root cause analysis and their correlation to the creation of resilient production systems. The article also provides practical contributions, with an overview of current research to support practitioners in gaining insights into potential solutions to be implemented and further developed, with the aim of improving root cause analysis in production systems.}
}
@article{SICARI2022102822,
title = {Insights into security and privacy towards fog computing evolution},
journal = {Computers & Security},
volume = {120},
pages = {102822},
year = {2022},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2022.102822},
url = {https://www.sciencedirect.com/science/article/pii/S0167404822002164},
author = {Sabrina Sicari and Alessandra Rizzardi and Alberto Coen-Porisini},
keywords = {Fog computing, Internet of things, Security, Privacy, Cloud computing, Fog networking},
abstract = {The incremental diffusion of the Internet of Things (IoT) technologies and applications represents the outcome of a world ever more connected by means of heterogeneous and mobile devices. IoT scenarios imply the presence of multiple data producers (e.g., sensors, actuators, RFID, NFC) and consumers (e.g., end-user devices, such as smartphones, tablets, and PCs). A variety of standards and protocols must cooperate to efficiently gather, process, and share the information. The fog computing paradigm, due to its distributed nature, represents a viable solution to cope with interoperability, scalability, security, and privacy issues, which naturally emerge, since it operates as an intermediate layer between data consumers/producers and traditional cloud systems. This paper analyzes the evolution in the modeling of new methodologies, related to fog computing and IoT, showing how moving security and privacy tasks toward the edge of the network provide both advantages and new challenges to be faced in this research field. The proposed discussion provides an overview of requirements for the realization of secure and privacy-aware IoT-based fog computing infrastructures.}
}
@article{TANG2022103679,
title = {A literature review of Artificial Intelligence applications in railway systems},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {140},
pages = {103679},
year = {2022},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2022.103679},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X22001206},
author = {Ruifan Tang and Lorenzo {De Donato} and Nikola Bes̆inović and Francesco Flammini and Rob M.P. Goverde and Zhiyuan Lin and Ronghui Liu and Tianli Tang and Valeria Vittorini and Ziyulong Wang},
keywords = {Artificial Intelligence, Railways, Transportation, Machine Learning, Autonomous driving, Maintenance, Smart mobility, Train control, Traffic management},
abstract = {Nowadays it is widely accepted that Artificial Intelligence (AI) is significantly influencing a large number of domains, including railways. In this paper, we present a systematic literature review of the current state-of-the-art of AI in railway transport. In particular, we analysed and discussed papers from a holistic railway perspective, covering sub-domains such as maintenance and inspection, planning and management, safety and security, autonomous driving and control, revenue management, transport policy, and passenger mobility. This review makes an initial step towards shaping the role of AI in future railways and provides a summary of the current focuses of AI research connected to rail transport. We reviewed about 139 scientific papers covering the period from 2010 to December 2020. We found that the major research efforts have been put in AI for rail maintenance and inspection, while very limited or no research has been found on AI for rail transport policy and revenue management. The remaining sub-domains received mild to moderate attention. AI applications are promising and tend to act as a game-changer in tackling multiple railway challenges. However, at the moment, AI research in railways is still mostly at its early stages. Future research can be expected towards developing advanced combined AI applications (e.g. with optimization), using AI in decision making, dealing with uncertainty and tackling newly rising cybersecurity challenges.}
}
@article{TRUDGETT2022101302,
title = {A framework for operationalising Aboriginal and Torres Strait Islander data sovereignty in Australia: Results of a systematic literature review of published studies},
journal = {eClinicalMedicine},
volume = {45},
pages = {101302},
year = {2022},
issn = {2589-5370},
doi = {https://doi.org/10.1016/j.eclinm.2022.101302},
url = {https://www.sciencedirect.com/science/article/pii/S2589537022000323},
author = {Skye Trudgett and Kalinda Griffiths and Sara Farnbach and Anthony Shakeshaft},
abstract = {Summary
Background
Racial health disparities are only likely to be meaningfully improved by tailoring public health and clinical interventions to the specific needs of Indigenous people and their communities. Accurate tailoring relies on the availability of high-quality Indigenous-specific data. The potential benefits of increased availability of Indigenous data need to be balanced by efforts to ensure those data are collected and used appropriately. This paper identifies characteristics of Indigenous Data Sovereignty (IDS) principles and considers a framework for operationalisation.
Methods
A PRISMA compliant search of the literature was undertaken, using methods detailed in the Cochrane Collaboration Handbook on Systematic Reviews of Health Promotion and Public Health Interventions (1). The search strategy comprised two steps: a search of 11 scientific electronic databases and five grey literature sources. The search was limited by date of publication (1 January 2000 to 1 December 2021). The following keywords and subject heading terms were used: (exp Aboriginal and Torres Strait Islander or Aborigin* or Torres Strait Island* or, Oceanic ancestry group) and (exp research or biomedical research or population surveillance or translational medical research or, research design) and (exp data or datasets or data collection or data management or health surveys or information dissemination or, intellectual property) and (exp self-determination or ownership or control or access or possession or OCAP or sovereignty or, ethics) and, (exp Australia). IDS principles: (i) ownership; (ii) control; (iii) accessibility; (iv) custodianship; (v) accountability to Indigenous people; (vi) amplify Community voice; (vii) relevant and reciprocal; and (viii) sustainably self-determining. Using standard data extraction forms, we examined relevant Australian studies to identify key characteristics and frequency with which they cited IDS principles. These findings were consolidated into an operationalisation framework.
Findings
34 relevant Australian published studies were identified. The most frequently cited IDS principles were Accountability to Aboriginal and Torres Strait Islander peoples and sustainably self-determining. The least frequently cited principle was Access. A framework to operationalise IDS principles is proposed that is both standardised internationally and able to be tailored to the diverse contexts of Indigenous peoples.
Interpretation
IDS is emergent in Australia and there is a clear need to establish an agreed set of International IDS principles and a framework for their operationalisation and contextualisation across diverse Indigenous communities and contexts.
Funding
This research project is funded through an Australian Research Council (ARC) Discovery Grant from 2017 to 2022. The National Drug and Alcohol Research Centre (NDARC) is funded by the Australian Government Department of Health. The 1st author (ST) is supported by a scholarship co-funded by NDARC and the Lowitja Institute.}
}
@article{REN2022133,
title = {Ensuring the quality of meat in cold chain logistics: A comprehensive review},
journal = {Trends in Food Science & Technology},
volume = {119},
pages = {133-151},
year = {2022},
issn = {0924-2244},
doi = {https://doi.org/10.1016/j.tifs.2021.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0924224421006634},
author = {Qing-Shan Ren and Kui Fang and Xin-Ting Yang and Jia-Wei Han},
keywords = {Meat, Cold chain logistics, Packaging, Quality perception, Intelligent development},
abstract = {Background
Meat packaging and intelligent evaluation and monitoring of key parameters not only are important technologies to ensure meat quality and safety but also form the key foundation for optimizing packaging materials and improving the efficiency of cold chain operations. In recent years, numerous studies have focused on comprehensive (or multi-functional) packaging materials, multiple parameter evaluation methods, quality intelligent monitoring technology, and optimization of the control of various links in cold chain logistics (CCL). Such research has significant practical application value for extending meat shelf-life and reducing the risk of foodborne diseases.
Scope and approach
This paper reviews the current research status, existing problems, and future evolution of CCL by focusing on meat packaging, meat quality evaluation and monitoring, and meat quality prediction and control. We also elaborate in detail the challenges faced in researching these topics and discuss the focal points of future research aiming to improve the quality and efficiency of CCL.
Key findings and conclusions
Packaging material optimization and dynamic quality perception are vital for achieving meat quality and safety over the entire CCL and demand the digital and intelligent development of the meat cold chain. A key finding of this review is that the comprehensive (or composite) packaging and intelligent quality assessment and monitoring are important forces promoting the transformation of traditional meat CCL to smart, green, and efficient CLL involving the intelligent management and control of all links therein.}
}
@article{ZAMAN2022109355,
title = {Feature selection for online streaming high-dimensional data: A state-of-the-art review},
journal = {Applied Soft Computing},
volume = {127},
pages = {109355},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.109355},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622005154},
author = {Ezzatul Akmal Kamaru Zaman and Azlinah Mohamed and Azlin Ahmad},
keywords = {Online feature selection, Streaming features, Feature relevancy, Feature redundancy, High-dimensional data, Feature drift},
abstract = {Knowledge discovery for data streaming requires online feature selection to reduce the complexity of real-world datasets and significantly improve the learning process. This is achieved by selecting highly relevant subsets and minimising irrelevant and redundant features. However, researchers have difficulties in addressing various forms of data. The goal of this article is to present a state-of-the-art review of feature subset selection based on the data form for the high-dimensional data used in online streaming. Through a systematic literature review assessing journal and conference papers from the past five years, detailed discussions on traditional feature selection and online feature selection were presented. Subsequently, a taxonomy of the challenges related to OFS provides a comprehensive review of state-of-the-art OFS and the benchmark methods. Several data forms were identified based on the extensive review: group stream, multi-label, capricious, imbalance, and feature drift. Using critical analysis, the evaluation metrics of online feature selection methods were compared from the perspectives of threshold initialisation, accuracy, high dimensionality, running time, relevancy, and redundancy for the optimal feature subset. An online feature selection framework was derived to illustrate the relationship between the application area, data form, online feature selection methods, evaluation metrics, and tools. Finally, the findings and potential directions for future research were thoroughly discussed. It is suggested that future researchers explore the derived framework and aim to advance each method.}
}
@article{SAW202212,
title = {Current challenges of implementing artificial intelligence in medical imaging},
journal = {Physica Medica},
volume = {100},
pages = {12-17},
year = {2022},
issn = {1120-1797},
doi = {https://doi.org/10.1016/j.ejmp.2022.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1120179722019962},
author = {Shier Nee Saw and Kwan Hoong Ng},
keywords = {Artificial intelligence, Medical imaging, Challenges, Ethics, Data governance, Algorithm robustness},
abstract = {The idea of using artificial intelligence (AI) in medical practice has gained vast interest due to its potential to revolutionise healthcare systems. However, only some AI algorithms are utilised due to systems’ uncertainties, besides the never-ending list of ethical and legal concerns. This paper intends to provide an overview of current AI challenges in medical imaging with an ultimate aim to foster better and effective communication among various stakeholders to encourage AI technology development. We identify four main challenges in implementing AI in medical imaging, supported with consequences and past events when these problems fail to mitigate. Among them is the creation of a robust AI algorithm that is fair, trustable and transparent. Another issue is on data governance, in which best practices in data sharing must be established to promote trust and protect the patients’ privacy. Next, stakeholders, such as the government, technology companies and hospital management, should come to a consensus in creating trustworthy AI policies and regulatory frameworks, which is the fourth challenge, to support, encourage and spur innovation in digital AI healthcare technology. Lastly, we discussed the efforts of various organizations such as the World Health Organisation (WHO), American College of Radiology (ACR), European Society of Radiology (ESR) and Radiological Society of North America (RSNA), who are already actively pursuing ethical developments in AI. The efforts by various stakeholders will eventually overcome hurdles and the deployment of AI-driven healthcare applications in clinical practice will become a reality and hence lead to better healthcare services and outcomes.}
}
@article{ALWAN2022101951,
title = {Data quality challenges in large-scale cyber-physical systems: A systematic review},
journal = {Information Systems},
volume = {105},
pages = {101951},
year = {2022},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2021.101951},
url = {https://www.sciencedirect.com/science/article/pii/S0306437921001484},
author = {Ahmed Abdulhasan Alwan and Mihaela Anca Ciupala and Allan J. Brimicombe and Seyed Ali Ghorashi and Andres Baravalle and Paolo Falcarin},
keywords = {Cyber-physical systems (CPS), Wireless Sensor Networks(WSN), Data quality management, Data quality dimensions, Smart cities, Quality of observations},
abstract = {Cyber-physical systems (CPSs) are integrated systems engineered to combine computational control algorithms and physical components such as sensors and actuators, effectively using an embedded communication core. Smart cities can be viewed as large-scale, heterogeneous CPSs that utilise technologies like the Internet of Things (IoT), surveillance, social media, and others to make informed decisions and drive the innovations of automation in urban areas. Such systems incorporate multiple layers and complex structure of hardware, software, analytical algorithms, business knowledge and communication networks, and operate under noisy and dynamic conditions. Thus, large-scale CPSs are vulnerable to enormous technical and operational challenges that may compromise the quality of data of their applications and accordingly reduce the quality of their services. This paper presents a systematic literature review to investigate data quality challenges in smart-cities large-scale CPSs and to identify the most common techniques used to address these challenges. This systematic literature review showed that significant work had been conducted to address data quality management challenges in smart cities, large-scale CPS applications. However, still, more is required to provide a practical, comprehensive data quality management solution to detect errors in sensor nodes’ measurements associated with the main data quality dimensions of accuracy, timeliness, completeness, and consistency. No systematic or generic approach was demonstrated for detecting sensor nodes and sensor node networks failures in large-scale CPS applications. Moreover, further research is required to address the challenges of ensuring the quality of the spatial and temporal contextual attributes of sensor nodes’ observations.}
}
@article{SHARMA2022107217,
title = {Technological revolutions in smart farming: Current trends, challenges & future directions},
journal = {Computers and Electronics in Agriculture},
volume = {201},
pages = {107217},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2022.107217},
url = {https://www.sciencedirect.com/science/article/pii/S0168169922005324},
author = {Vivek Sharma and Ashish Kumar Tripathi and Himanshu Mittal},
keywords = {Smart farming, Current Trends in smart farming, Precision agriculture, Agriculture 4.0, Machine Learning},
abstract = {With increasing population, the demand for agricultural productivity is rising to meet the goal of “Zero Hunger”. Consequently, farmers have optimized the agricultural activities in a sustainable way with the modern technologies. This integration has boosted the agriculture production due to high potentiality in assisting the farmers. The impulse towards the technological advancement has revived the traditional agriculture methods and resulted in eco-friendly, sustainable, and efficient farming. This has revolutionized the era of smart farming which primarily alliance with modern technologies like, big data, machine learning, deep learning, swarm intelligence, internet-of-things, block chain, robotics and autonomous system, cloud-fog-edge computing, cyber physical systems, and generative adversarial networks (GAN). To cater the same, a detailed survey on ten hot-spots of smart farming is presented in this paper. The survey covers the technology-wise state-of-the-art methods along with their application domains. Moreover, the publicly available data sets with existing research challenges are investigated. Lastly, the paper concludes with suggestions to the identified problems and possible future research directions.}
}
@article{WANG202268,
title = {Evaluation of survey and remote sensing data products used to estimate land use change in the United States: Evolving issues and emerging opportunities},
journal = {Environmental Science & Policy},
volume = {129},
pages = {68-78},
year = {2022},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2021.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S1462901121003762},
author = {Minzi Wang and Michelle Wander and Steffen Mueller and Nico Martin and Jennifer B. Dunn},
keywords = {Land use change, Survey data, Thematic maps, Remote sensing, Land use classification, Error, Uncertainty, Biofuel policy},
abstract = {Transparent, consistent, and statistically reliable land use/ land cover area estimates are needed to assess land use change and greenhouse gas emissions associated with biofuel production and other land uses that are influenced by policy. As relevant studies have increased rapidly during past decades, the methods used to combine data extracted from land use land cover (LULC) surveys and remote sensing-based products and track or report sources of uncertainty vary notably. This paper reviews six data sources that are most commonly used to investigate LULC and change in the contiguous U.S. by highlighting the main characteristics, strengths and weaknesses and considering how uncertainty is assessed by the June Area Survey (JAS), the Census of Agriculture (COA), the Farm Survey Agency (FSA) acreage, the National Resources Inventory (NRI), the National Wetlands Inventory (NWI), and the Forest Inventory and Analysis (FIA); and two remote sensing-based data products, the Cropland Data Layer (CDL) and the National Land Cover Database (NLCD). The summary and conclusion identify important research gaps or challenges limiting current land use/land cover and change studies (e.g., lack of high-quality reference data and uncertainty quantification, etc.) and opportunities and emerging techniques (data fusion and machine learning) that will improve reliability of land use/land cover assessments and associated policies. Blended approaches that marry high quality ground truth data that are more finely resolved than data supplied by government surveys with multitemporal imagery are needed track use of non-agricultural lands vulnerable to agricultural expansion. These considerations are notably important as the U.S. considers the renewal and possibly revision of its Renewable Fuel Standard, which includes provisions that require monitoring of agricultural land expansion.}
}
@article{LI2022160,
title = {Artificial intelligence in radiotherapy},
journal = {Seminars in Cancer Biology},
volume = {86},
pages = {160-171},
year = {2022},
issn = {1044-579X},
doi = {https://doi.org/10.1016/j.semcancer.2022.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S1044579X22001912},
author = {Guangqi Li and Xin Wu and Xuelei Ma},
keywords = {Artificial intelligence, Radiotherapy, Auto-segmentation, Auto-planning, Quality assurance},
abstract = {Radiotherapy is a discipline closely integrated with computer science. Artificial intelligence (AI) has developed rapidly over the past few years. With the explosive growth of medical big data, AI promises to revolutionize the field of radiotherapy through highly automated workflow, enhanced quality assurance, improved regional balances of expert experiences, and individualized treatment guided by multi-omics. In addition to independent researchers, the increasing number of large databases, biobanks, and open challenges significantly facilitated AI studies on radiation oncology. This article reviews the latest research, clinical applications, and challenges of AI in each part of radiotherapy including image processing, contouring, planning, quality assurance, motion management, and outcome prediction. By summarizing cutting-edge findings and challenges, we aim to inspire researchers to explore more future possibilities and accelerate the arrival of AI radiotherapy.}
}
@article{DEBRAH2022108443,
title = {Green finance gap in green buildings: A scoping review and future research needs},
journal = {Building and Environment},
volume = {207},
pages = {108443},
year = {2022},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2021.108443},
url = {https://www.sciencedirect.com/science/article/pii/S0360132321008398},
author = {Caleb Debrah and Albert Ping Chuen Chan and Amos Darko},
keywords = {Sustainability, Climate change, Green buildings, Green finance, Scoping review},
abstract = {Green buildings, although critical to climate change mitigation, have a huge investment deficit. Green finance provides a viable option for bridging the green buildings investment gap. Despite the benefits of green finance in green buildings (GF-in-GBs), limited attention has been paid to this research area. To provide an overview of and map the area for the first time, this study conducted a systematic scoping review. Systematic searches across the five databases of Scopus, the Web of Science, ScienceDirect, Google Scholar, and normal Google identified a total of 28 relevant studies, including both the grey and academic literature. Study selection and data charting were conducted independently by two reviewers using standardized forms, with disagreements resolved through discussions. General and methodological characteristics of GF-in-GBs research were mapped. Results indicated that this is a highly under-researched and under-invested area. Asia has so far however contributed most. Previous studies embraced a variety of research designs, but most were content or report analysis-based, with limited empirical work. Based on identified gaps this study suggested future research directions, including (1) green incentives for GF-in-GBs, (2) GF-in-GBs rating software, (3) AI-enabled GF-in-GBs performance assessment software, and (4) intelligent GF-in-GBs cost-benefit analysis framework. The findings of this study provide an understanding of the status quo and future needs of GF-in-GBs, which would help researchers, policymakers, and practitioners improve and promote the implementation of green finance for promoting green buildings to combat climate change.}
}
@article{DEEPA2022209,
title = {A survey on blockchain for big data: Approaches, opportunities, and future directions},
journal = {Future Generation Computer Systems},
volume = {131},
pages = {209-226},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22000243},
author = {N. Deepa and Quoc-Viet Pham and Dinh C. Nguyen and Sweta Bhattacharya and B. Prabadevi and Thippa Reddy Gadekallu and Praveen Kumar Reddy Maddikunta and Fang Fang and Pubudu N. Pathirana},
keywords = {Blockchain, Big data, Vertical applications, Smart city, Smart healthcare, Smart transportation, Security},
abstract = {Big data has generated strong interest in various scientific and engineering domains over the last few years. Despite many advantages and applications, there are many challenges in big data to be tackled for better quality of service, e.g., big data analytics, big data management, and big data privacy and security. Blockchain with its decentralization and security nature has the great potential to improve big data services and applications. In this article, we provide a comprehensive survey on blockchain for big data, focusing on up-to-date approaches, opportunities, and future directions. First, we present a brief overview of blockchain and big data as well as the motivation behind their integration. Next, we survey various blockchain services for big data, including blockchain for secure big data acquisition, data storage, data analytics, and data privacy preservation. Then, we review the state-of-the-art studies on the use of blockchain for big data applications in different domains such as smart city, smart healthcare, smart transportation, and smart grid. For a better understanding, some representative blockchain-big data projects are also presented and analyzed. Finally, challenges and future directions are discussed to further drive research in this promising area.}
}
@article{KASTOUNI20222758,
title = {Big data analytics in telecommunications: Governance, architecture and use cases},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {6, Part A},
pages = {2758-2770},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2020.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S131915782030553X},
author = {Mohamed Zouheir Kastouni and Ayoub {Ait Lahcen}},
keywords = {Big data analytics, Big data project’s governance methodology, Big data architecture, Data governance methodology, Big data project’s team, Big data telecommunications use cases},
abstract = {With the upsurge of data traffic due to the change in customer behavior towards the use of telecommunications services, fostered by the current global health situation (mainly due to Covid-19), the telecommunications operators have a golden opportunity to create new sources of revenues using Big Data Analytics (BDA) solutions. Looking to setting up a BDA project, we faced several challenges, notably, in terms of choice of the technical solution from the plethora of the existing tools, and the choice of the governance methodologies for governing the project and the data. The majority of research documents related to the telecommunications industry have not addressed BDA project implementation from start to finish. The purpose of this study focuses on a BDA telecommunications project, namely, Project’s Governance, Architecture, Data Governance and the BDA Project’s Team. The last part of this study presents useful BDA use cases, in terms of applications enabling revenue creation and cost optimization. It appears that this work will facilitate the implementation of BDA projects, and enable telecommunications operators to have a better understanding about the fundamental aspects to be focused on. It is therefore, a study that will contribute positively toward such goal.}
}
@article{SHARMA2022100383,
title = {Digital Twins: State of the art theory and practice, challenges, and open research questions},
journal = {Journal of Industrial Information Integration},
volume = {30},
pages = {100383},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2022.100383},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X22000516},
author = {Angira Sharma and Edward Kosasih and Jie Zhang and Alexandra Brintrup and Anisoara Calinescu},
keywords = {Digital Twin, Internet of Things, Autonomous systems, Big data, Machine learning},
abstract = {Digital Twin was introduced over a decade ago, as an innovative all-encompassing tool, with perceived benefits including real-time monitoring, simulation, optimisation and accurate forecasting. However, the theoretical framework and practical implementations of digital twin (DT) are yet to fully achieve this vision at scale. Although an increasing number of successful implementations exist in research and industrial works, sufficient implementation details are not publicly available, making it difficult to fully assess their components and effectiveness, to draw comparisons, identify successful solutions, share lessons, and thus to jointly advance and benefit from the DT methodology. This work first presents a review of relevant DT research and industrial works, focusing on the key DT features, current approaches in different domains, and successful DT implementations, to infer the key DT components and properties, and to identify current limitations and reasons behind the delay in the widespread implementation and adoption of digital twin. This work identifies that the major reasons for this delay are: the fact the DT is still a fast evolving concept; the lack of a universal DT reference framework, e.g. DT standards are scarce and still evolving; problem- and domain-dependence; security concerns over shared data; lack of DT performance metrics; and reliance of digital twin on other fast-evolving technologies. Advancements in machine learning, Internet of Things (IoT) and big data have led to significant improvements in DT features such as real-time monitoring and accurate forecasting. Despite this progress and individual company-based efforts, certain research and implementation gaps exist in the field, which have so far prevented the widespread adoption of the DT concept and technology; these gaps are also discussed in this work. Based on reviews of past work and the identified gaps, this work then defines a conceptualisation of DT which includes its components and properties; these also validate the uniqueness of DT as a concept, when compared to similar concepts such as simulation, autonomous systems and optimisation. Real-life case studies are used to showcase the application of the conceptualisation. This work discusses the state-of-the-art in DT, addresses relevant and timely DT questions, and identifies novel research questions, thus contributing to a better understanding of the DT paradigm and advancing the theory and practice of DT and its allied technologies.}
}
@article{HUSEIEN2022100116,
title = {A review on 5G technology for smart energy management and smart buildings in Singapore},
journal = {Energy and AI},
volume = {7},
pages = {100116},
year = {2022},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2021.100116},
url = {https://www.sciencedirect.com/science/article/pii/S2666546821000653},
author = {Ghasan Fahim Huseien and Kwok Wei Shah},
keywords = {5G technology, Sustainability, Smart building, Facilities management, Build environment},
abstract = {Sustainable and smart building is a recent concept that is gaining momentum in public opinion, and thus, it is making its way into the agendas of researchers and city authorities all over the world. To move towards sustainable development goals, 5G technology would make significant impacts are building construction, operation, and management by facilitating high-class services, providing efficient functionalities. It's well known that the Singapore is one of top smart cities in this world and from the first counties that adopted of 5G technology in various sectors including smart buildings. Based on these facts, this paper discusses the international trends in 5G applications for smart buildings, and R&D and test bedding works conducted in 5G labs. As well as, the manuscript widely reviewed and discussed the 5G technology development, use cases, applications and future projects which supported by Singapore government. Finally, the 5G use cases for smart buildings and build environment improvement application were discussed. This study can serve as a benchmark for researchers and industries for the future progress and development of smart cities in the context of big data.}
}
@article{GHORBANI2022101089,
title = {Framework components for data-centric dry laboratories in the minerals industry: A path to science-and-technology-led innovation},
journal = {The Extractive Industries and Society},
volume = {10},
pages = {101089},
year = {2022},
issn = {2214-790X},
doi = {https://doi.org/10.1016/j.exis.2022.101089},
url = {https://www.sciencedirect.com/science/article/pii/S2214790X22000508},
author = {Yousef Ghorbani and Steven E. Zhang and Glen T. Nwaila and Julie E. Bourdeau},
keywords = {Dry laboratory, Data analytics, Process simulation, Mining industry, Data-centric, Data-driven},
abstract = {ABSTRACT
The world continues to experience a surge in data generation and digital transformation. Historic data is increasingly being replaced by modernized data, such as big data, which is regarded as data that exhibits the 5Vs: volume, variety, velocity, veracity and value. The capacity to optimally use and comprehend value from big data has become an indispensable aptitude for modern companies. In contrast to commercial and technology firms, usage, management and governance of data, including big data is a novel and evolving trend for mining and mineral industries. Although the mining industry can be unenthusiastic to change, embracing modernized data and big data is evolutionarily unavoidable, given many industry-wide challenges (i.e., fluctuation in commodity prices, geotechnical and harsh ground conditions, and ore grade), which corrode revenues and increase business risks, including the possibility of regulatory non-compliance. The minerals industry holds a genuine gold mine of data that were collected for scientific, engineering, operational and other purposes. Data and data-centric workspaces that are targeted towards innovation and experimentation, which if combined with in-discipline expertise are two harmonious ingredients that can provide many practical solutions for the mining and mineral industries. In this paper, the concept, the opportunity and the necessity for a move towards a technology- and innovation-based, data-centric ‘dry laboratories’ (common workspaces that facilitates data-centric experimentation and innovation) in the minerals industry are assessed. We contend that the dry laboratory environment maximizes the value of data for the minerals industry. Toward the establishment of dry laboratories, we propose several essential components of a framework that would enable the functionality of dry laboratories in the minerals industry, while concomitantly examining the components from both academia and industry perspectives.}
}
@article{HE2022104168,
title = {Integrated structural health monitoring in bridge engineering},
journal = {Automation in Construction},
volume = {136},
pages = {104168},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104168},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522000413},
author = {Zhiguo He and Wentao Li and Hadi Salehi and Hao Zhang and Haiyi Zhou and Pengcheng Jiao},
keywords = {Structural health monitoring (SHM), Bridge engineering},
abstract = {Integrated structural health monitoring (SHM) uses the mechanism analysis, monitoring technology and data analytics to diagnose the classification, location and significance of structural situations (e.g., sudden or cumulative damages) to ensure the functionality and operation of bridges. Integrated SHM systems have improved the maintenance, management and decision-making of bridges by continuously monitoring and evaluating working conditions. This review article discusses the current process and future trends of bridge monitoring focusing on the cutting-edge SHM technologies, transmission and analytics methods of the sensing data, and prediction and early-warning models. In particular, four extensively applied sensing technologies (i.e., fiber optic sensors, piezoelectric sensors, global navigation satellite system and magnetostrictive sensors) are reviewed and compared, the wireless data transmission approaches (i.e., ZigBee, Bluetooth, NB-IoT, Wi-Fi, LoRa) are discussed, the artificial intelligence-based data processing methods are presented, and the performance prediction and early warning systems are summarized. In the end, the challenges and future research avenues of the current integrated SHM systems are discussed with respect to the characteristics of bridges.}
}
@article{FANG2022,
title = {Computational Approaches and Challenges in Spatial Transcriptomics},
journal = {Genomics, Proteomics & Bioinformatics},
year = {2022},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2022.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1672022922001292},
author = {Shuangsang Fang and Bichao Chen and Yong Zhang and Haixi Sun and Longqi Liu and Shiping Liu and Yuxiang Li and Xun Xu},
keywords = {Spatial transcriptomics, Computational approaches, Data quality, Data interpretation, Multi-omics integration},
abstract = {The development of spatial transcriptomics technologies has transformed genetic research from a single-cell data level to a two-dimensional spatial coordinate system and facilitated the study of the composition and function of various cell subsets in different environments and organs. The large-scale data generated by these spatial transcriptomics technologies, which contains spatial gene expression information, have elicited the need for spatially resolved approaches to meet the requirements of computational and biological data interpretation. These requirements include dealing with the explosive growth of data to determine the cell-level and gene-level expression, correcting the inner batch effect and loss of expression to improve the data quality, conducting efficient interpretation and in-depth knowledge mining both at the single-cell and tissue-wide levels, and conducting multi-omics integration analysis to provide an extensible framework towards the in-depth understanding of biological processes. However, algorithms designed specifically for spatial transcriptomics technologies to meet these requirements are still in their infancy. Here, we review computational approaches to these problems in light of corresponding issues and challenges, and present forward-looking insights into algorithm development.}
}
@article{DEBRAH2022104192,
title = {Artificial intelligence in green building},
journal = {Automation in Construction},
volume = {137},
pages = {104192},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104192},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522000656},
author = {Caleb Debrah and Albert P.C. Chan and Amos Darko},
keywords = {Artificial intelligence, Green building, Bibliometric analysis, Systematic analysis, Sustainability},
abstract = {The Architecture, Engineering and Construction (AEC) sector faces severe sustainability and efficiency challenges. The application of artificial intelligence in green building (AI-in-GB) is an effective solution to enhance the sustainability and efficiency of the sector. While studies have been conducted in the AI-in-GB domain, an in-depth study on the state-of-the-art of AI-in-GB research is hitherto lacking. To provide a better understanding of this underexplored area, this study was initiated via a bibliometric-systematic analysis method. The study aims to reveal the synthesis between AI and GB, as well as to highlight research trends along with knowledge gaps that may be tackled in future AI-in-GB research. A quantitative bibliometric analysis was conducted to objectively identify the major research hotspots, trends, knowledge gaps and future research needs based on 383 research publications identified from Scopus. A further qualitative systematic analysis was also conducted on 76 screened research publications on AI-in-GB. Through this mixed-methods systematic review, knowledge gaps were identified, and future research directions of AI-in-GB were proposed as follows: digital twins and AI of things; blockchain; robotics and 4D printing; and legal, ethical, and moral responsibilities of AI-in-GB. This study adds to the GB knowledge domain by synthesizing the state-of-the-art of AI-in-GB and revealing the research needs in this field to enhance the sustainability and efficiency of the AEC sector.}
}
@article{LI2022,
title = {Intelligent Drilling and Completion: A Review},
journal = {Engineering},
year = {2022},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2022.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S2095809922006257},
author = {Gensheng Li and Xianzhi Song and Shouceng Tian and Zhaopeng Zhu},
keywords = {Intelligent drilling and completion, Artificial intelligence, Intelligent application scenarios, Literature review, Systematic discuss},
abstract = {The application of artificial intelligence (AI) has become inevitable in the petroleum industry. In drilling and completion engineering, AI is regarded as a transformative technology that can lower costs and significantly improve drilling efficiency (DE). In recent years, numerous studies have focused on intelligent algorithms and their application. Advanced technologies, such as digital twins and physics-guided neural networks, are expected to play roles in drilling and completion engineering. However, many challenges remain to be addressed, such as the automatic processing of multi-source and multi-scale data. Additionally, in intelligent drilling and completion, methods for the fusion of data-driven and physics-based models, few-sample learning, uncertainty modeling, and the interpretability and transferability of intelligent algorithms are research frontiers. Based on intelligent application scenarios, this study comprehensively reviews the research status of intelligent drilling and completion and discusses key research areas in the future. This study aims to enhance the berthing of AI techniques in drilling and completion engineering.}
}
@article{BURNS2022420,
title = {Real-World Evidence for Regulatory Decision-Making: Guidance From Around the World},
journal = {Clinical Therapeutics},
volume = {44},
number = {3},
pages = {420-437},
year = {2022},
issn = {0149-2918},
doi = {https://doi.org/10.1016/j.clinthera.2022.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0149291822000170},
author = {Leah Burns and Nadege Le Roux and Robert Kalesnik-Orszulak and Jennifer Christian and Mathias Hukkelhoven and Frank Rockhold and John O'Donnell},
keywords = {Efficiency, Product effectiveness, Real-world evidence, Regulatory decision making},
abstract = {Purpose
Interest in leveraging real-world evidence (RWE) to support regulatory decision making for product effectiveness has been increasing globally as evident by the increasing number of regulatory frameworks and guidance documents. However, acceptance of RWE, especially before marketing for regulatory approval, differs across countries. In addition, guidance on the design and conduct of innovative clinical trials, such as randomized controlled registry studies, pragmatic trials, and other hybrid studies, is lacking.
Methods
We assessed the global regulatory environment with regard to RWE based on regional availability of the following 3 key regulatory elements: (1) RWE regulatory framework, (2) data quality and standards guidance. and (3) study methods guidance.
Findings
This article reviews the available frameworks and existing guidance from across the globe and discusses the observed gaps and opportunities for further development and harmonization.
Implications
Cross-country collaborations are encouraged to further shape and align RWE policies and help establish frameworks in countries without current policies with the goal of creating efficiencies when considering RWE to support regulatory decision-making globally.}
}
@article{SARKER2022100528,
title = {Smart City Data Science: Towards data-driven smart cities with open research issues},
journal = {Internet of Things},
volume = {19},
pages = {100528},
year = {2022},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2022.100528},
url = {https://www.sciencedirect.com/science/article/pii/S2542660522000300},
author = {Iqbal H. Sarker},
keywords = {Smart cities, Data science, Machine learning, Internet of Things, Data-driven decision making, Intelligent services, Cybersecurity},
abstract = {Cities are undergoing huge shifts in technology and operations in recent days, and ‘data science’ is driving the change in the current age of the Fourth Industrial Revolution (Industry 4.0 or 4IR). Extracting useful knowledge or actionable insights from city data and building a corresponding data-driven model is the key to making a city system automated and intelligent. Data science is typically the scientific study and analysis of actual happenings with historical data using a variety of scientific methodologies, machine learning techniques, processes, and systems. In this paper, we concentrate on and explore “Smart City Data Science”, where city data collected from various sources such as sensors, Internet-connected devices, or other external sources, is being mined for insights and hidden correlations to enhance decision-making processes and deliver better and more intelligent services to citizens. To achieve this goal, artificial intelligence, particularly, machine learning analytical modeling can be employed to provide deeper knowledge about city data, which makes the computing process more actionable and intelligent in various real-world city services. Finally, we identify and highlight ten open research issues for future development and research in the context of data-driven smart cities. Overall, we aim to provide an insight into smart city data science conceptualization on a broad scale, which can be used as a reference guide for the researchers, industry professionals, as well as policy-makers of a country, particularly, from the technological point of view.}
}
@article{KIRTLEY2022243,
title = {Translating promise into practice: a review of machine learning in suicide research and prevention},
journal = {The Lancet Psychiatry},
volume = {9},
number = {3},
pages = {243-252},
year = {2022},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(21)00254-6},
url = {https://www.sciencedirect.com/science/article/pii/S2215036621002546},
author = {Olivia J Kirtley and Kasper {van Mens} and Mark Hoogendoorn and Navneet Kapur and Derek {de Beurs}},
abstract = {Summary
In ever more pressured health-care systems, technological solutions offering scalability of care and better resource targeting are appealing. Research on machine learning as a technique for identifying individuals at risk of suicidal ideation, suicide attempts, and death has grown rapidly. This research often places great emphasis on the promise of machine learning for preventing suicide, but overlooks the practical, clinical implementation issues that might preclude delivering on such a promise. In this Review, we synthesise the broad empirical and review literature on electronic health record-based machine learning in suicide research, and focus on matters of crucial importance for implementation of machine learning in clinical practice. The challenge of preventing statistically rare outcomes is well known; progress requires tackling data quality, transparency, and ethical issues. In the future, machine learning models might be explored as methods to enable targeting of interventions to specific individuals depending upon their level of need—ie, for precision medicine. Primarily, however, the promise of machine learning for suicide prevention is limited by the scarcity of high-quality scalable interventions available to individuals identified by machine learning as being at risk of suicide.}
}
@article{GOH20221029,
title = {Are batch effects still relevant in the age of big data?},
journal = {Trends in Biotechnology},
volume = {40},
number = {9},
pages = {1029-1040},
year = {2022},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2022.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167779922000361},
author = {Wilson Wen Bin Goh and Chern Han Yong and Limsoon Wong},
keywords = {artificial intelligence, batch effect, machine learning, RNA sequencing, single cell},
abstract = {Batch effects (BEs) are technical biases that may confound analysis of high-throughput biotechnological data. BEs are complex and effective mitigation is highly context-dependent. In particular, the advent of high-resolution technologies such as single-cell RNA sequencing presents new challenges. We first cover how BE modeling differs between traditional datasets and the new data landscape. We also discuss new approaches for measuring and mitigating BEs, including whether a BE is significant enough to warrant correction. Even with the advent of machine learning and artificial intelligence, the increased complexity of next-generation biotechnological data means increased complexities in BE management. We forecast that BEs will not only remain relevant in the age of big data but will become even more important.}
}
@article{DICKERSON2022,
title = {Data, information, knowledge, wisdom and understanding},
journal = {Anaesthesia & Intensive Care Medicine},
year = {2022},
issn = {1472-0299},
doi = {https://doi.org/10.1016/j.mpaic.2022.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1472029922002089},
author = {Jonathan E Dickerson},
keywords = {Cognitive bias, competence, data, DIKW hierarchy, information, knowledge, metacognition, understanding, wisdom},
abstract = {The digital age commenced in the mid-20th century and since we have seen approximately exponential growth in information. This period has also seen the rapid growth of computer technology that has facilitated, for instance, the derivation of whole genomes and automated drug discovery. Data, information, knowledge and wisdom lay the foundations for understanding how experience is formed from evidence and observations. When data are put into context, the resultant information can drive growth and further contribute to increased knowledge. Appreciating the source of data enables us to recognize and hopefully correct for inherent error and bias. Ultimately knowledge discovery can be automated to gain information from data and so on, enhancing our understanding of a given subject and expanding collective wisdom.}
}
@article{WANG2022477,
title = {Methodology of network pharmacology for research on Chinese herbal medicine against COVID-19: A review},
journal = {Journal of Integrative Medicine},
volume = {20},
number = {6},
pages = {477-487},
year = {2022},
issn = {2095-4964},
doi = {https://doi.org/10.1016/j.joim.2022.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095496422000966},
author = {Yi-xuan Wang and Zhen Yang and Wen-xiao Wang and Yu-xi Huang and Qiao Zhang and Jia-jia Li and Yu-ping Tang and Shi-jun Yue},
keywords = {Chinese traditional medicine, Herbal medicine, Network pharmacology, Compound identification, COVID-19},
abstract = {Traditional Chinese medicine, as a complementary and alternative medicine, has been practiced for thousands of years in China and possesses remarkable clinical efficacy. Thus, systematic analysis and examination of the mechanistic links between Chinese herbal medicine (CHM) and the complex human body can benefit contemporary understandings by carrying out qualitative and quantitative analysis. With increasing attention, the approach of network pharmacology has begun to unveil the mystery of CHM by constructing the heterogeneous network relationship of “herb-compound-target-pathway,” which corresponds to the holistic mechanisms of CHM. By integrating computational techniques into network pharmacology, the efficiency and accuracy of active compound screening and target fishing have been improved at an unprecedented pace. This review dissects the core innovations to the network pharmacology approach that were developed in the years since 2015 and highlights how this tool has been applied to understanding the coronavirus disease 2019 and refining the clinical use of CHM to combat it.}
}
@article{YOU202268,
title = {Mapping global cropping system: Challenges, opportunities, and future perspectives},
journal = {Crop and Environment},
volume = {1},
number = {1},
pages = {68-73},
year = {2022},
issn = {2773-126X},
doi = {https://doi.org/10.1016/j.crope.2022.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S2773126X22000065},
author = {Liangzhi You and Zhanli Sun},
keywords = {Cropping system, Food security, Global crop mapping, Remote sensing, SPAM},
abstract = {Spatially explicit global cropping system data products, which provide critical information on harvested areas, crop yields, and other management variables, are imperative to tackle current grand challenges such as global food security and climate change. These cropping system datasets are also very useful for researchers as they can support various scientific analyses in research projects. Yet, effectively searching, navigating, and fully understanding various global datasets can be a daunting task for researchers and policy analysts. In this review, we first compare a few selected global data products, which use crop census and statistical data as the main data source, and identify key problems and challenges of the global crop mapping such as data accuracy and consistency. We then pointed out the future perspectives and directions in further improving the global cropping data products. Collective mechanisms and efforts with the support of open-access data hosting platforms, standard protocols, and consistent financial support are necessary to produce high-quality datasets for researchers, practitioners, and policymakers. Moreover, machine learning and data fusion approaches can also be further explored in future mapping exercises.}
}
@article{WANG2022105028,
title = {Principles, research status, and prospects of feature engineering for data-driven building energy prediction: A comprehensive review},
journal = {Journal of Building Engineering},
volume = {58},
pages = {105028},
year = {2022},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2022.105028},
url = {https://www.sciencedirect.com/science/article/pii/S2352710222010385},
author = {Zeyu Wang and Lisha Xia and Hongping Yuan and Ravi S. Srinivasan and Xiangnan Song},
keywords = {Feature engineering, Feature construction, Feature selection, Feature extraction, Building energy prediction, Machine learning},
abstract = {With the rapid growth in the volume of relevant and available data, feature engineering is emerging as a popular research subject in data-driven building energy prediction owing to its essential role in improving data quality. Many studies have examined the feasibility of applying feature engineering methods to data-driven building energy prediction. However, a systematic review of this area's research status, characteristics, and limitations is lacking. Therefore, this study analyzes the current status of research and directions of future work in feature engineering for building energy prediction. In this article, we first discuss the concept of feature engineering and its main methods, including the construction, selection, and extraction of features. We, then, summarize the status and characteristics of feature engineering research in the building energy domain using a comprehensive study of 172 relevant articles. We also discuss critical issues in feature engineering in data-driven building energy prediction, including why feature engineering has recently received increasing attention, whether it is useful in this domain, and effective ways to apply it. Finally, we identify promising research directions in the area based on its current state and limitations. The results here provide researchers and the industry with a better understanding of the state of the art and future research trends in feature engineering for data-driven building energy prediction.}
}
@article{MA2022105082,
title = {Knowledge graph construction and application in geosciences: A review},
journal = {Computers & Geosciences},
volume = {161},
pages = {105082},
year = {2022},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2022.105082},
url = {https://www.sciencedirect.com/science/article/pii/S0098300422000450},
author = {Xiaogang Ma},
keywords = {Knowledge graph, Open data, Machine learning, Artificial intelligence, Data science},
abstract = {Knowledge graph (KG) is a topic of great interests to geoscientists as it can be deployed throughout the data life cycle in data-intensive geoscience studies. Nevertheless, comparing with the large amounts of publications on machine learning applications in geosciences, summaries and reviews of geoscience KGs are still limited. The aim of this paper is to present a comprehensive review of KG construction and implementation in geosciences. It consists of four major parts: 1) concepts relevant to KG and approaches for KG construction, 2) KG application in data collection, curation, and service, 3) KG application in data analysis, and 4) challenges and trends of geoscience KG creation and application in the near future. For each of the first three parts, a list of concepts, exemplar studies, and best practices are summarized. Those summaries are synthesized together in the challenge and trend analyses. As artificial intelligence and data science are thriving in geosciences, we hope this review of geoscience KGs can be of value to practitioners in data-intensive geoscience studies.}
}
@article{WANG2022104464,
title = {Construction and maintenance of urban underground infrastructure with digital technologies},
journal = {Automation in Construction},
volume = {141},
pages = {104464},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104464},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522003375},
author = {Mingzhu Wang and Xianfei Yin},
keywords = {Underground infrastructure, Literature review, Digital technologies, Inspection and maintenance, Condition assessment, Underground construction, Infrastructure operation & maintenance},
abstract = {Urban underground infrastructure is a critical component in cities to provide essential services to residents. Research efforts have been made to facilitate different activities of underground infrastructure projects using various methods, particularly digital technologies. To obtain deeper insights from existing research and provide directions for future research, this study conducts a comprehensive review of research on underground infrastructure construction and Operation & Maintenance (O&M) with a focus on digital technologies. The in-depth review was conducted based on 145 publications from the perspective of locating and mapping, construction and coordination, as well as O&M. Consequently, critical limitations and challenges are revealed, such as the lack of as-built and as-is information, the requirement of data quality and quantity for deep learning methods, the lack of fully automated robotic systems, etc. Afterwards, a status matrix was presented to identify the level of different digital technologies being studied and their future application potential for key activities of underground infrastructure projects. In the end, future research trends are proposed, including (1) digital twinning of underground infrastructure, (2) quality and uncertainty of inspection data, (3) data generation and semi-supervised learning, (4) predictive maintenance, and (5) fully automated robotic systems for inspection and maintenance. This study contributes to the body of knowledge by identifying the challenges and limitations of existing studies through a systematic review, providing a clear view of the achievements and potentials of digital technologies for underground infrastructure, and proposing future research directions to facilitate digital transformation in this area.}
}
@article{KOTECHA2022e757,
title = {CODE-EHR best-practice framework for the use of structured electronic health-care records in clinical research},
journal = {The Lancet Digital Health},
volume = {4},
number = {10},
pages = {e757-e764},
year = {2022},
issn = {2589-7500},
doi = {https://doi.org/10.1016/S2589-7500(22)00151-0},
url = {https://www.sciencedirect.com/science/article/pii/S2589750022001510},
author = {Dipak Kotecha and Folkert W Asselbergs and Stephan Achenbach and Stefan D Anker and Dan Atar and Colin Baigent and Amitava Banerjee and Birgit Beger and Gunnar Brobert and Barbara Casadei and Cinzia Ceccarelli and Martin R Cowie and Filippo Crea and Maureen Cronin and Spiros Denaxas and Andrea Derix and Donna Fitzsimons and Martin Fredriksson and Chris P Gale and Georgios V Gkoutos and Wim Goettsch and Harry Hemingway and Martin Ingvar and Adrian Jonas and Robert Kazmierski and Susanne Løgstrup and R Thomas Lumbers and Thomas F Lüscher and Paul McGreavy and Ileana L Piña and Lothar Roessig and Carl Steinbeisser and Mats Sundgren and Benoît Tyl and Ghislaine van Thiel and Kees van Bochove and Panos E Vardas and Tiago Villanueva and Marilena Vrana and Wim Weber and Franz Weidinger and Stephan Windecker and Angela Wood and Diederick E Grobbee},
abstract = {Summary
Big data is important to new developments in global clinical science that aim to improve the lives of patients. Technological advances have led to the regular use of structured electronic health-care records with the potential to address key deficits in clinical evidence that could improve patient care. The COVID-19 pandemic has shown this potential in big data and related analytics but has also revealed important limitations. Data verification, data validation, data privacy, and a mandate from the public to conduct research are important challenges to effective use of routine health-care data. The European Society of Cardiology and the BigData@Heart consortium have brought together a range of international stakeholders, including representation from patients, clinicians, scientists, regulators, journal editors, and industry members. In this Review, we propose the CODE-EHR minimum standards framework to be used by researchers and clinicians to improve the design of studies and enhance transparency of study methods. The CODE-EHR framework aims to develop robust and effective utilisation of health-care data for research purposes.}
}
@article{DADEBAYEV20224385,
title = {EEG-based emotion recognition: Review of commercial EEG devices and machine learning techniques},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {7},
pages = {4385-4401},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821000732},
author = {Didar Dadebayev and Wei Wei Goh and Ee Xion Tan},
keywords = {Electroencephalography, Emotion recognition, Consumer-grade EEG, Machine learning, Classification},
abstract = {Emotion recognition based on electroencephalography (EEG) signal features is now one of the booming big data research areas. As the number of commercial EEG devices in the current market increases, there is a need to understand current trends and provide researchers and young practitioners with insights into future investigations of emotion recognition systems. This paper aims to evaluate popular consumer-grade EEG devices’ status and review relevant studies that examined the reliability of these low-cost devices for emotion recognition over the last five years. Additionally, a comparison with research-grade devices is conducted. This paper also highlights EEG-based emotion recognition research’s key areas, including different feature extraction capabilities, characteristics, and machine learning algorithms. Finally, the main challenges for building an EEG-based emotion recognition system, focusing on the data collection process with commercial EEG devices and machine learning algorithms’ performance, are presented.}
}
@article{SUN2022191,
title = {Advances in optical phenotyping of cereal crops},
journal = {Trends in Plant Science},
volume = {27},
number = {2},
pages = {191-208},
year = {2022},
issn = {1360-1385},
doi = {https://doi.org/10.1016/j.tplants.2021.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S1360138521002028},
author = {Dawei Sun and Kelly Robbins and Nicolas Morales and Qingyao Shu and Haiyan Cen},
keywords = {cereal crops, high-throughput phenotyping, optical sensors, traits},
abstract = {Optical sensors and sensing-based phenotyping techniques have become mainstream approaches in high-throughput phenotyping for improving trait selection and genetic gains in crops. We review recent progress and contemporary applications of optical sensing-based phenotyping (OSP) techniques in cereal crops and highlight optical sensing principles for spectral response and sensor specifications. Further, we group phenotypic traits determined by OSP into four categories – morphological, biochemical, physiological, and performance traits – and illustrate appropriate sensors for each extraction. In addition to the current status, we discuss the challenges of OSP and provide possible solutions. We propose that optical sensing-based traits need to be explored further, and that standardization of the language of phenotyping and worldwide collaboration between phenotyping researchers and other fields need to be established.}
}
@article{FURSTENAU2022,
title = {Internet of things: Conceptual network structure, main challenges and future directions},
journal = {Digital Communications and Networks},
year = {2022},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2022.04.027},
url = {https://www.sciencedirect.com/science/article/pii/S2352864822000827},
author = {Leonardo B. Furstenau and Yan Pablo Reckziegel Rodrigues and Michele Kremer Sott and Pedro Leivas and Michael S. Dohan and José Ricardo López-Robles and Manuel J. Cobo and Nicola Luigi Bragazzi and Kim-Kwang {Raymond Choo}},
keywords = {Internet of things, Strategic intelligence, Industry 4.0, SciMAT, Bibliometric analysis, Science mapping},
abstract = {Internet of Things (IoT) is a key technology trend that supports our digitalized society in applications such as smart countries and smart cities. In this study, we investigated the existing strategic themes, thematic evolution structure, key challenges, and potential research opportunities associated with the IoT. For this study, we conducted a Bibliometric Performance and Network Analysis (BPNA), supplemented by an exhaustive Systematic Literature Review (SLR). Specifically, in BPNA, the software SciMAT was used to analyze 14,385 documents and 30,381 keywords in the Web of Science (WoS) database, which was released between 2002 and 2019. The results revealed that 31 clusters are classified according to their importance and development, and the conceptual structures of key clusters are presented, along with their performance analysis and the relationship with other subthemes. The thematic evolution structure described the important cluster(s) over time. For the SLR, 23 documents were analyzed. The SLR revealed key challenges and limitations associated with the IoT. We expect the results will form the basis of future research and guide decision-making in the IoT and other supporting industries.}
}
@article{ABBASI2022100042,
title = {The digitization of agricultural industry – a systematic literature review on agriculture 4.0},
journal = {Smart Agricultural Technology},
volume = {2},
pages = {100042},
year = {2022},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2022.100042},
url = {https://www.sciencedirect.com/science/article/pii/S2772375522000090},
author = {Rabiya Abbasi and Pablo Martinez and Rafiq Ahmad},
keywords = {Agriculture 4.0, Industry 4.0, Digitization, Connectivity, Internet of things, Smart agricultural systems},
abstract = {Agriculture is considered one of the most important sectors that play a strategic role in ensuring food security. However, with the increasing world's population, agri-food demands are growing — posing the need to switch from traditional agricultural methods to smart agriculture practices, also known as agriculture 4.0. To fully benefit from the potential of agriculture 4.0, it is significant to understand and address the problems and challenges associated with it. This study, therefore, aims to contribute to the development of agriculture 4.0 by investigating the emerging trends of digital technologies in the agricultural industry. For this purpose, a systematic literature review based on Protocol of Preferred Reporting Items for Systematic Reviews and Meta-Analyses is conducted to analyse the scientific literature related to crop farming published in the last decade. After applying the protocol, 148 papers were selected and the extent of digital technologies adoption in agriculture was examined in the context of service type, technology readiness level, and farm type. The results have shown that digital technologies such as autonomous robotic systems, internet of things, and machine learning are significantly explored and open-air farms are frequently considered in research studies (69%), contrary to indoor farms (31%). Moreover, it is observed that most use cases are still in the prototypical phase. Finally, potential roadblocks to the digitization of the agriculture sector were identified and classified at technical and socio-economic levels. This comprehensive review results in providing useful information on the current status of digital technologies in agriculture along with prospective future opportunities.}
}
@article{DU2022,
title = {Intelligent Monitoring System Based on Spatio–Temporal Data for Underground Space Infrastructure},
journal = {Engineering},
year = {2022},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2022.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S209580992200635X},
author = {Bowen Du and Junchen Ye and Hehua Zhu and Leilei Sun and Yanliang Du},
keywords = {Structure health monitoring, Underground space infrastructure, Machine learning, Spatio–temporal data},
abstract = {Intelligent sensing, mechanism understanding, and the deterioration forecasting based on spatio–temporal big data not only promote the safety of the infrastructure but also indicate the basic theory and key technology for the infrastructure construction to turn to intelligentization. The advancement of underground space utilization has led to the development of three characteristics (deep, big, and clustered) that help shape a tridimensional urban layout. However, compared to buildings and bridges overground, the diseases and degradation that occur underground are more insidious and difficult to identify. Numerous challenges during the construction and service periods remain. To address this gap, this paper summarizes the existing methods and evaluates their strong points and weak points based on real-world space safety management. The key scientific issues, as well as solutions, are discussed in a unified intelligent monitoring system.}
}
@article{GARRIDO2022103465,
title = {Revealing the landscape of privacy-enhancing technologies in the context of data markets for the IoT: A systematic literature review},
journal = {Journal of Network and Computer Applications},
volume = {207},
pages = {103465},
year = {2022},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2022.103465},
url = {https://www.sciencedirect.com/science/article/pii/S1084804522001126},
author = {Gonzalo Munilla Garrido and Johannes Sedlmeir and Ömer Uludağ and Ilias Soto Alaoui and Andre Luckow and Florian Matthes},
keywords = {Anonymization, Big data, Copy problem, Data exchange, Marketplace, Platform, Secure computation},
abstract = {IoT data markets in public and private institutions have become increasingly relevant in recent years because of their potential to improve data availability and unlock new business models. However, exchanging data in markets bears considerable challenges related to disclosing sensitive information. Despite considerable research focused on different aspects of privacy-enhancing data markets for the IoT, none of the solutions proposed so far seems to find a practical adoption. Thus, this study aims to organize the state-of-the-art solutions, analyze and scope the technologies that have been suggested in this context, and structure the remaining challenges to determine areas where future research is required. To accomplish this goal, we conducted a systematic literature review on privacy enhancement in data markets for the IoT, covering 50 publications dated up to July 2020, and provided updates with 24 publications dated up to May 2022. Our results indicate that most research in this area has emerged only recently, and no IoT data market architecture has established itself as canonical. Existing solutions frequently lack the required combination of anonymization and secure computation technologies. Furthermore, there is no consensus on the appropriate use of blockchain technology for IoT data markets and a low degree of leveraging existing libraries or reusing generic data market architectures. We also identified significant challenges remaining, such as the copy problem and the recursive enforcement problem that – while solutions have been suggested to some extent – are often not sufficiently addressed in proposed designs. We conclude that privacy-enhancing technologies need further improvements to positively impact data markets so that, ultimately, the value of data is preserved through data scarcity and users’ privacy and businesses-critical information are protected.}
}
@article{LI2022101021,
title = {A review of industrial big data for decision making in intelligent manufacturing},
journal = {Engineering Science and Technology, an International Journal},
volume = {29},
pages = {101021},
year = {2022},
issn = {2215-0986},
doi = {https://doi.org/10.1016/j.jestch.2021.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2215098621001336},
author = {Chunquan Li and Yaqiong Chen and Yuling Shang},
keywords = {Intelligent manufacturing, Artificial intelligence, Industrial big data, Big data-driven technology, Decision-making},
abstract = {Under the trend of economic globalization, intelligent manufacturing has attracted a lot of attention from academic and industry. Related enabling technologies make manufacturing industry more intelligent. As one of the key technologies in artificial intelligence, big data driven analysis improves the market competitiveness of manufacturing industry by mining the hidden knowledge value and potential ability of industrial big data, and helps enterprise leaders make wise decisions in various complex manufacturing environments. This paper provides a theoretical analysis basis for big data-driven technology to guide decision-making in intelligent manufacturing, fully demonstrating the practicability of big data-driven technology in the intelligent manufacturing industry, including key advantages and internal motivation. A conceptual framework of intelligent decision-making based on industrial big data-driven technology is proposed in this study, which provides valuable insights and thoughts for the severe challenges and future research directions in this field.}
}
@article{ZHANG20221,
title = {Application of machine learning, deep learning and optimization algorithms in geoengineering and geoscience: Comprehensive review and future challenge},
journal = {Gondwana Research},
volume = {109},
pages = {1-17},
year = {2022},
issn = {1342-937X},
doi = {https://doi.org/10.1016/j.gr.2022.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S1342937X2200123X},
author = {Wengang Zhang and Xin Gu and Libin Tang and Yueping Yin and Dongsheng Liu and Yanmei Zhang},
keywords = {Machine learning, Deep learning, Optimization algorithms, Geoengineering and geoscience, VOSviewer},
abstract = {The so-called Fourth Paradigm has witnessed a boom during the past two decades, with large volumes of observational data becoming available to scientists and engineers. Big data is characterized by the rule of the five Vs: Volume, Variety, Value, Velocity and Veracity. The concept of big data naturally matches well with the features of geoengineering and geoscience. Large-scale, comprehensive, multidirectional and multifield geotechnical data analysis is becoming a trend. On the other hand, Machine learning (ML), Deep Learning (DL) and Optimization Algorithm (OA) provide the ability to learn from data and deliver in-depth insight into geotechnical problems. Researchers use different ML, DL and OA models to solve various problems associated with geoengineering and geoscience. Consequently, there is a need to extend its research with big data research through integrating the use of ML, DL and OA techniques. This work focuses on a systematic review on the state-of-the-art application of ML, DL and OA algorithms in geoengineering and geoscience. Various ML, DL, and OA approaches are firstly concisely introduced, concerning mainly the supervised learning, unsupervised learning, deep learning and optimization algorithms. Then their representative applications in the geoengineering and geoscience are summarized via VOSviewer demonstration. The authors also provided their own thoughts learnt from these applications as well as work ongoing and future recommendations. This review paper aims to make a comprehensive summary and provide fundamental guidelines for researchers and engineers in the discipline of geoengineering and geoscience or similar research areas on how to integrate and apply ML, DL and OA methods.}
}
@article{BEITNER2022118,
title = {Knee registries: state of the art},
journal = {Journal of ISAKOS},
volume = {7},
number = {5},
pages = {118-131},
year = {2022},
issn = {2059-7754},
doi = {https://doi.org/10.1136/jisakos-2021-000625},
url = {https://www.sciencedirect.com/science/article/pii/S2059775421003060},
author = {Eran {Beit Ner} and Norimasa Nakamura and Christian Lattermann and Michael James McNicholas},
keywords = {knee injuries, anterior cruciate ligament, arthroplasty, replacement, patient outcome assessment, osteotomy, articular cartilage restoration, registry, post marketing surveillance},
abstract = {ABSTRACT
Sports injuries, trauma and the globally ageing and obese population require increasing levels of knee surgery. Shared decision making has replaced the paternalistic approach to patient management. Evidence-based medicine underpins surgical treatment strategies, from consenting an individual patient to national healthcare system design. The evolution of successful knee-related registries starting from specific arthroplasty registries has given rise to ligament reconstruction, osteotomy and cartilage surgery registries developing as platforms for surgical outcome data collection. Stakeholders include surgeons and their patients, researchers, healthcare systems, as well as the funding insurers and governments. Lately, implant manufacturers have also been mandated to perform postmarket surveillance with some hoping to base that on registry data. Aiming to assess the current status of knee-related registries, we performed a comprehensive literature and web search, which yielded 23 arthroplasty, 8 ligament, 4 osteotomy and 3 articular cartilage registries. Registries were evaluated for their scope, measured variables, impact and limitations. Registries have many advantages as they aim to increase awareness of outcomes; identify trends in practice over time, early failing implants, outlier surgeon or institution performance; and assist postmarketing surveillance. International collaborations have highlighted variations in practice. The limitations of registries are discussed in detail. Inconsistencies are found in collected data and measured variables. Potential measurement and selection biases are outlined. Without mandated data collection and with apparent issues such as unverified patient reporting of complications, registries are not designed to replace adverse event recording in place of a proper safety and efficacy study, as demanded by regulators. Registry ‘big data’ can provide evidence of associations of problems. However, registries cannot provide evidence of causation. Hence, without careful consideration of the data and its limitations, registry data are at risk of incorrectly drawn conclusions and the potential of misuse of the results. That must be guarded against. Looking at the future, registry operators benefit from a collective experience of running registries as they mature, allowing for improvements across specialties. Large-scale registries are not only of merit, improving with stakeholder acceptance, but also are critical in furthering our understanding of our patients’ outcomes. In doing so, they are a critical element for our future scientific discourse.}
}
@article{SKAF2022104082,
title = {Topological data analysis in biomedicine: A review},
journal = {Journal of Biomedical Informatics},
volume = {130},
pages = {104082},
year = {2022},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2022.104082},
url = {https://www.sciencedirect.com/science/article/pii/S1532046422000983},
author = {Yara Skaf and Reinhard Laubenbacher},
keywords = {Biomedical informatics, Personalized medicine, Big data analytics, Topological data analysis, TDA, Applied topology, Mapper, Persistent homology, Machine learning},
abstract = {Significant technological advances made in recent years have shepherded a dramatic increase in utilization of digital technologies for biomedicine– everything from the widespread use of electronic health records to improved medical imaging capabilities and the rising ubiquity of genomic sequencing contribute to a “digitization” of biomedical research and clinical care. With this shift toward computerized tools comes a dramatic increase in the amount of available data, and current tools for data analysis capable of extracting meaningful knowledge from this wealth of information have yet to catch up. This article seeks to provide an overview of emerging mathematical methods with the potential to improve the abilities of clinicians and researchers to analyze biomedical data, but may be hindered from doing so by a lack of conceptual accessibility and awareness in the life sciences research community. In particular, we focus on topological data analysis (TDA), a set of methods grounded in the mathematical field of algebraic topology that seeks to describe and harness features related to the “shape” of data. We aim to make such techniques more approachable to non-mathematicians by providing a conceptual discussion of their theoretical foundations followed by a survey of their published applications to scientific research. Finally, we discuss the limitations of these methods and suggest potential avenues for future work integrating mathematical tools into clinical care and biomedical informatics.}
}
@article{SIRCAR2022,
title = {Digital twin in hydrocarbon industry},
journal = {Petroleum Research},
year = {2022},
issn = {2096-2495},
doi = {https://doi.org/10.1016/j.ptlrs.2022.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2096249522000266},
author = {Anirbid Sircar and Abhishek Nair and Namrata Bist and Kriti Yadav},
keywords = {Digital twin technology, Hydrocarbon exploration, Industry 4.0, Oil and gas, Digitalization, Automation},
abstract = {The hydrocarbon industry is considering a range of digital technologies to improve productivity, efficiency, and safety of their operations while minimizing capital and operating costs, health and environmental risks, and variability in oil and gas project life cycles. Due to the emergence of industry 4.0 the improvement in performance, efficiency, and cost reduction, the hydrocarbon industry is gradually shifting towards solutions that are data-oriented. Understanding such complex systems involves the analysis of data from various sources at the same time. Digital Twin (DT) modelling is the foundation for the next generation of real-time production monitoring and optimization systems. It is a solution that boosts productivity by combining information, simulation, and visualization throughout the entire value chain of an operational firm, from subsurface equipment to central production plants. Oil and gas companies can majorly benefit from Hydrocarbon Exploration with the right use of such advanced technologies. This study focuses on the advancements in technology in the context of DT and how it has been used by the hydrocarbon industry. The study discusses about the emergence of the DT concept, various types, 5D representation, and tools for DT. Further, the study tries to implement fields of DT in hydrocarbon industry especially in the domains of exploration, drilling, and production. Challenges associated with DT strategy like accessibility, confidentiality integration, and maintenance are also discussed.}
}
@article{BERGHOUT2022100547,
title = {Machine learning for cybersecurity in smart grids: A comprehensive review-based study on methods, solutions, and prospects},
journal = {International Journal of Critical Infrastructure Protection},
volume = {38},
pages = {100547},
year = {2022},
issn = {1874-5482},
doi = {https://doi.org/10.1016/j.ijcip.2022.100547},
url = {https://www.sciencedirect.com/science/article/pii/S1874548222000348},
author = {Tarek Berghout and Mohamed Benbouzid and S.M. Muyeen},
keywords = {Cybersecurity, Cyberattacks, Machine learning, Model selection, Smart grids},
abstract = {In modern Smart Grids (SGs) ruled by advanced computing and networking technologies, condition monitoring relies on secure cyberphysical connectivity. Due to this connection, a portion of transported data, containing confidential information, must be protected as it is vulnerable and subject to several cyber threats. SG cyberspace adversaries attempt to gain access through networking platforms to commit several criminal activities such as disrupting or malicious manipulation of whole electricity delivery process including generation, distribution, and even customer services such as billing, leading to serious damage, including financial losses and loss of reputation. Therefore, human awareness training and software technologies are necessary precautions to ensure the reliability of data traffic and power transmission. By exploring the available literature, it is undeniable that Machine Learning (ML) has become the latest in the timeline and one of the leading artificial intelligence technologies capable of detecting, identifying, and responding by mitigating adversary attacks in SGs. In this context, the main objective of this paper is to review different ML tools used in recent years for cyberattacks analysis in SGs. It also provides important guidelines on ML model selection as a global solution when building an attack predictive model. A detailed classification is therefore developed with respect to data security triad, i.e., Confidentiality, Integrity, and Availability (CIA) within different types of cyber threats, systems, and datasets. Furthermore, this review highlights the various encountered challenges, drawbacks, and possible solutions as future prospects for ML cybersecurity applications in SGs.}
}
@article{PETROPOULOS2022705,
title = {Forecasting: theory and practice},
journal = {International Journal of Forecasting},
volume = {38},
number = {3},
pages = {705-871},
year = {2022},
issn = {0169-2070},
doi = {https://doi.org/10.1016/j.ijforecast.2021.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169207021001758},
author = {Fotios Petropoulos and Daniele Apiletti and Vassilios Assimakopoulos and Mohamed Zied Babai and Devon K. Barrow and Souhaib {Ben Taieb} and Christoph Bergmeir and Ricardo J. Bessa and Jakub Bijak and John E. Boylan and Jethro Browell and Claudio Carnevale and Jennifer L. Castle and Pasquale Cirillo and Michael P. Clements and Clara Cordeiro and Fernando Luiz {Cyrino Oliveira} and Shari {De Baets} and Alexander Dokumentov and Joanne Ellison and Piotr Fiszeder and Philip Hans Franses and David T. Frazier and Michael Gilliland and M. Sinan Gönül and Paul Goodwin and Luigi Grossi and Yael Grushka-Cockayne and Mariangela Guidolin and Massimo Guidolin and Ulrich Gunter and Xiaojia Guo and Renato Guseo and Nigel Harvey and David F. Hendry and Ross Hollyman and Tim Januschowski and Jooyoung Jeon and Victor Richmond R. Jose and Yanfei Kang and Anne B. Koehler and Stephan Kolassa and Nikolaos Kourentzes and Sonia Leva and Feng Li and Konstantia Litsiou and Spyros Makridakis and Gael M. Martin and Andrew B. Martinez and Sheik Meeran and Theodore Modis and Konstantinos Nikolopoulos and Dilek Önkal and Alessia Paccagnini and Anastasios Panagiotelis and Ioannis Panapakidis and Jose M. Pavía and Manuela Pedio and Diego J. Pedregal and Pierre Pinson and Patrícia Ramos and David E. Rapach and J. James Reade and Bahman Rostami-Tabar and Michał Rubaszek and Georgios Sermpinis and Han Lin Shang and Evangelos Spiliotis and Aris A. Syntetos and Priyanga Dilini Talagala and Thiyanga S. Talagala and Len Tashman and Dimitrios Thomakos and Thordis Thorarinsdottir and Ezio Todini and Juan Ramón {Trapero Arenas} and Xiaoqian Wang and Robert L. Winkler and Alisa Yusupova and Florian Ziel},
keywords = {Review, Encyclopedia, Methods, Applications, Principles, Time series, Prediction},
abstract = {Forecasting has always been at the forefront of decision making and planning. The uncertainty that surrounds the future is both exciting and challenging, with individuals and organisations seeking to minimise risks and maximise utilities. The large number of forecasting applications calls for a diverse set of forecasting methods to tackle real-life challenges. This article provides a non-systematic review of the theory and the practice of forecasting. We provide an overview of a wide range of theoretical, state-of-the-art models, methods, principles, and approaches to prepare, produce, organise, and evaluate forecasts. We then demonstrate how such theoretical concepts are applied in a variety of real-life contexts. We do not claim that this review is an exhaustive list of methods and applications. However, we wish that our encyclopedic presentation will offer a point of reference for the rich work that has been undertaken over the last decades, with some key insights for the future of forecasting theory and practice. Given its encyclopedic nature, the intended mode of reading is non-linear. We offer cross-references to allow the readers to navigate through the various topics. We complement the theoretical concepts and applications covered by large lists of free or open-source software implementations and publicly-available databases.}
}
@article{AHMAD2022112128,
title = {Data-driven probabilistic machine learning in sustainable smart energy/smart energy systems: Key developments, challenges, and future research opportunities in the context of smart grid paradigm},
journal = {Renewable and Sustainable Energy Reviews},
volume = {160},
pages = {112128},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2022.112128},
url = {https://www.sciencedirect.com/science/article/pii/S1364032122000569},
author = {Tanveer Ahmad and Rafal Madonski and Dongdong Zhang and Chao Huang and Asad Mujeeb},
keywords = {Data-driven probabilistic machine learning, Energy distribution, Discovery and design of energy materials, Big data analytics and smart grid, Strategic energy planning and smart manufacturing, Energy demand-side response},
abstract = {The current trend indicates that energy demand and supply will eventually be controlled by autonomous software that optimizes decision-making and energy distribution operations. New state-of-the-art machine learning (ML) technologies are integral in optimizing decision-making in energy distribution networks and systems. This study was conducted on data-driven probabilistic ML techniques and their real-time applications to smart energy systems and networks to highlight the urgency of this area of research. This study focused on two key areas: i) the use of ML in core energy technologies and ii) the use cases of ML for energy distribution utilities. The core energy technologies include the use of ML in advanced energy materials, energy systems and storage devices, energy efficiency, smart energy material manufacturing in the smart grid paradigm, strategic energy planning, integration of renewable energy, and big data analytics in the smart grid environment. The investigated ML area in energy distribution systems includes energy consumption and price forecasting, the merit order of energy price forecasting, and the consumer lifetime value. Cybersecurity topics for power delivery and utilization, grid edge systems and distributed energy resources, power transmission, and distribution systems are also briefly studied. The primary goal of this work was to identify common issues useful in future studies on ML for smooth energy distribution operations. This study was concluded with many energy perspectives on significant opportunities and challenges. It is noted that if the smart ML automation is used in its targeting energy systems, the utility sector and energy industry could potentially save from $237 billion up to $813 billion.}
}
@article{KAUR2022100035,
title = {Face mask recognition system using CNN model},
journal = {Neuroscience Informatics},
volume = {2},
number = {3},
pages = {100035},
year = {2022},
note = {Multimedia-based Emerging Technologies and Data Analytics for Neuroscience as a Service (NaaS)},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2021.100035},
url = {https://www.sciencedirect.com/science/article/pii/S2772528621000352},
author = {Gagandeep Kaur and Ritesh Sinha and Puneet Kumar Tiwari and Srijan Kumar Yadav and Prabhash Pandey and Rohit Raj and Anshu Vashisth and Manik Rakhra},
keywords = {Artificial Intelligence (AL), Machine learning (ML), Deep neural learning (DL), Convolutional Neural Network Model (CNN), Artificial Neural Networks (ANN), Security},
abstract = {COVID-19 epidemic has swiftly disrupted our day-to-day lives affecting the international trade and movements. Wearing a face mask to protect one's face has become the new normal. In the near future, many public service providers will expect the clients to wear masks appropriately to partake of their services. Therefore, face mask detection has become a critical duty to aid worldwide civilization. This paper provides a simple way to achieve this objective utilising some fundamental Machine Learning tools as TensorFlow, Keras, OpenCV and Scikit-Learn. The suggested technique successfully recognises the face in the image or video and then determines whether or not it has a mask on it. As a surveillance job performer, it can also recognise a face together with a mask in motion as well as in a video. The technique attains excellent accuracy. We investigate optimal parameter values for the Convolutional Neural Network model (CNN) in order to identify the existence of masks accurately without generating over-fitting.}
}
@article{PERNO2022103558,
title = {Implementation of digital twins in the process industry: A systematic literature review of enablers and barriers},
journal = {Computers in Industry},
volume = {134},
pages = {103558},
year = {2022},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2021.103558},
url = {https://www.sciencedirect.com/science/article/pii/S0166361521001652},
author = {Matteo Perno and Lars Hvam and Anders Haug},
keywords = {Digital twin, Simulation, Process industry, Literature review, Barrier, Enabler},
abstract = {Since the introduction of the concept of “digital twins” (DTs) in 2002, the number of practical applications in different industrial sectors has grown rapidly. Despite the hype surrounding this technology, companies face significant challenges upon deciding to implement DTs in their organizations due to the novelty of the concept. Furthermore, little research on DT has been conducted for the process industry, which may be explained by the high complexity of accurately representing and modeling the physics behind production processes. To consolidate the fragmented literature on the enabling factors and challenges in DT implementation in the process industry, this study organizes the existing studies on DTs with a focus on barriers and enablers. On this basis, this study contributes to the existing body of knowledge on DTs by organizing the DT literature and by proposing conceptual models describing enablers of and barriers to DT implementation, as well as their mutual relationships.}
}
@article{REJEB2022100580,
title = {The Interplay between the Internet of Things and agriculture: A bibliometric analysis and research agenda},
journal = {Internet of Things},
volume = {19},
pages = {100580},
year = {2022},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2022.100580},
url = {https://www.sciencedirect.com/science/article/pii/S2542660522000701},
author = {Abderahman Rejeb and Karim Rejeb and Alireza Abdollahi and Fadi Al-Turjman and Horst Treiblmaier},
keywords = {Internet of Things, Agriculture, Bibliometrics, Sustainability, Challenges, Resource-based view, Precision agriculture},
abstract = {The proliferation of the Internet of Things (IoT) has fundamentally reshaped the agricultural sector. In recent years, academic research on the IoT has grown at an unprecedented pace. However, the broad picture of how this technology can benefit the agricultural sector is still missing. To close this research gap, we conduct a bibliometric study to investigate the current state of the IoT and agriculture in academic literature. Using a resource-based view (RBV), we also identify those agricultural resources that are mostly impacted by the introduction of the IoT (i.e., seeds, soil, water, fertilizers, pesticides, energy, livestock, human resources, technology infrastructure, business relations) and propose numerous themes for future research.}
}